{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2690737a",
   "metadata": {},
   "source": [
    "Purpose: Turn text-data into data with appropriate values neccessary for functional RAGAS evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe365bb",
   "metadata": {},
   "source": [
    "Fetch documents (from only the SciComp wiki as of now) and put into accessable format for generation of expected outputs and creation of context later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e912570b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='Overview of Janelia Scientific Computing\\nThe Janelia Scientific Computing team supports the institute’s mission by developing and maintaining computational infrastructure, software tools, and data analysis pipelines essential for modern biological research. They collaborate closely with scientists to address computational challenges and drive innovation in various research areas, including neuroscience, cell biology, and bioinformatics.\\n\\nKey Areas of Focus\\nHigh-Performance Computing (HPC):\\n\\nProvides access to powerful computing clusters to handle large-scale data analysis and complex simulations.\\nOptimizes computational workflows to maximize efficiency and resource utilization.\\nData Management and Storage:\\n\\nDevelops and maintains robust data storage solutions to handle the vast amounts of data generated by research activities.\\nEnsures data integrity, security, and accessibility.\\nSoftware Development:\\n\\nCreates custom software tools and platforms tailored to specific research needs.\\nDevelops user-friendly interfaces and integrates with existing scientific tools to enhance usability.\\nBioinformatics and Data Analysis:\\n\\nProvides expertise in bioinformatics to analyze genomic, proteomic, and other biological data.\\nDevelops algorithms and pipelines for data processing, statistical analysis, and visualization.\\nImaging and Image Analysis:\\n\\nSupports advanced imaging techniques, including light microscopy, electron microscopy, and in vivo imaging.\\nDevelops image analysis tools to process and quantify complex imaging data.\\nCollaboration and Support:\\n\\nWorks closely with researchers to understand their computational needs and provide tailored solutions.\\nOffers training and support to scientists to enhance their computational skills.\\nNotable Projects and Contributions\\nFlyEM Project:\\n\\nThe Fly Electron Microscopy (FlyEM) project aims to map the entire brain of the fruit fly, Drosophila melanogaster, at nanoscale resolution using electron microscopy.\\nThe Scientific Computing team has developed sophisticated data processing pipelines and analysis tools to handle the massive datasets generated by this project.\\nNeuroglancer:\\n\\nAn open-source web-based tool for visualizing large-scale volumetric data, such as 3D electron microscopy images.\\nDeveloped in collaboration with Google, Neuroglancer allows researchers to interactively explore complex datasets in real-time.\\nJanelia Workstation:\\n\\nA powerful software platform for managing and analyzing microscopy data.\\nIntegrates various image processing and analysis tools into a cohesive workflow, streamlining the research process.\\nOpen-source Contributions:\\n\\nThe team actively contributes to the open-source community, releasing tools and software developed at Janelia for wider use in the scientific community.\\nExamples include the suite of tools for image analysis and neuroinformatics.\\nFacilities and Infrastructure\\nData Center: Houses high-performance computing clusters, massive storage systems, and networking infrastructure essential for supporting computational research.\\nCollaboration Spaces: Equipped with state-of-the-art visualization and collaboration tools to facilitate teamwork and knowledge sharing among scientists and computational experts.\\nEducational and Training Initiatives\\nWorkshops and Training Sessions: Regularly organizes workshops and training sessions to educate researchers on computational tools, data analysis techniques, and best practices.\\nDocumentation and Resources: Provides comprehensive documentation, tutorials, and online resources to help researchers effectively use computational tools and resources.\\nImpact on Research\\nThe Janelia Scientific Computing team’s contributions have significantly impacted various research areas:\\n\\nNeuroscience: Enabled groundbreaking discoveries in understanding brain function and neural circuits through advanced data analysis and visualization tools.\\nCell Biology: Facilitated high-throughput data analysis and imaging techniques, leading to new insights into cellular processes and structures.\\nGenomics: Supported large-scale genomic studies with robust bioinformatics tools, accelerating discoveries in genetics and molecular biology.\\nLeadership and Team Composition\\nLeadership: The team is led by experts in computational science and bioinformatics, who bring a wealth of experience and vision to the team.\\nTeam Composition: Comprises computational scientists, software developers, data analysts, and bioinformatics specialists, each bringing unique skills and expertise to the team.\\nFuture Directions\\nThe Janelia Scientific Computing team is continually evolving to meet the growing computational demands of modern biological research. Future directions include:\\n\\nIntegration of AI and Machine Learning: Leveraging AI and machine learning techniques to enhance data analysis and interpretation.\\nExpansion of Cloud Computing: Exploring cloud computing solutions to provide scalable and flexible computational resources.\\nDevelopment of Next-Generation Tools: Continuing to innovate and develop new tools and platforms to support emerging research needs.\\nConclusion\\nThe Janelia Scientific Computing team is an integral part of the research ecosystem at Janelia Research Campus, providing essential computational support and driving innovation across various scientific disciplines. Their work enables researchers to tackle complex biological questions and make significant scientific advancements.\\n\\n\\n\\n\\n\\n\\n', metadata={'source': '../data/test/test.txt'})]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# DONE: Recursively load all scraped files in the directory and its subdirectories\n",
    "loader = TextLoader(\"../data/test/test.txt\")\n",
    "documents = loader.load()\n",
    "print(documents)\n",
    "\n",
    "# from langchain_community.document_loaders import TextLoader\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# import glob\n",
    "\n",
    "# import glob\n",
    "# import os\n",
    "# import json\n",
    "# import mimetypes\n",
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "# class RecursiveTextLoader:\n",
    "#     def __init__(self, root_dir):\n",
    "#         self.root_dir = root_dir\n",
    "\n",
    "#     def load(self):\n",
    "#         documents = []\n",
    "#         for filepath in glob.glob(os.path.join(self.root_dir, '**'), recursive=True):\n",
    "#             if os.path.isfile(filepath):\n",
    "#                 mime_type, _ = mimetypes.guess_type(filepath)\n",
    "#                 if mime_type == 'application/json':\n",
    "#                     with open(filepath, 'r', encoding='utf-8') as file:\n",
    "#                         documents.append(json.load(file))\n",
    "#                 elif mime_type == 'text/html' or self._looks_like_html(filepath):\n",
    "#                     with open(filepath, 'r', encoding='utf-8') as file:\n",
    "#                         soup = BeautifulSoup(file, 'html.parser')\n",
    "#                         documents.append(soup.get_text())\n",
    "#                 elif mime_type == 'text/plain':\n",
    "#                     with open(filepath, 'r', encoding='utf-8') as file:\n",
    "#                         documents.append(file.read())\n",
    "#         return documents\n",
    "\n",
    "#     def _looks_like_html(self, filepath):\n",
    "#         with open(filepath, 'r', encoding='utf-8') as file:\n",
    "#             head = file.read(1024)  # Read the first 1024 bytes\n",
    "#             return '<html' in head or '<!DOCTYPE html>' in head\n",
    "\n",
    "# # Assuming your data folder is at \"../data/\"\n",
    "# loader = RecursiveTextLoader(\"../data/\")\n",
    "# documents = loader.load()\n",
    "# # Assuming documents is a list of strings or convertible to string\n",
    "# with open('output.txt', 'a', encoding='utf-8') as file:\n",
    "#     for document in documents:\n",
    "#         # Remove all linebreaks from the document and then append\n",
    "#         file.write(str(document).replace('\\n', '') + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1a0410",
   "metadata": {},
   "source": [
    "Generate the testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c75c1d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for ChatOpenAI\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#change the model to a better one once the whole thing is functional\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m generator_llm \u001b[38;5;241m=\u001b[39m \u001b[43mChatOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# critic_llm = ChatOpenAI(model=\"gpt-4\")\u001b[39;00m\n\u001b[1;32m     12\u001b[0m critic_llm \u001b[38;5;241m=\u001b[39m ChatOpenAI(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for ChatOpenAI\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. (type=value_error)"
     ]
    }
   ],
   "source": [
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "# generator with openai models\n",
    "import os\n",
    "\n",
    "\n",
    "#change the model to a better one once the whole thing is functional\n",
    "\n",
    "generator_llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "# critic_llm = ChatOpenAI(model=\"gpt-4\")\n",
    "critic_llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "generator = TestsetGenerator.from_langchain(\n",
    "    generator_llm,\n",
    "    critic_llm,\n",
    "    embeddings\n",
    ") \n",
    "\n",
    "\n",
    "testset = generator.generate_with_langchain_docs(documents, test_size=10, distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5717751c",
   "metadata": {},
   "source": [
    "Address potentiall duplicate questions (which the testset generator has done) and delete their rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d241aad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = testset.to_pandas()\n",
    "df = df.drop_duplicates(subset='question', keep='first')\n",
    "questions_list = df['question'].tolist()\n",
    "print (questions_list)\n",
    "\n",
    "seen = set()\n",
    "questions_list = [x for x in questions_list if not (x in seen or seen.add(x))]\n",
    "\n",
    "for item in questions_list:\n",
    "    print(item)\n",
    "\n",
    "    \n",
    "\n",
    "# testset.to_json(\"testset.json\")\n",
    "# Creates dataset of ground truths contexts and questions for the testset\n",
    "# Missing answers column \n",
    "# On one medium size document, it took about 1 minutes to generate 10 questions and cost 3 dollars on OpenAI\n",
    "# Seems expensive when using gpt-4, is its use justified or does 3.5 get the job done?\n",
    "# Evaluate gpt-4 vs gpt-3.5-turbo-16k for RAGAS evaluation test data generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb23bbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('testset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0a0523",
   "metadata": {},
   "source": [
    "fetch the LLM's response and append to a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03839e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming SemanticSearchParser is your class and it has a method named 'generate_response' that takes a question and returns an answer\n",
    "\n",
    "# Initialize your SemanticSearchParser class\n",
    "# Adjust this step if your class initialization requires different parameters\n",
    "\n",
    "\n",
    "# Now you can import the class\n",
    "\n",
    "from generate_answer import SemanticSearchService\n",
    "\n",
    "weaviate_url = \"http://localhost:8777\"\n",
    "service = SemanticSearchService(weaviate_url)\n",
    "print (questions_list)\n",
    "\n",
    "# List to store answers (optional)\n",
    "answers_list = []\n",
    "\n",
    "\n",
    "# Loop through each question in the questions_list\n",
    "for question in questions_list:\n",
    "    # Use the question as input to get the answer\n",
    "    answer = service.generate_response(question)\n",
    "    \n",
    "    # Print the answer\n",
    "    \n",
    "    # Optionally, append the answer to answers_list for further processing\n",
    "    answers_list.append(answer)\n",
    "\n",
    "print (answers_list)\n",
    "# temp_ans_list = [\"The Janelia Scientific Computing team operates and maintains a world-class computational infrastructure that includes a high-performance compute cluster with over 5000 cores and 300 GPUs. This infrastructure is used to analyze and mine the large amounts of data produced by Janelia's scientists. The team also supports a state-of-the-art storage and compute infrastructure across two data centers, which currently supports over 15 petabytes of scientific data. This data is split across various storage tiers and is connected with an optical fiber ring. The team also maintains a 4500 sq ft data center with significant power and cooling capacity. \\n\\nIn addition to hardware, the team also has deep software skills in a broad range of programming languages, extendable applications, frameworks, cloud & cluster technologies, and databases. These skills are used to help with research and engineering tasks, from quick questions to full software life cycle support. The team's software skills, combined with their domain knowledge in areas such as image processing, machine learning, data handling, microscopy, instrument control, 3D graphics & visualization, and bioinformatics & transcriptomics, allow them to efficiently work with both experimentalists and computer scientists. \\n\\nThe team also develops and maintains a variety of tools and projects, such as NeuronBridge, HortaCloud, VVD Viewer, EASI-FISH pipeline, Render, RS-FISH, and BigStitcher, which are used for various aspects of data analysis and simulation in biological research.\", \"The Janelia Scientific Computing team provides a wide range of support for advanced imaging techniques and image analysis. They offer consultation on experiment design as well as image visualization and processing. They also provide comprehensive image and data analysis support for multiple software packages through hands-on assistance and/or custom-written macros/plugins/scripts for ImageJ/FIJI, MATLAB, Imaris, etc. \\n\\nIn addition, they maintain several computer workstations dedicated to viewing and processing large image datasets acquired with the facility's instruments. These workstations are equipped with a suite of imaging software, including a full version of Imaris, and have robust hardware specifications to handle large datasets. \\n\\nThe team also has deep domain knowledge in image processing, machine learning, data handling, and 3D graphics & visualization, which allows them to efficiently work with experimentalists and computer scientists in various research areas.\", \"The Janelia Scientific Computing team provides world-class computational infrastructure to support the institute's scientific endeavors. They operate and maintain all of Janelia’s storage and associated backup infrastructure, high performance compute cluster, and all Linux systems. They also manage Janelia’s data center and backup and disaster recovery resources. The team supports a Linux compute cluster with over 5000 cores and 300 GPUs, and is responsible for maintaining many other Linux servers and workstations. They also handle a significant amount of data, with almost 100TB of new Janelia’s data being safely backed up every month.\\n\\nIn addition to infrastructure, the Scientific Computing Software team works closely with Janelia's labs and project teams, providing everything from answering quick questions to full software life cycle support. They have a broad range of software skills, including programming languages, extendable applications, frameworks, cloud & cluster technologies, and databases. They also have deep domain knowledge in areas like image processing, machine learning, data handling, microscopy, instrument control, 3D graphics & visualization, and bioinformatics & transcriptomics. \\n\\nThe team also identifies opportunities for code reuse, reducing development overhead and support costs across Janelia. They are strong proponents of open science and have created the Open Science Software Initiative. Most of their software is open source and available via GitHub. They also run a Scientific Computing Associates program to embed associates in SciComp and the lab or team they work with. \\n\\nThe team is led by Stephan Preibisch and consists of three teams: Software Engineering headed by Konrad Rokicki, Computational Methods and Solutions, both headed by Stephan Preibisch. They have developed several tools and projects like NeuronBridge, HortaCloud, VVD Viewer, EASI-FISH pipeline, Render, RS-FISH, and BigStitcher. \\n\\nIn summary, the Janelia Scientific Computing team supports the institute's mission and drives innovation in modern biological research by providing robust computational infrastructure, software support, and developing innovative tools and solutions.\", 'The Janelia Scientific Computing team supports advanced imaging techniques in neuroscience and cell biology through a variety of ways. They have deep domain knowledge in image processing, machine learning, data handling, electron and light microscopy, instrument control, 3D graphics & visualization, bioinformatics & transcriptomics. They also develop and maintain a range of software tools and applications that aid in these areas. Some of these tools include NeuronBridge for finding neuron matches across modalities, HortaCloud for cloud-based collaborative annotation, VVD Viewer for volumetric rendering of 3D/4D microscopy data, and BigStitcher for efficient alignment of multi-tile and multi-angle image datasets. They also work closely with labs and project teams, providing full software life cycle support.', \"The Janelia Scientific Computing team supports modern biological research in several ways. They maintain a world-class computational infrastructure, including storage and backup infrastructure, a high-performance compute cluster, and all Linux systems. They also manage Janelia's data center and backup and disaster recovery resources. The team supports data storage infrastructure for storing and accessing scientific data, with over 15 petabytes of scientific data split across various storage tiers. They also support a Linux compute cluster with over 5000 cores and 300 GPUs, and maintain many other Linux servers and workstations. \\n\\nIn addition to infrastructure support, the Scientific Computing Software team works closely with Janelia's labs, project teams, and shared resources to help with research and engineering tasks. They provide everything from answering quick questions to full software life cycle support. The team's software skills span a broad range of programming languages, extendable applications, frameworks, cloud & cluster technologies, and databases. They also have deep domain knowledge in image processing, machine learning, data handling, electron and light microscopy, instrument control, 3D graphics & visualization, bioinformatics & transcriptomics. \\n\\nThe team also develops and maintains a variety of tools and projects, such as NeuronBridge, HortaCloud, VVD Viewer, EASI-FISH pipeline, Render, RS-FISH, and BigStitcher. They are strong proponents of open science and most of their software is open source and available via GitHub. They also run the Scientific Computing Associates program, which offers challenging assignments for those interested in computational science.\", \"The Janelia Scientific Computing team provides comprehensive support for advanced imaging techniques in neuroscience, cell biology, and bioinformatics through a variety of collaborations and custom software tools. They work closely with Janelia's labs, project teams, and shared resources to assist with research and engineering tasks. This can range from answering quick questions to providing full software life cycle support.\\n\\nThe team's software skills cover a broad range of programming languages, extendable applications, frameworks, cloud & cluster technologies, and databases. They have deep domain knowledge in image processing, machine learning, data handling, electron and light microscopy, instrument control, 3D graphics & visualization, bioinformatics & transcriptomics. Many team members have backgrounds in biology, enabling them to work efficiently with experimentalists and computer scientists.\\n\\nThe team is also involved in various projects and tools such as NeuronBridge, HortaCloud, VVD Viewer, EASI-FISH pipeline, Render, RS-FISH, and BigStitcher, which are designed to support advanced imaging techniques and data analysis in neuroscience, cell biology, and bioinformatics.\\n\\nFurthermore, the team is a strong proponent of open science and has teamed up with the Computation & Theory research area to create the Open Science Software Initiative. Most of their software is open source and available via GitHub, promoting collaboration and knowledge sharing. They also run the Scientific Computing Associates program, which embeds associates in SciComp and the lab or team they work with.\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9699a438",
   "metadata": {},
   "source": [
    "Add values from the list of JaneliaGPT responses to the dataframe[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93eaea4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['answer'] = None\n",
    "# Assuming df is your DataFrame and answers_list is a list with values to populate the 'Answer' column\n",
    "if len(df) == len(answers_list):\n",
    "    df['answer'] = answers_list\n",
    "else:\n",
    "    print(\"The length of answers_list does not match the number of rows in the DataFrame.\")\n",
    "\n",
    "df.dropna(axis=1, how='all', inplace=True)\n",
    "display(df)\n",
    "# df.to_json('WithAnswersDatasetFromTestTxt.json', index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6095ca61",
   "metadata": {},
   "source": [
    "Preprocess the dataframe to conver to a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55166bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attempt to fix the issue with the answers_list not bsjdkflasdjjfklasdkl fasdjkfh jkas\n",
    "df_fix = df\n",
    "# List of columns to keep\n",
    "columns_to_keep = ['question', 'ground_truth', 'answer', 'contexts']\n",
    "\n",
    "# Reassign df to a DataFrame containing only the columns to keep\n",
    "df_fix= df_fix[columns_to_keep]\n",
    "\n",
    "\n",
    "\n",
    "# Assuming df is already defined and contains the necessary columns\n",
    "\n",
    "# Convert 'question' and 'answer' to lists of strings if they are not already\n",
    "# df_fix['question'] = df_fix['question'].apply(lambda x: [x] if isinstance(x, str) else x)\n",
    "# df_fix['answer'] = df_fix['answer'].apply(lambda x: [x] if isinstance(x, str) else x)\n",
    "\n",
    "# Ensure 'contexts' and 'ground_truth' are lists of lists of strings\n",
    "# This step assumes 'contexts' and 'ground_truth' are already in the correct format\n",
    "# If not, you would need to apply a similar conversion as above, ensuring each element is a list\n",
    "\n",
    "# Example conversion if 'contexts' and 'ground_truth' were not already lists of lists\n",
    "df_fix['contexts'] = df_fix['contexts'].apply(lambda x: [[y] for y in x] if isinstance(x, list) and all(isinstance(y, str) for y in x) else x)\n",
    "df_fix['ground_truth'] = df_fix['ground_truth'].apply(lambda x: [[y] for y in x] if isinstance(x, list) and all(isinstance(y, str) for y in x) else x)\n",
    "\n",
    "# Now df should be in the correct format for training\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "amnesty_qa = load_dataset(\"explodinggradients/amnesty_qa\", \"english_v2\")\n",
    "\n",
    "from datasets import Dataset\n",
    "dataset_fix = Dataset.from_pandas(df_fix)\n",
    "dataset_fix = dataset_fix.remove_columns(['__index_level_0__'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636e5b0c",
   "metadata": {},
   "source": [
    "Convert dataframe to Dataset and compare to a vaild Dataset for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec82fd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Features\n",
    "\n",
    "# Assuming dataset_fix and amnesty_qa[\"eval\"] are your datasets\n",
    "features_dataset_fix = dataset_fix.features\n",
    "features_amnesty_eval = amnesty_qa[\"eval\"].features\n",
    "def format_columns(example):\n",
    "    # Format 'question', 'answer', and 'ground_truths' columns to single values\n",
    "    for column in ['ground_truth', 'answer', 'question']:\n",
    "        if column in example and example[column]:\n",
    "            example[column] = example[column]\n",
    "    \n",
    "    # Correctly format 'contexts' column to a list of list of strings\n",
    "    if 'contexts' in example:\n",
    "        # Ensure 'contexts' is a list of strings (not a list of lists)\n",
    "        if isinstance(example['contexts'], list):\n",
    "            # If the items are lists (or other non-string types), flatten and convert to strings\n",
    "            example['contexts'] = [str(item) for sublist in example['contexts'] for item in (sublist if isinstance(sublist, list) else [sublist])]\n",
    "        else:\n",
    "            # If 'contexts' is not a list, convert it into a list of a single string\n",
    "            example['contexts'] = [str(example['contexts'])]\n",
    "\n",
    "    \n",
    "    return example\n",
    "\n",
    "\n",
    "# Apply the transformation to both datasets\n",
    "dataset_fix = dataset_fix.map(format_columns)\n",
    "# Direct comparison of data types\n",
    "if set(features_dataset_fix.keys()) == set(features_amnesty_eval.keys()):\n",
    "    all_types_match = True\n",
    "    for key in features_dataset_fix.keys():\n",
    "        type_dataset_fix = type(features_dataset_fix[key]).__name__\n",
    "        type_amnesty_eval = type(features_amnesty_eval[key]).__name__\n",
    "        if type_dataset_fix != type_amnesty_eval:\n",
    "            print(f\"Data type for feature '{key}' differs between datasets. dataset_fix: {type_dataset_fix}, amnesty_qa['eval']: {type_amnesty_eval}\")\n",
    "            all_types_match = False\n",
    "    if all_types_match:\n",
    "        print(\"The data types of all features in both datasets match.\")\n",
    "else:\n",
    "    print(\"The Features of the datasets differ in their keys.\")\n",
    "\"\"\"\n",
    "print (dataset_fix[\"question\"])\n",
    "print (dataset_fix[\"answer\"])\n",
    "print (dataset_fix[\"ground_truth\"])\n",
    "print (dataset_fix[\"contexts\"])\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2cc907",
   "metadata": {},
   "source": [
    "Run evaluation to gather the below metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7be48f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "\n",
    "\n",
    "from ragas import evaluate\n",
    "\n",
    "\n",
    "# Will reutrn a dataframe with the metrics\n",
    "# Returns error for now because answers column is missing\n",
    "# Error is misleading, fix dataset first and make it match the docs example dataset\n",
    "\n",
    "result = evaluate(\n",
    "    dataset_fix,\n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_recall,\n",
    "    ],\n",
    ")\n",
    "\n",
    "result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22595923",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)\n",
    "result.to_pandas()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
