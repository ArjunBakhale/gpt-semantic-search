{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa2da29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import glob\n",
    "import os \n",
    "\n",
    "data_path = \"../data/slack/slack_export_Janelia-Software_30days\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777945fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2username = {}\n",
    "id2realname = {}\n",
    "\n",
    "with open(f\"{data_path}/users.json\", 'r') as f:\n",
    "    users = json.load(f)\n",
    "    for user in users:\n",
    "        id = user['id']\n",
    "        id2username[id] = user['name']\n",
    "        id2realname[id] = user['profile']['real_name']\n",
    "\n",
    "print(f\"{len(id2username)} users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3562756",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel2id = {}\n",
    "with open(f\"{data_path}/channels.json\", 'r') as f:\n",
    "    channels = json.load(f)\n",
    "\n",
    "    for channel in channels:\n",
    "        print(f\"{channel['id']} {channel['name']}\")\n",
    "        channel2id[channel['name']] = channel['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba5d840",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.sub(\"<@(.*?)>\", lambda m: id2realname[m.group(1)], \"<@W97623DK2> has joined <@W97623DK2>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffe86d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from decimal import *\n",
    "from llama_index.legacy import Document\n",
    "\n",
    "ignored_subtypes = set(['channel_join','channel_leave'])\n",
    "\n",
    "\n",
    "def fix_text(text):\n",
    "    text = re.sub(\"&lt;\", \"<\", text)\n",
    "    text = re.sub(\"&gt;\", \">\", text)\n",
    "    text = re.sub(\"\\n+\", \"\\n\", text)\n",
    "    return text\n",
    "\n",
    "def get(element, key):\n",
    "    if element and key in element:\n",
    "        return element[key]\n",
    "    return None\n",
    "\n",
    "def extract_text(elements):\n",
    "    text = ''\n",
    "    for element in elements:\n",
    "        if 'elements' in element:\n",
    "            text += extract_text(element['elements'])\n",
    "        el_type = get(element, 'type')\n",
    "        if el_type == 'text':\n",
    "            if get(get(element, 'style'), 'code'): text += '`'\n",
    "            text += element['text']\n",
    "            if get(get(element, 'style'), 'code'): text += '`'\n",
    "        elif el_type == 'link':\n",
    "            text += get(element, 'url')\n",
    "        elif el_type == 'rich_text_preformatted':\n",
    "            text += \"\\n\"\n",
    "        elif el_type == 'user':\n",
    "            user_id = element['user_id']\n",
    "            try:\n",
    "                text += id2realname[user_id]\n",
    "            except KeyError:\n",
    "                print(f\"ERROR: no such user {user_id}\")\n",
    "                text += user_id\n",
    "\n",
    "    return text\n",
    "\n",
    "def parse_message(message):\n",
    "    thread_id, text_msg = None, None\n",
    "    if get(message, 'type') == 'message':\n",
    "        if 'subtype' in message and get(message, 'subtype') in ignored_subtypes:\n",
    "            pass\n",
    "        else:\n",
    "            ts = message['ts']\n",
    "            thread_ts = get(message, 'thread_ts') or ts\n",
    "            msg_user = message['user']\n",
    "            try:\n",
    "                realname = id2realname[msg_user]\n",
    "            except KeyError:\n",
    "                realname = message['user_profile']['display_name']\n",
    "                \n",
    "            if 'blocks' in message:\n",
    "                text = extract_text(message['blocks'])\n",
    "            else:\n",
    "                text = message['text']\n",
    "            \n",
    "            text_msg = re.sub(\"<@(.*?)>\", lambda m: id2realname[m.group(1)], text)\n",
    "            text_msg = fix_text(text_msg)\n",
    "\n",
    "            if 'attachments' in message:\n",
    "                for attachment in message['attachments']:\n",
    "                    if 'title' in attachment: text_msg += f\"\\n{fix_text(attachment['title'])}\"\n",
    "                    if 'text' in attachment: text_msg += f\"\\n{fix_text(attachment['text'])}\"\n",
    "                    \n",
    "            if 'files' in message:\n",
    "                for file in message['files']:\n",
    "                    text_msg += f\"\\n<{file['name']}>\"\n",
    "\n",
    "            if 'reactions' in message:\n",
    "                text_msg += f\"\\nOthers reacted to the previous message with \"\n",
    "                r = [f\"{reaction['name']} a total of {reaction['count']} times\" for reaction in message['reactions']]\n",
    "                text_msg += \", and with \".join(r) + \".\"\n",
    "\n",
    "            text_msg = f\"{realname} said: {text_msg}\\n\"\n",
    "            thread_id = Decimal(thread_ts)\n",
    "\n",
    "    return thread_id, text_msg\n",
    "\n",
    "\n",
    "def create_document(channel_id, ts, doc_text):\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(f\"Document[channel={channel_id},ts={ts}]\")\n",
    "    print(doc_text)\n",
    "    return Document(doc_text, extra_info={\"channel\": channel_id, \"ts\": ts})\n",
    "\n",
    "DOCUMENT_PAUSE_SECS = 300\n",
    "\n",
    "def index_channel(channel_name):\n",
    "    channel_id = channel2id[channel_name]\n",
    "    messages = {}\n",
    "    for messages_file in glob.glob(f\"{data_path}/{channel_name}/*.json\"):\n",
    "        with open(messages_file, 'r') as f:\n",
    "            for message in json.load(f):\n",
    "                #print(message)\n",
    "                try:\n",
    "                    thread_id, text_msg = parse_message(message)\n",
    "                except Exception as e:\n",
    "                    print(\"Error parsing\", message)\n",
    "                    raise e\n",
    "                    \n",
    "                if thread_id and text_msg:\n",
    "                    if thread_id not in messages:\n",
    "                        messages[thread_id] = []\n",
    "                    messages[thread_id].append(text_msg)\n",
    "\n",
    "    prev_id = Decimal(0)\n",
    "    thread_ids = list(messages.keys())\n",
    "    thread_ids.sort()\n",
    "\n",
    "    documents = []\n",
    "    doc_text = \"\"\n",
    "    start_ts = None\n",
    "\n",
    "    for thread_id in thread_ids:\n",
    "\n",
    "        # Create a new document whenever messages are separated by a longer pause\n",
    "        if doc_text and thread_id-prev_id > DOCUMENT_PAUSE_SECS:\n",
    "            doc = create_document(channel_id, start_ts, doc_text)\n",
    "            documents.append(doc)\n",
    "            doc_text = \"\"\n",
    "            start_ts = None\n",
    "\n",
    "        print(thread_id)\n",
    "        if not start_ts:\n",
    "            start_ts = str(thread_id)\n",
    "\n",
    "        for text_msg in messages[thread_id]:\n",
    "            doc_text += text_msg\n",
    "\n",
    "        prev_id = thread_id\n",
    "\n",
    "    # Add final document\n",
    "    doc = create_document(channel_id, start_ts, doc_text)\n",
    "    documents.append(doc)\n",
    "\n",
    "    return documents\n",
    "\n",
    "documents = index_channel(\"general\")\n",
    "print(f\"Loaded {len(documents)} documents\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7faaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify weviate-client is installed and the database is live and ready\n",
    "import weaviate\n",
    "client = weaviate.Client(\"http://localhost:8080\")\n",
    "assert client.is_live()\n",
    "assert client.is_ready()\n",
    "client.get_meta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c417967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!! Delete data in Weaviate\n",
    "client.schema.delete_class(\"Slack_Node\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cc25f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Documents from cached Slack logs\n",
    "documents = []\n",
    "for channel_name in channel2id.keys():\n",
    "    for doc in index_channel(channel_name):\n",
    "        documents.append(doc)\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6927a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.legacy import LLMPredictor, PromptHelper, ServiceContext\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from llama_index.legacy import LangchainEmbedding\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.5, model_name=\"gpt-3.5-turbo-0301\")\n",
    "llm_predictor = LLMPredictor(llm=llm)\n",
    "embed_model = LangchainEmbedding(OpenAIEmbeddings())\n",
    "\n",
    "max_input_size = 4096\n",
    "num_output = 256\n",
    "max_chunk_overlap = 20\n",
    "prompt_helper = PromptHelper(max_input_size, num_output, max_chunk_overlap)\n",
    "\n",
    "service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, embed_model=embed_model, prompt_helper=prompt_helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dee433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate embedding for all of the documents and save them into Weaviate\n",
    "from llama_index.legacy import GPTVectorStoreIndex\n",
    "from llama_index.vector_stores import WeaviateVectorStore\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "\n",
    "class_prefix = \"Slack\"\n",
    "vector_store = WeaviateVectorStore(weaviate_client=client, class_prefix=class_prefix)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "# persists the vector_store into Weaviate\n",
    "index = GPTVectorStoreIndex.from_documents(documents, storage_context=storage_context, service_context=service_context)\n",
    "\n",
    "# persist the docstore and index_store\n",
    "# this is currently required although in theory Weaviate should be able to handle these as well\n",
    "storage_context.persist(persist_dir='../storage/index/slack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39dbaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slack_sdk import WebClient\n",
    "slack_token = os.environ.get('SLACK_TOKEN')\n",
    "client = WebClient(token=slack_token)\n",
    "res = client.api_test()\n",
    "if not res[\"ok\"]:\n",
    "    raise ValueError(f\"Error initializing Slack API: {res['error']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd53304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_nodes(nodes):\n",
    "    docs_ids = set()\n",
    "    unique_nodes = list()\n",
    "    for node in nodes:\n",
    "        if node.node.ref_doc_id not in docs_ids:\n",
    "            docs_ids.add(node.node.ref_doc_id)\n",
    "            unique_nodes.append(node)\n",
    "    return unique_nodes\n",
    "        \n",
    "def get_message_link(channel, ts):\n",
    "    res = client.chat_getPermalink(channel=channel, message_ts=ts)\n",
    "    if res['ok']:\n",
    "        return res['permalink']\n",
    "\n",
    "def print_response(response, node_text=False):\n",
    "    print(response.response)    \n",
    "    for node in get_unique_nodes(response.source_nodes):\n",
    "        channel_id = node.node.extra_info['channel']\n",
    "        ts = node.node.extra_info['ts']\n",
    "        print(get_message_link(channel_id, ts))\n",
    "        if node_text:\n",
    "            print(node.node.text)\n",
    "        \n",
    "def query(question, n=5, node_text=False):   \n",
    "    query_engine = index.as_query_engine(similarity_top_k=n)\n",
    "    res = query_engine.query(question)\n",
    "    print_response(res, node_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d748b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.retrievers import VectorIndexRetriever\n",
    "from llama_index.vector_stores.types import VectorStoreQueryMode\n",
    "from llama_index.legacy import ResponseSynthesizer\n",
    "from llama_index.query_engine import RetrieverQueryEngine\n",
    "\n",
    "# configure retriever\n",
    "retriever = VectorIndexRetriever(\n",
    "    index,\n",
    "    similarity_top_k=3,\n",
    "    vector_store_query_mode=VectorStoreQueryMode.HYBRID,\n",
    "    alpha=0.8,\n",
    ")\n",
    "\n",
    "# configure response synthesizer\n",
    "synth = ResponseSynthesizer.from_args()\n",
    "\n",
    "# construct query engine\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    response_synthesizer=synth,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2278b5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "query(\"Should you limit your cluster jobs or submit everything at once?\", node_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46d305b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query(\"What are some interesting software packages that people are using?\", node_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0388197a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
