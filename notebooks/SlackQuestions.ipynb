{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808c72bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import glob\n",
    "import os \n",
    "\n",
    "data_path = \"../data/slack/slack_export_Janelia-Software_30days\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c788af75",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2username = {}\n",
    "id2realname = {}\n",
    "\n",
    "with open(f\"{data_path}/users.json\", 'r') as f:\n",
    "    users = json.load(f)\n",
    "    for user in users:\n",
    "        id = user['id']\n",
    "        id2username[id] = user['name']\n",
    "        id2realname[id] = user['profile']['real_name']\n",
    "\n",
    "print(f\"{len(id2username)} users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee09b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel2id = {}\n",
    "with open(f\"{data_path}/channels.json\", 'r') as f:\n",
    "    channels = json.load(f)\n",
    "\n",
    "    for channel in channels:\n",
    "        print(f\"{channel['id']} {channel['name']}\")\n",
    "        channel2id[channel['name']] = channel['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa25f150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "msg = \"Well, this is a sentence. And the U.S. is a country. But is this a question? What about if I mention the U.S.?\"\n",
    "nltk.tokenize.sent_tokenize(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d540bf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from decimal import *\n",
    "from nltk import tokenize\n",
    "\n",
    "ignored_subtypes = set(['channel_join','channel_leave'])\n",
    "\n",
    "def fix_text(text):\n",
    "    text = re.sub(\"&lt;\", \"<\", text)\n",
    "    text = re.sub(\"&gt;\", \">\", text)\n",
    "    text = re.sub(\"\\n+\", \"\\n\", text)\n",
    "    return text\n",
    "\n",
    "def get(element, key):\n",
    "    if element and key in element:\n",
    "        return element[key]\n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_text(elements):\n",
    "    text = ''\n",
    "    for element in elements:\n",
    "        if 'elements' in element:\n",
    "            text += extract_text(element['elements'])\n",
    "        el_type = get(element, 'type')\n",
    "        if el_type == 'text':\n",
    "            if get(get(element, 'style'), 'code'): text += '`'\n",
    "            text += element['text']\n",
    "            if get(get(element, 'style'), 'code'): text += '`'\n",
    "        elif el_type == 'link':\n",
    "            text += get(element, 'url')\n",
    "        elif el_type == 'rich_text_preformatted':\n",
    "            text += \"\\n\"\n",
    "        elif el_type == 'user':\n",
    "            user_id = element['user_id']\n",
    "            try:\n",
    "                text += id2realname[user_id]\n",
    "            except KeyError:\n",
    "                #print(f\"ERROR: no such user {user_id}\")\n",
    "                text += user_id\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def parse_message(message):\n",
    "    if get(message, 'type') == 'message':\n",
    "        if 'subtype' in message and get(message, 'subtype') in ignored_subtypes:\n",
    "            pass\n",
    "        else:\n",
    "            ts = message['ts']\n",
    "            thread_ts = get(message, 'thread_ts') or ts\n",
    "            msg_user = message['user']\n",
    "            try:\n",
    "                realname = id2realname[msg_user]\n",
    "            except KeyError:\n",
    "                realname = message['user_profile']['display_name']\n",
    "                \n",
    "            if 'blocks' in message:\n",
    "                text = extract_text(message['blocks'])\n",
    "            else:\n",
    "                text = message['text']\n",
    "            \n",
    "            text_msg = re.sub(\"<@(.*?)>\", lambda m: id2realname[m.group(1)], text)\n",
    "            text_msg = fix_text(text_msg)\n",
    "\n",
    "            text_msg = f\"{realname} said: {text_msg}\\n\"\n",
    "            return text_msg\n",
    "            \n",
    "def parse_questions(msg):\n",
    "    questions = []\n",
    "    for sentence in tokenize.sent_tokenize(msg):\n",
    "        if sentence[-1] == \"?\":\n",
    "            questions.append(sentence)\n",
    "    return questions\n",
    "    \n",
    "\n",
    "def parse_channel(channel_name):\n",
    "    channel_id = channel2id[channel_name]\n",
    "    messages = {}\n",
    "    for messages_file in glob.glob(f\"{data_path}/{channel_name}/*.json\"):\n",
    "        with open(messages_file, 'r') as f:\n",
    "            for message in json.load(f):\n",
    "                msg = parse_message(message)\n",
    "                qs = parse_questions(msg)\n",
    "                for q in qs:\n",
    "                    print(q)\n",
    "\n",
    "    return documents\n",
    "\n",
    "documents = []\n",
    "for channel_name in channel2id.keys():\n",
    "    for doc in parse_channel(channel_name):\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d884d46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b6c6e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
