{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2690737a",
   "metadata": {},
   "source": [
    "Purpose: Turn text-data into data with appropriate values neccessary for functional RAGAS evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe365bb",
   "metadata": {},
   "source": [
    "Fetch documents (from only the SciComp wiki as of now) and put into accessable format for generation of expected outputs and creation of context later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "097ef27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"WEB LOADER\"\"\"\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "import bs4 as bs\n",
    "import html2text\n",
    "from llama_index.core import Document\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "data_path = '../data/janelia.org'  # Use './' to indicate the current directory\n",
    "text_maker = html2text.HTML2Text()\n",
    "text_maker.ignore_links = True\n",
    "text_maker.images_to_alt = True\n",
    "text_maker.single_line_break = True\n",
    "text_maker.ignore_emphasis = True\n",
    "SOURCE = \"Web\"\n",
    "\n",
    "\n",
    "def webpage_to_text(soup):\n",
    "    \"\"\" Convert a generic web page to searchable text\n",
    "    \"\"\"\n",
    "    title = soup.title.text\n",
    "    text = text_maker.handle(str(soup))\n",
    "    return title,text\n",
    "\n",
    "\n",
    "def janelia_org_to_text(soup):\n",
    "    \"\"\" Convert a janelia.org page to searchable text\n",
    "    \"\"\"\n",
    "    title = soup.title.text.replace(\" | Janelia Research Campus\",\"\")\n",
    "    content_sections = soup.find_all(\"section\", class_=\"content-section\")\n",
    "    if not content_sections:\n",
    "        return title,None\n",
    "    if len(content_sections) > 1:\n",
    "        raise Exception(\"More than one content section\")\n",
    "    content = content_sections[0]\n",
    "    # Remove useless content\n",
    "    for div in content.find_all(\"div\", {'class':['panels-ipe-label','secondary_menu']}):\n",
    "        div.decompose()\n",
    "    # Html2text smashes text together if only tags separate it\n",
    "    # This fix not only adds the spacing but also adds a separator for nav buttons\n",
    "    for span in content.find_all(\"span\", {'class':'button-wrapper'}):\n",
    "        sep = bs.NavigableString(\" / \")\n",
    "        span.insert(0, sep)\n",
    "    text = text_maker.handle(str(content))\n",
    "    return title,text\n",
    "\n",
    "\n",
    "def html_to_text(link, body):\n",
    "    \"\"\" Convert a web page to plain text for use as a GPT prompt.\n",
    "    \"\"\"\n",
    "    soup = bs.BeautifulSoup(body,'lxml')\n",
    "    if \"janelia.org\" in link:\n",
    "        title,text = janelia_org_to_text(soup)\n",
    "    else:\n",
    "        title,text = webpage_to_text(soup)\n",
    "    return title,text\n",
    "\n",
    "\n",
    "class WebSiteLoader():\n",
    "\n",
    "    def __init__(self, data_path):\n",
    "        self.data_path = data_path\n",
    "\n",
    "    def create_document(self, name, title, link, doc_text):\n",
    "        metadata = {\"source\": self.data_path, \"title\": title, \"link\": link}\n",
    "        # Debugging: Print doc_text to ensure it's not empty\n",
    "        return [Document(page_content=doc_text, metadata=metadata)]\n",
    "    \n",
    "    def load_all_documents(self):\n",
    "        documents = []\n",
    "        for root, dirs, files in os.walk(self.data_path):\n",
    "            for name in files:\n",
    "                filepath = os.path.join(root, name)\n",
    "                with open(filepath) as f:\n",
    "                    link = f.readline().strip()\n",
    "                    body = f.read()\n",
    "                    title, text = html_to_text(link, body)\n",
    "                    \n",
    "                    \n",
    "                    # print(f\"Title: {title}\")\n",
    "                    # print(f\"Text: {text}\")\n",
    "                    if text:\n",
    "                        final_text = title + \"\\n\" + text\n",
    "                        with open('tempTestGen.txt', 'w') as file:\n",
    "                            file.write(final_text)\n",
    "                        loader = TextLoader(\"./tempTestGen.txt\")\n",
    "                        doc = loader.load()\n",
    "                        documents.append(doc)\n",
    "        return documents\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Open output.txt in write mode\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31d58422",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ARCHIVED WIKI LOADRER\"\"\"\n",
    "import argparse\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import logging\n",
    "import warnings\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "import html2text\n",
    "from llama_index.core import Document\n",
    "\n",
    "warnings.simplefilter(\"ignore\", ResourceWarning)\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Constants\n",
    "SOURCE = \"Wiki\"\n",
    "\n",
    "text_maker = html2text.HTML2Text()\n",
    "text_maker.ignore_links = True\n",
    "text_maker.ignore_images = True\n",
    "\n",
    "\n",
    "def wiki_to_text(ancestors, title, authors, labels, body):\n",
    "    \"\"\" Convert a wiki document to plain text for use as a GPT prompt.\n",
    "    \"\"\"\n",
    "    body_text = text_maker.handle(body)\n",
    "    text =  f\"Title: {title}\\n\"\n",
    "    if authors: text += f\"Authors: {authors}\\n\" \n",
    "    if ancestors: text += f\"Ancestors: {ancestors}\\n\" \n",
    "    if labels: text += f\"Labels: {ancestors}\\n\"\n",
    "    text += f\"{body_text}\"\n",
    "    return text\n",
    "\n",
    "\n",
    "class WikiLoader():\n",
    "\n",
    "    def __init__(self, data_path):\n",
    "        self.data_path = data_path\n",
    "\n",
    "    def create_document(self, name, title, link, doc_text):\n",
    "        metadata = {\"source\": self.data_path, \"title\": title, \"link\": link}\n",
    "        return [Document(page_content=doc_text, metadata=metadata)]\n",
    "\n",
    "    def load_all_documents(self):\n",
    "        documents = []\n",
    "        for root, dirs, files in os.walk(self.data_path):\n",
    "            for name in files:\n",
    "                filepath = os.path.join(root, name)\n",
    "                with open(filepath) as f:\n",
    "                    link = f.readline().rstrip()\n",
    "                    ancestors = f.readline().rstrip()\n",
    "                    title = f.readline().rstrip()\n",
    "                    authors = f.readline().rstrip()\n",
    "                    labels = f.readline().rstrip()\n",
    "                    body = re.sub('[\\n]+', '\\n', \"\".join(f.readlines()))\n",
    "                    text = wiki_to_text(ancestors, title, authors, labels, body)\n",
    "                    # doc = self.create_document(name, title, link, text)\n",
    "                    # documents.append(doc)\n",
    "                    if text:\n",
    "                        final_text = title + \"\\n\" + text\n",
    "                        with open('tempTestGen.txt', 'w') as file:\n",
    "                            file.write(final_text)\n",
    "                        loader = TextLoader(\"./tempTestGen.txt\")\n",
    "                        doc = loader.load()\n",
    "                        documents.append(doc)\n",
    "        return documents\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d48ebe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ARCHIVED SLACK LOADER\"\"\"\n",
    "import argparse\n",
    "import re\n",
    "import sys\n",
    "import glob\n",
    "import json\n",
    "import logging\n",
    "import warnings\n",
    "from decimal import Decimal\n",
    "\n",
    "from llama_index.core import Document\n",
    "\n",
    "warnings.simplefilter(\"ignore\", ResourceWarning)\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Constants\n",
    "SOURCE = \"Slack\"\n",
    "DOCUMENT_PAUSE_SECS = 300\n",
    "IGNORED_SUBTYPES = set(['channel_join','channel_leave','bot_message'])\n",
    "\n",
    "\n",
    "def get(dictionary, key):\n",
    "    \"\"\" Get the key out of the dictionary, if it exists. If not, return None.\n",
    "    \"\"\"\n",
    "    if dictionary and key in dictionary:\n",
    "        return dictionary[key]\n",
    "    return None\n",
    "\n",
    "\n",
    "def fix_text(text):\n",
    "    \"\"\" Standard transformations on text like squashing multiple newlines.\n",
    "    \"\"\"\n",
    "    text = re.sub(\"\\n+\", \"\\n\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "class ArchivedSlackLoader():\n",
    "\n",
    "    def __init__(self, data_path, debug=False):\n",
    "        self.data_path = data_path\n",
    "        self.id2username = {}\n",
    "        self.id2realname = {}\n",
    "        self.channel2id = {}\n",
    "        self.debug = debug\n",
    "\n",
    "        for user in self.get_users():\n",
    "            id = user['id']\n",
    "            self.id2username[id] = user['name']\n",
    "            self.id2realname[id] = user['profile']['real_name']\n",
    "\n",
    "        logger.info(f\"Loaded {len(self.id2username)} users\")\n",
    "        for channel in self.get_channels():\n",
    "            logger.debug(f\"{channel['id']}: {channel['name']}\")\n",
    "            self.channel2id[channel['name']] = channel['id']\n",
    "        \n",
    "        logger.info(f\"Loaded {len(self.channel2id)} channels\")\n",
    "\n",
    "\n",
    "    def get_users(self):\n",
    "        \"\"\" Generator which returns users from the users.json file.\n",
    "        \"\"\"\n",
    "        with open(f\"{self.data_path}/users.json\", 'r') as f:\n",
    "            users = json.load(f)\n",
    "            for user in users:\n",
    "                yield user\n",
    "\n",
    "\n",
    "    def get_channels(self):\n",
    "        \"\"\" Generator which returns channels from the channels.json file.\n",
    "        \"\"\"\n",
    "        with open(f\"{self.data_path}/channels.json\", 'r') as f:\n",
    "            channels = json.load(f)\n",
    "            for channel in channels:\n",
    "                yield channel\n",
    "\n",
    "\n",
    "    def get_messages(self, channel_name):\n",
    "        \"\"\" Generator which returns messages from the json files in the given channel directory.\n",
    "        \"\"\"\n",
    "        for messages_file in glob.glob(f\"{self.data_path}/{channel_name}/*.json\"):\n",
    "            with open(messages_file, 'r') as f:\n",
    "                for message in json.load(f):\n",
    "                    yield message\n",
    "\n",
    "\n",
    "    def extract_text(self, elements):\n",
    "        \"\"\" Recursively parse an 'elements' structure, \n",
    "            converting user elements to their real names.\n",
    "        \"\"\"\n",
    "        text = ''\n",
    "        for element in elements:\n",
    "            if 'elements' in element:\n",
    "                text += self.extract_text(element['elements'])\n",
    "            el_type = get(element, 'type')\n",
    "            if el_type == 'text':\n",
    "                if get(get(element, 'style'), 'code'): text += '`'\n",
    "                text += element['text']\n",
    "                if get(get(element, 'style'), 'code'): text += '`'\n",
    "            elif el_type == 'link':\n",
    "                text += get(element, 'url')\n",
    "            elif el_type == 'rich_text_preformatted':\n",
    "                text += \"\\n\"\n",
    "            elif el_type == 'user':\n",
    "                user_id = element['user_id']\n",
    "                try:\n",
    "                    text += self.id2realname[user_id]\n",
    "                except KeyError:\n",
    "                    logger.error(f\"No such user '{user_id}'\")\n",
    "                    text += user_id\n",
    "\n",
    "        return text\n",
    "\n",
    "    def parse_message(self, message):\n",
    "        \"\"\" Parse a message into text that will be read by a GPT model. \n",
    "        \"\"\"\n",
    "        thread_id, text_msg = None, None\n",
    "        if get(message, 'type') == 'message':\n",
    "            if 'subtype' in message and get(message, 'subtype') in IGNORED_SUBTYPES:\n",
    "                pass\n",
    "            else:\n",
    "                ts = message['ts']\n",
    "                thread_ts = get(message, 'thread_ts') or ts\n",
    "                thread_id = Decimal(thread_ts)\n",
    "\n",
    "                # Translate user\n",
    "                user_id = message['user']\n",
    "                try:\n",
    "                    realname = self.id2realname[user_id]\n",
    "                except KeyError:\n",
    "                    try:\n",
    "                        realname = message['user_profile']['display_name']\n",
    "                    except KeyError:\n",
    "                        realname = user_id\n",
    "                    \n",
    "                if 'blocks' in message:\n",
    "                    text = self.extract_text(message['blocks'])\n",
    "                else:\n",
    "                    text = message['text']\n",
    "                \n",
    "                text_msg = re.sub(\"<@(.*?)>\", lambda m: self.id2realname[m.group(1)], text)\n",
    "                text_msg = fix_text(text_msg)\n",
    "\n",
    "                if 'attachments' in message:\n",
    "                    for attachment in message['attachments']:\n",
    "                        if 'title' in attachment: text_msg += f\"\\n{fix_text(attachment['title'])}\"\n",
    "                        if 'text' in attachment: text_msg += f\"\\n{fix_text(attachment['text'])}\"\n",
    "                        \n",
    "                if 'files' in message:\n",
    "                    for file in message['files']:\n",
    "                        if 'name' in file:\n",
    "                            # There are several cases where a file doesn't have a name:\n",
    "                            # 1) The file has been deleted (mode=tombstone)\n",
    "                            # 2) We have no access (file_access=access_denied)\n",
    "                            text_msg += f\"\\n<{file['name']}>\"\n",
    "\n",
    "                if 'reactions' in message:\n",
    "                    text_msg += f\"\\nOthers reacted to the previous message with \"\n",
    "                    r = [f\"{reaction['name']} a total of {reaction['count']} times\" for reaction in message['reactions']]\n",
    "                    text_msg += \", and with \".join(r) + \".\"\n",
    "\n",
    "                text_msg = f\"{realname} said: {text_msg}\\n\"\n",
    "        \n",
    "        return thread_id, text_msg\n",
    "\n",
    "\n",
    "    def create_document(self, channel_id, ts, doc_text):\n",
    "        final_text = doc_text\n",
    "        with open('tempTestGen.txt', 'w') as file:\n",
    "            file.write(final_text)\n",
    "        loader = TextLoader(\"./tempTestGen.txt\")\n",
    "        \n",
    "        return loader.load()\n",
    "\n",
    "    def load_documents(self, channel_name):\n",
    "        channel_id = self.channel2id[channel_name]\n",
    "        messages = {}\n",
    "        for message in self.get_messages(channel_name):\n",
    "            try:\n",
    "                thread_id, text_msg = self.parse_message(message)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error parsing message: {message}\")\n",
    "                raise e\n",
    "                \n",
    "            if thread_id and text_msg:\n",
    "                if thread_id not in messages:\n",
    "                    messages[thread_id] = []\n",
    "                messages[thread_id].append(text_msg)\n",
    "\n",
    "        prev_id = Decimal(0)\n",
    "        documents = []\n",
    "        doc_text = \"\"\n",
    "        start_ts = None\n",
    "\n",
    "        for thread_id in sorted(list(messages.keys())):\n",
    "\n",
    "            # Create a new document whenever messages are separated by a longer pause\n",
    "            if doc_text and thread_id-prev_id > DOCUMENT_PAUSE_SECS:\n",
    "                doc = self.create_document(channel_id, start_ts, doc_text)\n",
    "                documents.append(doc)\n",
    "                doc_text = \"\"\n",
    "                start_ts = None\n",
    "\n",
    "            logger.debug(thread_id)\n",
    "\n",
    "            # Starting timestamp for the next document\n",
    "            if not start_ts:\n",
    "                start_ts = str(thread_id)\n",
    "\n",
    "            # Add all messages from the current thread\n",
    "            for text_msg in messages[thread_id]:\n",
    "                doc_text += text_msg\n",
    "\n",
    "            prev_id = thread_id\n",
    "\n",
    "        # Add final document\n",
    "        doc = self.create_document(channel_id, start_ts, doc_text)\n",
    "        documents.append(doc)\n",
    "\n",
    "        return documents\n",
    "\n",
    "\n",
    "    def load_all_documents(self):\n",
    "        documents = []\n",
    "        for channel_name in self.channel2id.keys():\n",
    "            for doc in self.load_documents(channel_name):\n",
    "                documents.append(doc)\n",
    "        return documents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e912570b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loaded 170 users\n",
      "INFO:__main__:Loaded 44 channels\n",
      "ERROR:__main__:No such user 'WAPC2SXJN'\n",
      "ERROR:__main__:No such user 'W8C6WFVM4'\n",
      "ERROR:__main__:No such user 'W9GJ4UF33'\n",
      "ERROR:__main__:No such user 'W0129A3DR8B'\n",
      "ERROR:__main__:No such user 'WBHHEM2AU'\n",
      "ERROR:__main__:No such user 'W010W8A1EBF'\n",
      "ERROR:__main__:No such user 'W010W8A1EBF'\n",
      "ERROR:__main__:No such user 'W010W8A1EBF'\n",
      "ERROR:__main__:No such user 'WA7Q7CKGS'\n",
      "ERROR:__main__:No such user 'U02QZ8GH64X'\n",
      "ERROR:__main__:No such user 'W013JPYQ5PA'\n",
      "ERROR:__main__:No such user 'W013JPYQ5PA'\n",
      "ERROR:__main__:No such user 'WD5FSBZTJ'\n",
      "ERROR:__main__:No such user 'W010W8A1EBF'\n",
      "ERROR:__main__:No such user 'UMVJ4KRV2'\n",
      "ERROR:__main__:No such user 'U03PL1HLZBP'\n",
      "ERROR:__main__:No such user 'U040HM3D0TU'\n",
      "ERROR:__main__:No such user 'UN7R87EUE'\n",
      "ERROR:__main__:No such user 'U040HM3D0TU'\n",
      "ERROR:__main__:No such user 'U028YV8LZUP'\n",
      "ERROR:__main__:No such user 'UN7R87EUE'\n",
      "ERROR:__main__:No such user 'UN7R87EUE'\n",
      "ERROR:__main__:No such user 'UN7R87EUE'\n",
      "ERROR:__main__:No such user 'UN7R87EUE'\n",
      "ERROR:__main__:No such user 'UNZ3K8W5R'\n",
      "ERROR:__main__:No such user 'U019XPGTGRL'\n",
      "ERROR:__main__:No such user 'UNZ3K8W5R'\n",
      "ERROR:__main__:No such user 'UNZ3K8W5R'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UV8CP1F2N'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U019XPGTGRL'\n",
      "ERROR:__main__:No such user 'UGF6L2YUS'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U0182GKL7QR'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UGF6L2YUS'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'UH5AYU4JD'\n",
      "ERROR:__main__:No such user 'UNZ3K8W5R'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UV8CP1F2N'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'UV8CP1F2N'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UV8CP1F2N'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U019XPGTGRL'\n",
      "ERROR:__main__:No such user 'UNZ3K8W5R'\n",
      "ERROR:__main__:No such user 'U019XPGTGRL'\n",
      "ERROR:__main__:No such user 'UNZ3K8W5R'\n",
      "ERROR:__main__:No such user 'U019XPGTGRL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UV8CP1F2N'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'UV8CP1F2N'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U04PR67HG3B'\n",
      "ERROR:__main__:No such user 'UNZ3K8W5R'\n",
      "ERROR:__main__:No such user 'UFJ8DBDC3'\n",
      "ERROR:__main__:No such user 'U04PR67UZ4H'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UGF6L2YUS'\n",
      "ERROR:__main__:No such user 'U019XPGTGRL'\n",
      "ERROR:__main__:No such user 'U04PR67HG3B'\n",
      "ERROR:__main__:No such user 'U0182GKL7QR'\n",
      "ERROR:__main__:No such user 'U04PR67HG3B'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UDM220J2W'\n",
      "ERROR:__main__:No such user 'UV8CP1F2N'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UV8CP1F2N'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UV8CP1F2N'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'U04PR67UZ4H'\n",
      "ERROR:__main__:No such user 'U04PR67UZ4H'\n",
      "ERROR:__main__:No such user 'U04PR67HG3B'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U4T03270V'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U4T03270V'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'UH5AYU4JD'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'UNZ3K8W5R'\n",
      "ERROR:__main__:No such user 'UNZ3K8W5R'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UNZ3K8W5R'\n",
      "ERROR:__main__:No such user 'U019XPGTGRL'\n",
      "ERROR:__main__:No such user 'UGF6L2YUS'\n",
      "ERROR:__main__:No such user 'U019XPGTGRL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UH5AYU4JD'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'U04PR67UZ4H'\n",
      "ERROR:__main__:No such user 'UH5AYU4JD'\n",
      "ERROR:__main__:No such user 'UNZ3K8W5R'\n",
      "ERROR:__main__:No such user 'U04PR67UZ4H'\n",
      "ERROR:__main__:No such user 'U04PR67HG3B'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UV8CP1F2N'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'UV8CP1F2N'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'UV8CP1F2N'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UV8CP1F2N'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UV8CP1F2N'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UV8CP1F2N'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UV8CP1F2N'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UV8CP1F2N'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U016WBXDARX'\n",
      "ERROR:__main__:No such user 'U029QJUSZFB'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U029QJUSZFB'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U04PR67UZ4H'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UV8CP1F2N'\n",
      "ERROR:__main__:No such user 'U029QJUSZFB'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'UAXU10MLL'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n",
      "ERROR:__main__:No such user 'U0JER9YUX'\n",
      "ERROR:__main__:No such user 'U029DL61X5L'\n"
     ]
    }
   ],
   "source": [
    "\"\"\"DOCUMENT LOADER ALL SOURCES\"\"\"\n",
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "# generator with openai models\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.llms import Ollama\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "import os\n",
    "\n",
    "# DONE: Recursively load all scraped files in the directory and its subdirectories\n",
    "# loader = TextLoader(\"./test.txt\")\n",
    "# documents = loader.load()\n",
    "# print(documents)\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import mimetypes\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\"\"\"ArchivedSlackLoader\n",
    "slack_to_2023-05-18\n",
    "\n",
    "\"\"\"\n",
    "import random\n",
    "\n",
    "class DocumentLoader:\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "\n",
    "    def load_documents(self):\n",
    "        all_documents = []\n",
    "        for folder_name in os.listdir(self.root_dir):\n",
    "            folder_path = os.path.join(self.root_dir, folder_name)\n",
    "            if os.path.isdir(folder_path):\n",
    "                if folder_name == \"wiki\":\n",
    "                    loader = WikiLoader(folder_path)\n",
    "                elif folder_name == \"slack\":\n",
    "                    # Specify the two subdirectories for slack\n",
    "                    subdirs = [\"janelia-software/slack_to_2023-05-18\"]\n",
    "                    for subdir in subdirs:\n",
    "                        subfolder_path = os.path.join(folder_path, subdir)\n",
    "                        # Check if the subdirectory exists\n",
    "                        if os.path.isdir(subfolder_path):\n",
    "                            loader = ArchivedSlackLoader(subfolder_path)\n",
    "                            documents = loader.load_all_documents()\n",
    "                            # Take a random 10% sample\n",
    "                            # sample_size = max(1, len(documents) // 10)\n",
    "                            # documents_sample = random.sample(documents, sample_size)\n",
    "                            # all_documents.extend(documents_sample)\n",
    "                            all_documents.extend(documents)\n",
    "                elif folder_name == \"janelia.com\":\n",
    "                    loader = WebSiteLoader(folder_path)\n",
    "                else:\n",
    "                    continue  # Skip if folder doesn't match any criteria\n",
    "                # For non-slack directories\n",
    "                if folder_name != \"slack\":\n",
    "                    documents = loader.load_all_documents()\n",
    "                    # Take a random 10% sample\n",
    "                    # sample_size = max(1, len(documents) // 10)\n",
    "                    # documents_sample = random.sample(documents, sample_size)\n",
    "                    # all_documents.extend(documents_sample)\n",
    "                    all_documents.extend(documents)\n",
    "        return all_documents\n",
    "    \n",
    "    def test_load_documents(self):\n",
    "        # This method is for testing purposes and will only load the first document in each folder path\n",
    "        all_documents = []\n",
    "        for folder_name in os.listdir(self.root_dir):\n",
    "            folder_path = os.path.join(self.root_dir, folder_name)\n",
    "            if os.path.isdir(folder_path):\n",
    "                if folder_name == \"wiki\":\n",
    "                    loader = WikiLoader(folder_path)\n",
    "                elif folder_name == \"slack\":\n",
    "                    # Specify the two subdirectories for slack\n",
    "                    subdirs = [\"janelia-software/slack_to_2023-05-18\"]\n",
    "                    for subdir in subdirs:\n",
    "                        subfolder_path = os.path.join(folder_path, subdir)\n",
    "                        # Check if the subdirectory exists\n",
    "                        if os.path.isdir(subfolder_path):\n",
    "                            loader = ArchivedSlackLoader(subfolder_path)\n",
    "                            documents = loader.load_all_documents()\n",
    "                            # Only load the first document for testing\n",
    "                            if documents:\n",
    "                                all_documents.append(documents[0])\n",
    "                elif folder_name == \"janelia.com\":\n",
    "                    loader = WebSiteLoader(folder_path)\n",
    "                else:\n",
    "                    continue  # Skip if folder doesn't match any criteria\n",
    "                # For non-slack directories\n",
    "                if folder_name != \"slack\":\n",
    "                    documents = loader.load_all_documents()\n",
    "                    # Only load the first document for testing\n",
    "                    if documents:\n",
    "                        all_documents.append(documents[0])\n",
    "        return all_documents\n",
    "\n",
    "# Assuming your data folder is at \"./data/\"\n",
    "loader = DocumentLoader(\"../data\")\n",
    "documents = loader.test_load_documents()\n",
    "with open('documents.txt', 'w') as file:\n",
    "    for document in documents:\n",
    "        file.write(str(document) + '\\n')\n",
    "# # Assuming documents is a list of strings or convertible to string\n",
    "\n",
    "\n",
    "# Now `final_df` contains all the generated testsets in one DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0b4bc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:ragas.testset.docstore:Document [ID: 8f49cbbb-a463-47c6-ac94-1cb45252d24c] has no filename, using `doc_id` instead\n",
      "INFO:ragas.testset.docstore:Document [ID: 8f49cbbb-a463-47c6-ac94-1cb45252d24c] has no filename, using `doc_id` instead\n",
      "WARNING:ragas.testset.docstore:Filename and doc_id are the same for all nodes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Generating:   0%|          | 0/10 [00:21<?, ?it/s]Exception ignored in: <generator object tqdm.__iter__ at 0x30c557520>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/tqdm/std.py\", line 1196, in __iter__\n",
      "    self.close()\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/tqdm/std.py\", line 1302, in close\n",
      "    self.display(pos=0)\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/tqdm/std.py\", line 1495, in display\n",
      "    self.sp(self.__str__() if msg is None else msg)\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/tqdm/std.py\", line 459, in print_status\n",
      "    fp_write('\\r' + s + (' ' * max(last_len[0] - len_s, 0)))\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/tqdm/std.py\", line 453, in fp_write\n",
      "    fp_flush()\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/tqdm/utils.py\", line 196, in inner\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ipykernel/iostream.py\", line 604, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/zmq/sugar/socket.py\", line 701, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"_zmq.py\", line 1073, in zmq.backend.cython._zmq.Socket.send\n",
      "  File \"_zmq.py\", line 1115, in zmq.backend.cython._zmq.Socket.send\n",
      "  File \"_zmq.py\", line 1190, in zmq.backend.cython._zmq._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Exception ignored in sys.unraisablehook: <built-in function unraisablehook>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ipykernel/iostream.py\", line 604, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/zmq/sugar/socket.py\", line 701, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"_zmq.py\", line 1073, in zmq.backend.cython._zmq.Socket.send\n",
      "  File \"_zmq.py\", line 1115, in zmq.backend.cython._zmq.Socket.send\n",
      "  File \"_zmq.py\", line 1190, in zmq.backend.cython._zmq._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Exception in thread Thread-63:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/logging/__init__.py\", line 1163, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ipykernel/iostream.py\", line 694, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ipykernel/iostream.py\", line 590, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/zmq/sugar/socket.py\", line 701, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"_zmq.py\", line 1073, in zmq.backend.cython._zmq.Socket.send\n",
      "  File \"_zmq.py\", line 1115, in zmq.backend.cython._zmq.Socket.send\n",
      "  File \"_zmq.py\", line 1190, in zmq.backend.cython._zmq._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/executor.py\", line 95, in run\n",
      "    results = self.loop.run_until_complete(self._aresults())\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 687, in run_until_complete\n",
      "    return future.result()\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/executor.py\", line 83, in _aresults\n",
      "    raise e\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/executor.py\", line 78, in _aresults\n",
      "    r = await future\n",
      "        ^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py\", line 631, in _wait_for_one\n",
      "    return f.result()  # May raise f.exception().\n",
      "           ^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "           ^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/executor.py\", line 111, in wrapped_callable_async\n",
      "    return counter, await callable(*args, **kwargs)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/testset/evolutions.py\", line 142, in evolve\n",
      "    ) = await self._aevolve(current_tries, current_nodes)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/testset/evolutions.py\", line 466, in _aevolve\n",
      "    simple_question, current_nodes, _ = await self.se._aevolve(\n",
      "                                        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/testset/evolutions.py\", line 311, in _aevolve\n",
      "    logger.info(\"seed question generated: %s\", seed_question)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/logging/__init__.py\", line 1539, in info\n",
      "    self._log(INFO, msg, args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/logging/__init__.py\", line 1684, in _log\n",
      "    self.handle(record)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/logging/__init__.py\", line 1700, in handle\n",
      "    self.callHandlers(record)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/logging/__init__.py\", line 1762, in callHandlers\n",
      "    hdlr.handle(record)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/logging/__init__.py\", line 1028, in handle\n",
      "    self.emit(record)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/logging/__init__.py\", line 1168, in emit\n",
      "    self.handleError(record)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/logging/__init__.py\", line 1081, in handleError\n",
      "    sys.stderr.write('--- Logging error ---\\n')\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ipykernel/iostream.py\", line 694, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ipykernel/iostream.py\", line 590, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/zmq/sugar/socket.py\", line 701, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"_zmq.py\", line 1073, in zmq.backend.cython._zmq.Socket.send\n",
      "  File \"_zmq.py\", line 1115, in zmq.backend.cython._zmq.Socket.send\n",
      "  File \"_zmq.py\", line 1190, in zmq.backend.cython._zmq._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Exception in threading.excepthook:\n",
      "Exception ignored in thread started by: <bound method Thread._bootstrap of <Runner(Thread-63, stopped 13665710080)>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/threading.py\", line 1030, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self._invoke_excepthook(self)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/threading.py\", line 1389, in invoke_excepthook\n",
      "    local_print(\"Exception in threading.excepthook:\",\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ipykernel/iostream.py\", line 604, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/zmq/sugar/socket.py\", line 701, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"_zmq.py\", line 1073, in zmq.backend.cython._zmq.Socket.send\n",
      "  File \"_zmq.py\", line 1115, in zmq.backend.cython._zmq.Socket.send\n",
      "  File \"_zmq.py\", line 1190, in zmq.backend.cython._zmq._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Exception ignored in sys.unraisablehook: <built-in function unraisablehook>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ipykernel/iostream.py\", line 604, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/zmq/sugar/socket.py\", line 701, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"_zmq.py\", line 1073, in zmq.backend.cython._zmq.Socket.send\n",
      "  File \"_zmq.py\", line 1115, in zmq.backend.cython._zmq.Socket.send\n",
      "  File \"_zmq.py\", line 1190, in zmq.backend.cython._zmq._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:ragas.testset.evolutions:seed question generated: What is the purpose of running JACS containers on the Scientific Computing Server - e03u07?\n",
      "INFO:ragas.testset.evolutions:seed question generated: Here is a question that can be fully answered from the given context:\n",
      "\n",
      "\"What is the purpose of the Scientific Computing Server - e03u07?\"\n",
      "\n",
      "This question can be answered by reading the \"Purpose\" section of the context, which states: \"Runs the production services for the Janelia Workstation using Docker Swarm. This is the master server.\"\n",
      "INFO:ragas.testset.evolutions:seed question generated: Here is a question that can be fully answered from the given context:\n",
      "\n",
      "\"What is the purpose of installing and configuring s3fs on the Scientific Computing Server?\"\n",
      "\n",
      "This question can be answered by referring to the \"Purpose\" section, which states that the server runs production services for the Janelia Workstation using Docker Swarm. Additionally, the \"Software\" section mentions that s3fs is used for mounting AWS S3 buckets.\n",
      "INFO:ragas.testset.evolutions:seed question generated: Here is a question that can be fully answered from the given context:\n",
      "\n",
      "\"What is the purpose of installing and configuring s3fs on the Scientific Computing Server?\"\n",
      "\n",
      "This question can be answered by referring to the \"Purpose\" section, which states that the server runs production services for the Janelia Workstation using Docker Swarm. Additionally, the \"Software\" section mentions that s3fs is used for mounting AWS S3 buckets.\n",
      "INFO:ragas.testset.evolutions:seed question generated: Here is a question that can be fully answered from the given context:\n",
      "\n",
      "\"What is the purpose of the Scientific Computing Server, e03u07?\"\n",
      "\n",
      "This question can be answered by reading the \"Purpose\" section of the context, which states that the server \"Runs the production services for the Janelia Workstation using Docker Swarm. This is the master server.\"\n",
      "INFO:ragas.testset.evolutions:retrying evolution: 1 times\n",
      "INFO:ragas.testset.evolutions:seed question generated: Here's a question that can be fully answered from the given context:\n",
      "\n",
      "\"What is an alternative to Numba mentioned in this conversation?\"\n",
      "\n",
      "This question can be answered by referencing the message where Cameron Arshadi says \"nice, seems like a good alternative to numba\" and linking it to the inducer/pyopencl library.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:ragas.testset.evolutions:retrying evolution: 2 times\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:ragas.testset.evolutions:rewritten question: Here is the rewritten question:\n",
      "\n",
      "\"What service does s3fs enable for mounting on the Scientific Computing Server, given its purpose of running production services using Docker Swarm?\"\n",
      "\n",
      "This question requires the reader to make multiple logical connections and inferences. They need to understand that the server runs production services using Docker Swarm (from the \"Purpose\" section) and that s3fs is used for mounting AWS S3 buckets (from the \"Software\" section). The reader then needs to infer that s3fs enables the mounting of these buckets on the Scientific Computing Server, which is the master server.\n",
      "INFO:ragas.testset.evolutions:seed question generated: Here's a question that can be fully answered from the given context:\n",
      "\n",
      "\"What is an alternative approach to NumPy-compatible matrix library accelerated by CUDA, as mentioned in the scicomp virtual happy hour?\"\n",
      "\n",
      "This question uses the keyphrase \"GPU-accelerated array computing\" and can be answered based on the provided context.\n",
      "INFO:ragas.testset.evolutions:retrying evolution: 1 times\n",
      "INFO:ragas.testset.evolutions:retrying evolution: 3 times\n",
      "INFO:ragas.testset.evolutions:seed question generated: Here's a question that can be fully answered from the given context:\n",
      "\n",
      "\"What is an alternative to Numba mentioned in this conversation?\"\n",
      "\n",
      "This question can be answered by referencing the message where Cameron Arshadi says \"nice, seems like a good alternative to numba\" and linking it to the inducer/pyopencl library.\n",
      "INFO:ragas.testset.evolutions:seed question generated: Here's a question that can be fully answered from the given context:\n",
      "\n",
      "\"What is an alternative approach to NumPy-compatible matrix library accelerated by CUDA, as mentioned in the scicomp virtual happy hour?\"\n",
      "\n",
      "This question uses the keyphrase \"GPU-accelerated array computing\" and can be answered based on the provided context.\n",
      "INFO:ragas.testset.evolutions:retrying evolution: 4 times\n",
      "INFO:ragas.testset.evolutions:seed question generated: Here's a question that can be fully answered from the given context:\n",
      "\n",
      "\"What is an alternative to Numba mentioned in this conversation?\"\n",
      "\n",
      "This question can be answered by referencing the message where Cameron Arshadi says \"nice, seems like a good alternative to numba\" and linking it to the inducer/pyopencl library.\n",
      "INFO:ragas.testset.evolutions:retrying evolution: 5 times\n",
      "INFO:ragas.testset.evolutions:retrying evolution: 2 times\n",
      "INFO:ragas.testset.evolutions:seed question generated: Here's a question that can be fully answered from the given context:\n",
      "\n",
      "\"What is CuPy, and how does it differ from other libraries like Numba?\"\n",
      "\n",
      "This question can be answered by referencing the provided context, which mentions that CuPy is \"NumPy-compatible matrix library accelerated by CUDA\" and that Davis Bennett mentioned it as an alternative to Numba.\n",
      "INFO:ragas.testset.evolutions:retrying evolution: 6 times\n",
      "WARNING:ragas.executor:max retries exceeded for MultiContextEvolution(generator_llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=15, max_wait=90, max_workers=16, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), docstore=InMemoryDocumentStore(splitter=<langchain_text_splitters.base.TokenTextSplitter object at 0x30be93bc0>, nodes=[Node(page_content=\"Davis Bennett said: to inaugurate this channel -- GPU-accelerated array computing came up in the scicomp virtual happy hour yesterday. Here's the library I was talking about (CuPy): https://cupy.chainer.org/\\nCuPy\\nCuPy is NumPy-compatible matrix library accelerated by CUDA\\nDavis Bennett said: a lower-level vendor-agnostic approach using OpenCL is here: https://github.com/inducer/pyopencl\\ninducer/pyopencl\\nOpenCL integration for Python, plus shiny features - inducer/pyopencl\\nCameron Arshadi said: nice, seems like a good alternative to numba\\nDavis Bennett said: yeah I'm not sure how a cuda kernel jitted with numba will compare in performance to the same operation on a cupy array\\nOthers reacted to the previous message with +1::skin-tone-3 a total of 1 times.\\n\", metadata={'source': './tempTestGen.txt'}, doc_id='ddaf50de-f60d-4ecd-bde7-cfe98cdf2955', wins=32)], node_embeddings_list=[[-0.01725480024039584, -0.004083251731097058, 0.02810026250043858, -0.030390340092342476, 0.0032640808533688052, 0.00967161765579621, 0.01906957733882603, -0.019602489448888906, -0.03214750557418349, -0.031801832149358035, 0.03347258393160573, 0.022583910165153286, 0.0008254722065003568, 0.0030894443600142938, -0.005786407020877686, 0.009167512285350529, 0.009045087134437236, -0.0018138783721125605, 0.01931442950329783, 0.010744640999689083, -0.04004035292625644, 0.011205537657692886, -0.014338191195810363, -0.005361518554564725, -0.03891691708954152, 0.017830920131577985, 0.01620337985573999, -0.02775458907561312, -0.023260851316689087, -0.0010046095491932341, 0.03373183806890222, 0.007806428530205277, 0.0007372537783138952, -0.009059490038584528, -0.033414968589726125, -0.028373918610559754, 0.003044435168138678, 0.00047529915469745406, 0.033616611110433445, 0.005447936445109785, 0.03969467950143098, -0.00288960278440202, -0.005429932582095017, -0.004698980307176214, 0.0012782665906370138, -0.005880026363496394, 0.023304060960453576, 0.008612996284728018, -0.02815787411702775, 0.010463782971832963, 0.02133084912243534, 0.03594989834610182, -0.022036596082265728, -0.03934900980189596, 0.008533779846256603, -0.0032010677984784216, -0.012278561001585761, 0.01591531991014892, -0.005797209431818808, -0.018032560789640082, 0.005077059102179823, 0.02847473987091341, 0.007370737652951193, 0.043612299231818086, -0.001780571481648957, -0.0069206438715498165, 0.014669459853843313, 0.029310113899392042, 0.025694959812711127, -0.0035935494976293224, 0.01276826346788415, 0.022411075315385772, -0.006686595049341744, -0.029843026009454918, 0.020279430600424708, -0.01852226325593847, -0.016433828184741893, -0.02006338610689271, -0.012696248015825076, 0.01155841113760808, 0.0005635175246762526, -0.019444056571946075, 0.020149803531776464, 0.00795765995507446, -0.002061429975166383, 0.013351585276801244, -0.006236500802279063, 0.01901196572223686, -0.016001737335032674, -0.020653907970899537, 0.007611987927232912, 0.012444195796263541, 0.016347410759858134, 0.007986465763369045, -0.007403144420113254, 0.05867783941537325, -0.0038924118541615164, 0.024081823372343037, -0.017470844733927838, 0.0003492728702936969, -0.007453554584628778, 0.01941525076365149, -0.029987055050927844, -0.026948020855429074, -0.019746518490361832, -0.017110769336277695, -0.006960252090785523, 0.020495475093956706, 0.02140286457449441, 0.03715974974505528, 0.002405301756404845, 0.032377955765830614, -0.03381825363114076, -0.02438428715340401, 0.008029675407133532, -0.028791605624799068, 0.02328965898762889, -0.02449951038658235, -0.015512035800056896, -0.023246449343864405, 0.016664276513743793, 0.025968617785477516, 0.032377955765830614, -0.008879452339759456, 0.025622944360652055, 0.02040905766907295, -0.01548322999176231, -0.018277412954111887, 0.03232034042395101, -0.010679827465364961, 0.025680557839886445, 0.0189111444618832, 0.009815647628591745, 0.015252781662760409, -0.015007930429611214, -0.012091322316348347, 0.007792025626057984, 0.0026285484005024477, -0.02409622720781294, -0.04145184684591722, 0.0031308530586837387, 0.014338191195810363, -0.03252198294465832, 0.017845322104402667, -0.03577706349633431, 0.05896590122360954, 0.006423739953177782, -0.013747667469158316, 0.00481060351280969, -0.007165494639037706, 0.01167363530210903, -0.002219863084939864, -0.027351305896843706, 0.019127190818060417, 0.013279569824742172, 0.008260122804812824, 0.013344383359066294, 0.017773306652343595, -0.021518087807672753, 0.005134671184430299, 0.010089304670035524, -0.009858856341033624, -0.008540981763991555, -0.0006490354083350967, 0.010355759793744354, 0.023865778878811035, 0.043497072273349306, -0.028676382391620726, -0.004576554690601618, -0.001241358974136587, 0.012926696344826977, 0.009138706477055943, -0.03517213593421236, 0.0017355620569426888, 0.006866632282505512, -0.02604063137489137, 0.030591980750404573, -0.0005018547129458457, -0.032954075657012756, -0.005469540801330724, 0.023952196303694794, -0.016016141170502575, 0.00950598286111843, 0.017672487254635154, 0.0037159751142039196, -0.022871971973389575, 0.010276543355272939, 0.003950024169242644, 0.009938072779505038, -0.008159302475781775, 0.02138846073902451, 0.014907109169257556, -0.01183206817905186, -0.03381825363114076, -0.5936342100554578, -0.018147785885463643, -0.02040905766907295, -0.026400706772541516, -0.011536806315725836, 0.019170398599179687, 0.011688038206256324, 0.015569647416646066, -0.00431370006009896, 0.021374058766199827, -0.013236361112300294, 0.009808445710856794, -0.001653644899320668, -0.019703310709242562, -0.003451320004267524, -0.018651890324586713, 0.012235352289143882, -0.029670189297042186, -0.019530473996829834, -0.004565752279660496, -0.025277272798471813, 0.023376076412512648, -0.01924241405123876, 0.02771138129449385, 0.024974809017410837, 0.020797938875017682, 0.02063950599807485, 0.01741323311733867, -0.0005959242918383135, 0.017125173171747596, -0.007720010173998912, 0.010139715300212354, 0.007698405817777972, -0.031024071600113792, 0.0563157482340555, -0.00583321669218704, -0.0035845477989525907, 0.027552948417551022, -0.007856838694720801, 0.03145616244982301, -0.041768712599802874, -0.01924241405123876, 0.01737002347357418, 0.013466809441302196, -0.03162899729959052, 0.01587211026638443, 0.022598314000623187, -0.00796486187280941, -0.00654976606295855, -0.01454703470293002, -0.009707625381825746, -0.0129915098791511, 0.0006985457405873938, 0.0006584873432855891, -0.0013151743235527667, 0.005498347075286614, 0.0184646516393493, -0.028618770775031555, 0.002704164112937039, -0.003755583333439627, -0.00016327156355758858, -0.0067946172961077436, -0.0043605097314083135, -0.035690644208805335, -0.02686160343054532, -0.0005563160726026062, -0.034538404426441044, -0.005710791075612443, -0.005555959157537089, 0.01708196352798311, 0.01371166067445139, -0.018450247803879397, -0.0012719653782802362, -0.014395802812399534, 0.017989353008520812, 0.024859585784232495, 0.03557542097562699, -0.010406170423921182, -0.0015501233854777077, 0.020668311806369438, 0.01088867097248462, -0.0022450684000282785, -0.02791302195255595, -0.008901057161641699, 0.022151821178089285, 0.014186959305279877, -0.02472995871558425, 0.005221089074975359, 0.01354602587977361, -0.021374058766199827, 0.006067265514395112, 0.02516204956529347, -0.02007778807971739, -0.0549618659309839, 0.00414806526542118, 0.02029383257324939, -0.012653039303383198, -0.0036079526346072676, -0.028993248145506384, -0.02111480462890334, -0.008036876393545873, -0.0046521706358668615, -0.008944265874083578, -0.0008817339291755288, 0.00024687651057766526, 0.01614576823915082, -0.0059052316785848085, 0.0051490740885775915, 0.03154257801206155, -0.029338919707686626, -0.03047675751722623, -0.02637190096424693, 0.0071114835156547065, -0.009448371244529259, 0.03508572037197382, -0.0433530450945216, 0.018781517393234956, -0.010154118204359646, -0.020135399696306563, -0.03367422272702261, -0.004889819951281104, -0.025968617785477516, 0.004184072991450716, -0.0059052316785848085, 0.002111840605343212, 0.027797798719377608, 0.032493178999008956, -0.010240536560566012, -0.03816796234859186, -0.005674783815244212, 0.010939081602661448, -0.010377364615626597, 0.020034578435952903, -0.005051853787091409, 0.027783394883907707, -0.005768403157862918, 0.00851217595569697, 0.019055175366001344, -0.007914451242632582, -0.022367865671621287, 0.0036547623059166212, -0.00139529100174105, 0.008324936339136946, 0.002994024537961849, -0.006394934144883196, 0.00583321669218704, -0.025306078606766397, 0.02173413416384997, -0.006517359295796489, 0.0008542781894179314, -0.029929443434338673, 0.01924241405123876, -0.007640793735527497, 0.020509878929426607, -0.006751408118004561, -0.005836817651054515, 0.009390758696617478, -0.02709205175954722, -0.019991370654833637, -0.04413080750641106, -0.012509009330587663, 0.015281587471054995, -0.020999581395724998, 0.015195170046171238, 0.002135245440997889, -0.0150367362379058, -0.015252781662760409, 0.03505691270103402, -0.0021532490711820046, -0.011587216945902666, -0.0008821840490339632, -0.02514764572982357, 0.024744362551054153, 0.02771138129449385, -0.011227141548252521, -0.005109465869341884, -0.005044652335017762, 0.00475659238942669, -0.017053157719688523, -0.0071186849677283524, -0.004788999156588751, 0.013740466482745975, -0.026602349293248832, -0.028604366939561653, 0.04410199983547126, 0.013257965934182537, 0.007597585023085619, 0.007511166666879254, -0.012112927138230591, 0.015368005827261359, 0.0004964535656829479, 0.020898760135371338, -0.03301168727360193, 0.02691921504713449, -0.020985177560255096, -0.0036259562647913833, 0.004090453183170705, 0.006448945268266196, 0.006639784912371086, 0.012545017056617199, 0.0259974235937721, 0.019645697230008172, 0.023937794330870107, -0.015281587471054995, 0.0033270941410898417, -0.03537377845491968, 0.02000577262765832, -0.020509878929426607, -0.004879017540339983, -0.0051166673214155306, 0.006553367021826025, 0.005264298253078542, -0.014475019250870948, -0.03079362327111189, 0.009102698751026407, 0.01575688703320609, -0.011313559904458887, -0.02547891531917913, -0.005584764965831675, -0.009405161600764772, -0.016736291965802865, 0.0031920658669710375, 0.025349288250530885, 0.017110769336277695, -0.021906969013617484, 0.006679393131606794, -0.020711519587488708, 0.024571525838641424, 0.026876005403370002, -0.014698265662137899, 0.0015870310019781345, 0.0042416846080398874, -0.005880026363496394, -0.0001803751286478248, 0.016721888130332964, 0.003256879401295159, 0.03805273911541352, -0.008915460065788992, 0.03520094360515216, 0.005044652335017762, -0.014640654045548727, 0.0186950999683512, 0.01675069393862755, -0.0002891853325486529, -0.0022486691260651015, -0.00041206095256635827, 0.017658083419165253, 0.014179758318867534, -0.011817665274904568, -0.013632443304657366, -0.008728220449228968, 0.012833077002208272, -0.01797494917305091, 0.013178749495711123, 0.007532771488761497, -0.008252921818400483, -0.0018507861050283134, 0.0036745664155344747, 0.03422153867255539, 0.027999441240084924, 0.009397960614352429, -0.004151666224288655, 0.009282736449851479, -0.0011630426589667154, 0.011248746370134765, -0.0068954385564614015, 0.03096645998352462, -0.029310113899392042, -0.007417547324260546, -0.01719718676116145, -0.01852226325593847, -0.036468406620694796, -0.015195170046171238, -0.023577718933219964, 0.028229889569086824, 0.0193576372844171, 0.0011801461658492885, 0.029209292639038383, 0.024542720030346837, -0.000833573898290872, -0.012804271193913686, -0.036266764099987484, 0.02161890906802641, 0.021705328355555383, -0.016232185664034577, -0.008605795298315677, -0.03534497450927031, 0.014964721717169336, -0.010082102752300573, 0.0008016171927795825, -0.004662972581146678, 0.009045087134437236, -0.01569927541661692, 0.01852226325593847, -0.020668311806369438, -0.00039023139089704433, 0.0330692988901911, 0.004320901512172607, -0.007640793735527497, -0.017830920131577985, 0.005761201705789272, -0.007082677241698816, -0.011572814041755372, -0.0006256305144727569, 0.040270799392613126, 0.002700563386900216, 0.010377364615626597, -0.0009632009087314524, 0.014006921606454803, -0.03298287960266213, 0.012069717494466102, -0.02670317055360249, -0.032925267986072954, -0.018234203310347398, 0.006927845323623462, -0.006297713843397014, 0.00967881864220855, 0.009261131627969234, 0.02025062479213012, 0.005127469732356652, -0.015108751689964872, 0.002241467673991455, -0.019559279805124417, 0.006646986364444733, 0.03658362985387314, 0.011111918315074179, -0.011255948287869716, 0.005883627322363869, -0.03975229111802015, 0.012509009330587663, -0.011140724123368764, -0.012458598700410833, 0.007158293186964059, 0.005293104061373128, -0.013805280017070097, 0.008087287023722703, 0.023304060960453576, -0.008238518914253189, 0.016505843636800965, 0.02582458688135937, -0.017888531748167156, -0.005350716143623603, 0.0026285484005024477, -0.021806149615909043, 0.003964427073389937, 0.030275114996518915, 0.019746518490361832, 0.007669600009483387, 0.00795765995507446, 0.02405301756404845, 0.034451985138912074, 0.0182486071458173, 0.02377935959128206, -0.010463782971832963, -0.019544877832299735, 0.007489562310658314, 1.2750315833471895e-05, -0.0026393505786129175, -0.012307367741202956, 0.014633452127813777, 0.03762064640305909, 0.0034261146891791097, 0.01830621876240647, 0.005386723869653139, 0.0038311992787048704, -0.0027239682225548927, -0.01050699168427484, 0.008872250422024506, -0.0021514488245789193, -0.01737002347357418, 0.021244431697551584, -0.0001358158383519069, -0.021748536136674653, -0.007878443516603046, 0.03612273692115977, 6.734529845674195e-05, -0.041423039174977416, -0.007039468529256938, -0.001829181515976722, 0.023520105453985574, -0.00459095759474891, -0.022367865671621287, 0.005379521951918188, -0.0015645264060403267, -0.010867067081924985, 0.007100681104713584, -0.010708634204982156, -0.004479334389115435, 0.014611848237254142, 0.0019065977078450511, -0.021892567040792798, 0.013121136947799343, -0.005602768828846443, 0.001481709125116763, 0.006531762665605086, -0.021863761232498214, -0.044908566193010084, 0.01657785722621482, 0.0057143920344799185, 0.008195309270488702, 0.02095637175196051, -0.000974003203257248, -0.014741475305902385, -0.010139715300212354, -0.017874127912697255, -0.030447951708931647, -0.03401989615184808, -0.03885930547295235, 0.03062078655869916, -0.028402724418854337, 0.004101255594111826, -0.027264886609314733, -0.0021604507560863033, 0.018176591693758227, 0.01692353065104028, -0.02444189876999318, -0.006650587323312208, -0.008000868667516337, 0.000731402569400226, 0.005944839897820515, -0.002804985140460045, -0.006268907569441124, -0.0014574040497452173, -0.027552948417551022, 0.01908398117429593, -0.022209432794678456, 0.016390618540977404, -0.014273377661486241, -0.030275114996518915, 0.00727351735146501, 0.012465800618145784, 0.017989353008520812, 0.013149942756093928, 0.006348124007912538, 0.013574831688068195, -0.012300165823468004, 0.0055271528835812, 0.0054155296779477245, 0.010146916286624695, 0.01000288631382916, 0.004943831074664104, 0.004994241704840933, -0.02074032725842851, 0.004198475895598009, 0.025234063154707324, -0.015007930429611214, 0.009261131627969234, 0.008080085105987752, 0.015454424183467725, 0.04456289649347506, -0.0029562165653292272, -0.04657931797525778, -0.017802114323283397, 0.0261990642518342, 0.022958389398273334, 0.004187673484656888, -0.013344383359066294, -0.006585773788988086, -0.04366991084840725, -0.026184662279009514, -0.011227141548252521, 0.007503965214805607, -0.02658794545777893, -0.00528230211609331, -0.014950318813022044, -0.004792599649794922, -0.0016941533582732439, 0.013668451030686903, -0.018479055474819202, -0.02880600946026897, 5.6908744505818965e-05, -0.001888593961245609, 0.0056135707741262605, 0.005746798801641979, 0.012314568727615298, -0.0036349581962987674, -0.021359654930729922, -0.028042649021204194, -0.0007034967679918572, -0.0048754170471338116, -0.0021172415779831203, 0.013308376564359367, 0.03966587555578161, 0.025781377237594882, 0.058245750428309255, 0.0020308236874380598, 0.018479055474819202, 0.004151666224288655, 0.00221086115343248, 0.009023482312554992, 0.020423459641897634, -0.001109931542469932, -0.0016095357143312687, -0.0010577206656900175, 0.02892123269344731, -0.010089304670035524, 0.004933029129384287, -0.0016293398239491223, 0.016131364403680917, 0.020265026764954806, 0.004194874936730534, -0.0016545451390375368, -0.014734273388167435, -0.03744781155329157, -0.026559139649484344, 0.00025250265956211726, -0.010420573328068476, 0.02130204331414075, -0.03643960267504543, -0.026026229402066687, 0.02448510841375767, 0.013070726317622515, 0.0298718318177495, -0.012357777440057175, 0.016721888130332964, 0.012026508782024225, 0.01588651410185433, 0.031715416587119495, 0.020927565943665925, -0.03891691708954152, -0.019991370654833637, -0.013834085825364682, 0.024139434988932205, 0.003224472634133098, 0.009210720997792406, 0.04243125177851399, 0.013639645222392317, 0.0013385792756227695, -0.029612577680453014, 0.03497049341350505, 0.00027635764417906, -0.007763219352102094, 0.02007778807971739, -0.02045226545019222, -0.018752711584940372, -0.04044363796767107, -0.0399251296930781, -0.013286771742477122, -0.01260262867320637, 0.02294398556280343, -0.006596576199929208, 0.013632443304657366, -0.013221958208153, 0.015252781662760409, 0.009585199299589843, 0.004194874936730534, 0.03537377845491968, -0.020149803531776464, 0.023548913124925377, 0.02581018490853469, -0.006909841460608694, 0.023030404850332406, -0.0034387173467233167, 0.026890409238839903, 0.024542720030346837, 0.026328691320482444, 0.029987055050927844, -0.010154118204359646, -6.132529459615984e-05, -0.020898760135371338, 0.003975229018669754, -0.02442749493452328, -0.039896322022138296, 0.022929583589978746, 0.008447362421372848, 0.008166503462194117, -0.016765097774097452, -0.013438002701685001, 0.005973646171776406, 0.005069857650106177, -0.010521394588422134, -0.010233334642831061, -0.00039135663233546734, -0.010478185875980255, -0.02033704221701388, 0.023534509289455476, 0.010550200396716718, 0.0442172230686496, 0.013157144673828879, -0.024859585784232495, -0.013956510976277975, -0.001522217584069339, -0.006592975241061732, 0.013906100346101145, -0.0008272725695187684, 0.02892123269344731, -0.02343368802910182, -0.019890549394479977, 0.026731976361897076, -0.0009731029635403791, -0.0031182504011395317, -0.022238238602973043, -0.023476897672866304, 0.03497049341350505, -0.021273237505846167, 0.00818090636634141, 0.013625242318245023, -0.003044435168138678, 0.036266764099987484, -0.012811472180326028, -0.01696673843215955, -0.007885644503015387, -0.0006472349871090221, -0.013898899359688804, 0.01276826346788415, -0.013459607523567245, -0.011493597603283959, 0.01741323311733867, 0.015584051252115969, 0.0071186849677283524, -0.01487830336096297, 0.013041920509327929, 0.04669454120843612, -0.0259830197583022, -0.002414303687912229, -0.017614873775400768, -0.020322638381543977, -0.020279430600424708, 0.022137417342619384, -0.008224116010105897, 0.007287920255612303, 0.02171973032838007, -0.02748093296549195, 0.05620052500087716, 0.013438002701685001, -0.0008385249256953354, -0.046435287071139635, 0.028978844310036483, -0.01626099147232916, -0.0036763668949682123, 0.03906094799365967, -0.025565332744062884, -0.02035144605248378, -0.01708196352798311, -0.010816656451748155, 0.02311682227521616, 0.01857987487252764, 0.002065030701203206, -0.0010919277958704899, 0.022036596082265728, 0.016174574047445406, -0.016347410759858134, -0.0036727661689313893, 0.015555244512498774, -0.026343095155952345, 0.0010064099122116458, 0.018493457447643885, -0.020668311806369438, 0.00440011795064402, -0.04090453090038444, -0.0002648802571771073, 0.00896587069596582, -0.0442460307395894, -0.013329980454919002, 0.003174062003956269, -0.013675652948421853, 0.0034387173467233167, 0.00779922707813163, -0.03041914590063706, -0.0031272523326469157, -0.02691921504713449, 0.0189255482973531, 0.008562586585873798, 0.008555384668138847, 0.01050699168427484, 0.022209432794678456, -0.010600611026893548, 0.012861882810502856, -0.00880023590128804, -0.019530473996829834, -0.007417547324260546, -0.01797494917305091, -0.028950038501741895, 0.003690769799115505, -0.006247303213220185, 0.015497632895909602, 0.017427635090163353, -0.0186806961328813, -0.030736011654522718, 0.011637627576079494, -0.0070358675703894626, -0.0012026508782024224, -0.01731241185698501, 0.03491288179691587, 0.024355481345109425, 0.009858856341033624, -0.0032460772231846895, -0.0014979125086977934, -0.00599885148686482, 0.027106453732371902, -0.016059350814267064, 0.018263009118641985, 0.012789868289766393, -0.008353742147431531, 0.012206546480849298, 0.007568778749129729, -0.01770129306292974, 0.002795983208952661, -0.0005297605143542146, 0.020999581395724998, 0.027034440142958048, 0.008865049435612163, 0.01686591903445111, 0.008490571133814726, 0.005408328225874078, -0.004961834937678872, -0.0006584873432855891, 0.0077344135438075085, 0.04067408443402776, -0.03822557396518103, -0.019055175366001344, 0.02035144605248378, 0.008360944065166482, 0.014950318813022044, -0.008368145982901433, -0.0021838555917409797, -0.020034578435952903, -0.007777622256249387, -0.013207555304005709, -0.01830621876240647, 0.00591603408952593, 0.009873259245180916, 0.0054659403081245535, 0.010622215848775792, 0.01963129525718349, 0.011320761822193838, 0.017715695035754424, -0.005239092937990127, -0.02481637614046801, 0.020999581395724998, -0.023073612631451672, -0.006863031789299341, 0.020279430600424708, 0.00569278767825898, -0.0010433176451273988, -0.014849497552668386, 0.01587211026638443, -0.01663547070544921, -0.033616611110433445, -0.010586208122746256, -0.03479765856373753, -0.000824572024991151, 0.003024630825690172, -0.006092470829483527, -0.018752711584940372, 0.012235352289143882, -0.012818674098060978, -0.00727351735146501, -0.0023260853179334308, -0.02074032725842851, 0.020265026764954806, -0.028935636528917213, -0.015728081224911504, 0.010931880616249107, -0.010046095957593646, -0.035892286729512654, -0.008778631079405798, 0.0055163509383013825, -0.008591392394168383, 0.012509009330587663, 0.2095925140146736, 0.011270351192017008, 0.010651021657070376, 0.03571945187974514, 0.0065713708848407935, -0.0059304369936732226, -0.008540981763991555, -0.003561142963297914, -0.013913302263836096, 0.004709782252456032, 0.001567226892360281, -0.0036817681004387734, -0.018176591693758227, -0.011731246918698202, -0.008548182750403897, -0.014525429881047778, -0.03557542097562699, -0.048250066032215044, -0.010910275794366863, 0.005735996390700857, 0.003445918798796963, -0.01088867097248462, -0.0030894443600142938, -0.026948020855429074, -0.0048754170471338116, -0.002146047619108358, 0.009880461162915867, -0.0028679981953504286, 0.04029960706355293, 0.004716984170190983, -0.02177734194496924, 0.02604063137489137, 0.011284754096164301, -0.019919355202774564, -0.008886653326171797, -0.010751842917424034, 0.00583321669218704, -0.006909841460608694, 0.0291948906662137, 0.02810026250043858, -0.018882338653588616, -0.0014853098511535862, -0.010269342368860597, -0.01421576511357446, -0.0017553661665605424, -0.009585199299589843, -0.018882338653588616, -0.026731976361897076, -0.011623224671932202, 0.018435845831054714, -0.015800096676970576, -0.0031110489490658853, 0.0291948906662137, 0.0182486071458173, -0.018839129009824127, -0.017470844733927838, 0.009469975135088893, 0.015267184566907701, 0.01588651410185433, 0.0007993667681103995, -0.010982291246425935, 0.011774456562462688, -0.0025169249620383203, 0.02543570567541464, -0.01807577043340457, 0.012818674098060978, -0.01260262867320637, 0.012112927138230591, 0.014921513004727459, -0.013553226866185951, -0.025637348196121956, 0.009405161600764772, 0.003723176566277566, 0.004486535841189082, -0.006780214391960452, -0.022569508192328603, 0.020149803531776464, 0.013329980454919002, 0.020221818983835536, 0.02990063762604409, 0.01028374527300789, -0.014467818264458606, -0.014619049223666485, 0.014006921606454803, -0.0339622845352589, -0.03281004475289461, 0.012897890536532392, 0.0024971208524204665, -0.002360292331698577, -0.027639365842434777, 0.004328102964246253, -0.020279430600424708, -0.016001737335032674, -0.014475019250870948, 0.009311542258146064, -0.002749173537643307, 0.012134531028790224, 0.01902636955770676, 0.003247877469787775, 0.03269482151971627, -0.02333286676874816, 0.03860005133565586, 0.020855550491606853, 0.009527587683000672, -0.0038420014568153397, -0.013567629770333245, -0.010687029383099914, 0.02504682446946991, 0.009585199299589843, -0.005095062965194591, -0.015166363306554043, -0.01420856412716212, 0.007255513488450242, -0.02405301756404845, -0.010449380067685669, 0.027005632472018246, -0.022569508192328603, -7.150866704065027e-05, 0.031340939216644666, 0.001648243810265433, -0.022151821178089285, 0.0008799335661571172, -0.021316447149610656, -0.013193152399858415, 0.00638773269280955, 0.0014484021182378333, -0.01700994807592404, 0.002749173537643307, -0.031081683216702963, -0.00669379650141539, 0.027725783267318536, -0.026011825566596786, 0.03355899949384427, -0.007388741515965961, -0.007205102858273413, 0.009686020559943501, 0.0010442177684289414, -0.0030192298530502637, -0.005883627322363869, 0.0035053311276505243, -0.02274234490474133, 0.0008385249256953354, 0.019717712682067248, -0.008447362421372848, 0.024931601236291567, -0.010831059355895449, 0.00688463614552028, 0.006459747679207318, 0.02366413635810372, -0.014345392182222704, -0.013373190098683489, 0.007230308173361828, 0.004144464306553705, -0.03413511938502641, 0.030044666667517015, -0.024557122003171523, -0.01437419799051729, -0.03197467072441598, 0.008829041709582626, 0.0027167667704812463, -0.0073347299269216565, -0.0129915098791511, 0.03309810283584047, 0.028503545679207994, -0.03442318119326271, -0.031081683216702963, -0.18516502466808596, 0.007352733789936425, 0.01133516472634113, -0.017153978980042183, 0.015958529553913407, 0.0186950999683512, 0.011407179247077593, 0.00884344461372992, -0.028935636528917213, -0.011263149274282057, 0.006016854884218283, 0.011824866261316909, 0.0031182504011395317, -0.02304480682315709, 0.019141592790885103, -0.008058481215428117, -0.031052877408408376, 0.01310673404365205, 0.027783394883907707, 0.027999441240084924, 0.04228722087439585, -0.02403861372857855, 0.022151821178089285, 0.012509009330587663, 0.014950318813022044, -0.013207555304005709, -0.008418555681755653, 0.0031272523326469157, 0.01641942434927199, -0.03450960048079168, -0.0016815508171443628, 0.008166503462194117, 0.03517213593421236, -0.003896012813028992, 0.016088156622561647, 0.021906969013617484, -0.0037123743881670966, -0.016664276513743793, 0.004212878799745302, 0.024873989619702396, 0.03194586305347618, 0.015281587471054995, -0.003899613539065815, 0.008735422366963919, -0.02719287301990088, 0.00033689527267870685, 0.006963852583991695, -0.03416392705596622, 0.018810323201529543, -0.01737002347357418, 0.025392496031650152, -0.034365569576673534, 0.023520105453985574, -0.004464931484968142, 0.010319752999037425, 0.012530614152469905, 0.004050844963934997, 0.025032422496645227, -0.005487544664345492, -0.015713677389441603, 0.011191134753545594, -0.018392636187290225, 0.003957225621316291, -0.0043173005533051305, 1.8552308349035325e-05, -0.021993388301146458, -0.014575840511224606, 0.000804317795514863, -0.03462482371397002, -0.00719069995412612, -0.007460756502363729, 0.02000577262765832, 0.011565612124020422, 0.00023472395833997668, 0.004987040252767287, 0.023750553782987478, -0.011536806315725836, 0.0014366997004104948, 0.008029675407133532, -0.021532491643142655, -0.007662398557409741, 0.025248466990177226, -0.005077059102179823, -0.006992658857947584, 0.006999860310021231, -0.005177879896872177, 0.01702435191139394, 0.034538404426441044, -0.010967888342278643, -0.02791302195255595, 0.016765097774097452, -0.02516204956529347, 0.009426766422647014, -0.010377364615626597, 0.009138706477055943, 0.02025062479213012, -0.011234343465987472, -0.0189111444618832, 0.02123002786208168, -0.02771138129449385, 0.020610700189780267, 0.0070358675703894626, -0.02444189876999318, -0.01237938226193942, 0.02958377187215843, 0.03986751807648893, -0.02271353723380153, 0.01183206817905186, 0.02033704221701388, -0.011097514479604277, 0.0042596884710546555, 0.003982430936404705, 0.01978972813412632, -9.519485671068011e-05, -0.014150951579250339, 0.028791605624799068, -0.016333006924388233, -0.010478185875980255, 0.01051419360200979, -0.04784678099080041, 0.054040072614976294, -0.0056567799522294435, -0.026501528032895173, 0.006182489678896063, -0.01796054720022623, -0.003217271182059452, -0.09396519858276396, -0.0255365269357683, 0.022238238602973043, 0.013963712894012926, -0.017038753884218622, 0.004086852689964534, -0.02481637614046801, 0.03200347467006535, -0.03880169385636318, 0.02328965898762889, -0.0090090794084077, -0.04934469419799016, 0.00885064653146487, 0.015612857060410554, -0.008195309270488702, -0.002551132208634119, -0.040184383830374586, 0.0009150408778467955, -0.060607841609627004, 0.012372181275527076, -0.014647855963283678, 0.01133516472634113, 0.021100400793433435, -0.0007750616927388539, -0.0010082102752300573, 0.015454424183467725, -0.029929443434338673, 0.023692942166398306, 0.013992518702307511, 0.0027185670170843316, 0.01762927761087067, -0.009887662149328208, 0.015900916074679017, -0.013438002701685001, -0.015771289006030774, -0.025291676633941714, -0.0002087310353627123, -0.03335735697313696, 0.01338759300283078, -0.025234063154707324, -0.00710428206358106, -0.004929428170516812, -0.006765811487813159, 0.010298148177155183, -0.027797798719377608, 0.024744362551054153, -0.03966587555578161, 0.0296413834887476, 0.021215625889256996, -0.02228144824673753, 0.00038505533266719526, -0.010096506587770476, 0.01664987267827389, 0.020221818983835536, 0.01338039108509583, -0.006207694993984478, 0.021820551588733725, 0.002444909975640552, -0.017240396404925938, -0.016390618540977404, -0.033328553027487585, 0.02506122830493981, -0.007763219352102094, 0.0214460742182589, 0.0300734724758116, -0.003156058373772153, 0.000523459185582111, -0.0008794834462986828, 0.005937638445746869, 0.01299871179688605, -0.01758606796710618, 0.009491579956971136, -0.021215625889256996, 0.029266904255627554, -0.0259974235937721, 0.011241545383722422, -0.005541555787728493, -0.012127330042377883, 0.03381825363114076, 0.012264158097438468, -0.027552948417551022, 0.003899613539065815, -0.008706616558669335, -0.0010343157136200147, -0.006416538501104136, 0.032464371328069154, 0.001843584536539341, -0.009412363518499722, 0.028733994008209897, -0.011911284617523275, 6.796417688229987e-05, 0.0006818922371479289, 0.010939081602661448, -0.017946143364756327, -0.021604507095201727, 0.020855550491606853, -0.0068954385564614015, -0.012818674098060978, -0.010651021657070376, 0.017384427309044083, -0.031801832149358035, -0.0062545046652938315, -0.07241830496679662, 0.03566184026315597, -0.0016941533582732439, -0.004331703457452423, -0.0042092778408778266, -0.03594989834610182, -0.0015060142004883086, -0.02274234490474133, 0.0016923529952548324, 0.01764367958369535, -0.021762939972144554, 0.003697971484019804, -0.0013790877345753456, -0.010334155903184719, -0.004014837703566766, -0.011796060453022323, 0.04456289649347506, -0.013438002701685001, 0.027408917513432877, 0.018651890324586713, -0.019976966819363732, 0.010377364615626597, 0.014921513004727459, 0.019098383147120614, -0.03623796015433811, -0.022094209561500114, -0.011291955082576643, 0.03540258612585948, -0.006899039049667573, -0.014482221168605898, 0.012984308892738758, -0.033040491219251296, 0.009282736449851479, 0.013495615249596781, 0.01758606796710618, 0.013063525331210172, -0.009534788669413015, -0.008080085105987752, 0.011435985986694788, 0.006207694993984478, -0.013848488729511974, -0.02134525295790524, 0.0018399838105025179, 0.0017778708789136766, -0.01233617354949754, -0.027653767815259463, 0.0076768014615570335, 0.004356908772540838, 0.02506122830493981, 0.03376064201455159, 0.0011117319054883435, 0.002936412455711374, 0.020092191915187293, -0.052254101324840686, 0.023981002111989377, 0.009700423464090795, 0.002020021276496938, -0.023966600139164695, 0.004194874936730534, -0.02000577262765832, 0.010751842917424034, 0.01376207037330561, 0.019602489448888906, 0.007806428530205277, 0.01011811047833011, -0.005455137897183431, -0.019717712682067248, -0.004706181759249861, 0.01957368364059432, -0.023952196303694794, 0.023851375043341134, -0.021762939972144554, 0.016549051417920235, 0.011630425658344544, -0.006765811487813159, -0.029022053953800968, 0.004832207869030629, -0.010262140451125647, -0.02304480682315709, -0.001146839275385685, 0.016621066869979308, -0.003633157949695682, -0.01696673843215955, -0.0032712823054424516, 0.022295850219562215, 0.0018102776460757373, -0.0027365708800990997, -0.02274234490474133, -0.006182489678896063, 0.014014123524189754, -3.685143882961706e-05, 0.002689760975959094, 0.019184802434649588, 0.0006283310590003742, 0.006672191679533147, 0.010622215848775792, 7.252137851446468e-05, 0.005397525814932956, -0.002333286770007077, 0.012134531028790224, 0.001798575228248399, 0.019213608242944175, -0.010831059355895449, -0.019055175366001344, -0.032550790615598124, 0.005869224418216576, -0.022699135260976847, -0.001132436254823066, -0.021518087807672753, 0.014748676292314728, 0.012948301166709222, 0.018032560789640082, -0.018795921228704857, 0.025291676633941714, -0.01476307919646202, 0.02239667147991587, -0.009311542258146064, 0.012926696344826977, -0.010679827465364961, 0.01338039108509583, 0.009822848615004086, 0.014640654045548727, 0.0005671183089207388, 0.023937794330870107, 0.03957945626825264, 0.02274234490474133, 0.011644829493814445, -0.0003825798189649636, 0.021906969013617484, 0.007936055133192215, -0.014964721717169336, -0.009995685327416818, 0.001744563872034747, -0.009916468888945403, -0.0009532988539225256, -0.020927565943665925, -0.020941967916490608, 0.02334727060421806, 0.00425248701898101, 0.0640645646820103, 0.017571665994281498, -0.016793903582392036, -0.003953624662448815, -0.0046737749920878, -0.0113927763429303, 0.011918486535258226, -0.0223390598633267, -0.018234203310347398, -0.018190995529228128, -0.030044666667517015, 0.007741614995881155, -0.021849357397028313, -0.03364541878137325, 0.001975012084621322, -0.010154118204359646, 0.007532771488761497, 0.019429652736476174, -0.02746652913002205, -0.017067559692513206, 0.015713677389441603, 0.0032856854424203968, -0.0028607967432767822, -0.0042596884710546555, -0.029929443434338673, 0.005937638445746869, 0.02035144605248378, 0.010636618752923084, -0.006740606172724744, -0.05778485377030545, 0.0053471151847561274, 0.009858856341033624, -0.021100400793433435, -0.026357498991422246, -0.00830333244857731, 0.006373329323000953, -0.008533779846256603, 0.01924241405123876, 0.004637767266058264, 0.022526298548564114, -0.0038384007307785168, 0.00489342091014858, -0.042834536819928624, -0.02742332134890278, 0.013401995906978074, -0.01760047180257608, -0.030303920804813502, -0.03315571445242964, -0.04928708258140099]], node_map={'ddaf50de-f60d-4ecd-bde7-cfe98cdf2955': Node(page_content=\"Davis Bennett said: to inaugurate this channel -- GPU-accelerated array computing came up in the scicomp virtual happy hour yesterday. Here's the library I was talking about (CuPy): https://cupy.chainer.org/\\nCuPy\\nCuPy is NumPy-compatible matrix library accelerated by CUDA\\nDavis Bennett said: a lower-level vendor-agnostic approach using OpenCL is here: https://github.com/inducer/pyopencl\\ninducer/pyopencl\\nOpenCL integration for Python, plus shiny features - inducer/pyopencl\\nCameron Arshadi said: nice, seems like a good alternative to numba\\nDavis Bennett said: yeah I'm not sure how a cuda kernel jitted with numba will compare in performance to the same operation on a cupy array\\nOthers reacted to the previous message with +1::skin-tone-3 a total of 1 times.\\n\", metadata={'source': './tempTestGen.txt'}, doc_id='ddaf50de-f60d-4ecd-bde7-cfe98cdf2955', wins=32)}, run_config=RunConfig(timeout=60, max_retries=15, max_wait=90, max_workers=16, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), node_filter=NodeFilter(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=15, max_wait=90, max_workers=16, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), threshold=1.5, context_scoring_prompt=Prompt(name='score_context', instruction='\\n    Given a context, perform the following task and output the answer in VALID JSON format: Assess the provided context and assign a numerical score of 1 (Low), 2 (Medium), or 3 (High) for each of the following criteria in your JSON response:\\n\\nclarity: Evaluate the precision and understandability of the information presented. High scores (3) are reserved for contexts that are both precise in their information and easy to understand. Low scores (1) are for contexts where the information is vague or hard to comprehend.\\ndepth: Determine the level of detailed examination and the inclusion of innovative insights within the context. A high score indicates a comprehensive and insightful analysis, while a low score suggests a superficial treatment of the topic.\\nstructure: Assess how well the content is organized and whether it flows logically. High scores are awarded to contexts that demonstrate coherent organization and logical progression, whereas low scores indicate a lack of structure or clarity in progression.\\nrelevance: Judge the pertinence of the content to the main topic, awarding high scores to contexts tightly focused on the subject without unnecessary digressions, and low scores to those that are cluttered with irrelevant information.\\nStructure your JSON output to reflect these criteria as keys with their corresponding scores as values\\n    ', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"clarity\": {\"title\": \"Clarity\", \"type\": \"integer\"}, \"depth\": {\"title\": \"Depth\", \"type\": \"integer\"}, \"structure\": {\"title\": \"Structure\", \"type\": \"integer\"}, \"relevance\": {\"title\": \"Relevance\", \"type\": \"integer\"}}, \"required\": [\"clarity\", \"depth\", \"structure\", \"relevance\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'The Pythagorean theorem is a fundamental principle in geometry. It states that in a right-angled triangle, the square of the length of the hypotenuse (the side opposite the right angle) is equal to the sum of the squares of the lengths of the other two sides. This can be written as a^2 + b^2 = c^2 where c represents the length of the hypotenuse, and a and b represent the lengths of the other two sides.', 'output': {'clarity': 3, 'depth': 1, 'structure': 3, 'relevance': 3}}, {'context': 'Albert Einstein (14 March 1879 - 18 April 1955) was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time.', 'output': {'clarity': 3, 'depth': 2, 'structure': 3, 'relevance': 3}}, {'context': \"I love chocolate. It's really tasty. Oh, and by the way, the earth orbits the sun, not the other way around. Also, my favorite color is blue.\", 'output': {'clarity': 2, 'depth': 1, 'structure': 1, 'relevance': 1}}], input_keys=['context'], output_key='output', output_type='json', language='english')), question_filter=QuestionFilter(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=15, max_wait=90, max_workers=16, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), filter_question_prompt=Prompt(name='filter_question', instruction='\\nAsses the given question for clarity and answerability given enough domain knowledge, consider the following criteria:\\n1.Independence: Can the question be understood and answered without needing additional context or access to external references not provided within the question itself? Questions should be self-contained, meaning they do not rely on specific documents, tables, or prior knowledge not shared within the question.\\n2.Clear Intent: Is it clear what type of answer or information the question seeks? The question should convey its purpose without ambiguity, allowing for a direct and relevant response.\\nBased on these criteria, assign a verdict of \"1\" if a question is specific, independent, and has a clear intent, making it understandable and answerable based on the details provided. Assign \"0\" if it fails to meet one or more of these criteria due to vagueness, reliance on external references, or ambiguity in intent.\\nProvide feedback and a verdict in JSON format, including suggestions for improvement if the question is deemed unclear. Highlight aspects of the question that contribute to its clarity or lack thereof, and offer advice on how it could be reframed or detailed for better understanding and answerability.\\n', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"feedback\": {\"title\": \"Feedback\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"type\": \"integer\"}}, \"required\": [\"feedback\", \"verdict\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'What is the discovery about space?', 'output': {'feedback': \"The question is too vague and broad, asking for a 'discovery about space' without specifying any particular aspect, time frame, or context of interest. This could refer to a wide range of topics, from the discovery of new celestial bodies to advancements in space travel technology. To improve clarity and answerability, the question could specify the type of discovery (e.g., astronomical, technological), the time frame (e.g., recent, historical), or the context (e.g., within a specific research study or space mission).\", 'verdict': 0}}, {'question': \"How does ALMA-13B-R perform compared to other translation models in the WMT'23 study, based on the results in context1 and context2?\", 'output': {'feedback': \"This question asks for a comparison of the ALMA-13B-R model's performance against other translation models within the WMT'23 study, specifically referring to results in 'context1' and 'context2'. While it clearly specifies the model of interest (ALMA-13B-R) and the study (WMT'23), it assumes access to and understanding of 'context1' and 'context2' without explaining what these contexts entail. This makes the question unclear for those not familiar with the WMT'23 study or these specific contexts. To improve clarity and answerability for a broader audience, the question could benefit from defining or describing 'context1' and 'context2' or explaining the criteria used for comparison in these contexts.\", 'verdict': 0}}, {'question': 'How do KIWI-XXL and XCOMET compare to the gold standard references in Table 1 in terms of evaluation scores, translation model performance, and success rate in surpassing the references?', 'output': {'feedback': \"The question requests a comparison between KIWI-XXL and XCOMET models and gold standard references in 'Table 1', focusing on evaluation scores, translation model performance, and success rates in surpassing the references. It specifies the models and criteria for comparison, making the intent clear. However, the question assumes access to 'Table 1' without providing its content or context, making it unclear for those without direct access to the source material. To be clearer and more answerable for a general audience, the question could include a brief description of the content or key findings of 'Table 1', or alternatively, frame the question in a way that does not rely on specific, unpublished documents.\", 'verdict': 0}}, {'question': 'What is the configuration of UL2 training objective in OpenMoE and why is it a better choice for pre-training?', 'output': {'feedback': 'The question asks for the configuration of the UL2 training objective within the OpenMoE framework and the rationale behind its suitability for pre-training. It is clear in specifying the topic of interest (UL2 training objective, OpenMoE) and seeks detailed information on both the configuration and the reasons for its effectiveness in pre-training. However, the question might be challenging for those unfamiliar with the specific terminology or the context of OpenMoE and UL2. For broader clarity and answerability, it would be helpful if the question included a brief explanation or context about OpenMoE and the UL2 training objective, or clarified the aspects of pre-training effectiveness it refers to (e.g., efficiency, accuracy, generalization).', 'verdict': 1}}, {'question': 'What is the detailed configuration of the UL2 training objective in OpenMoE, based on the provided context?', 'output': {'feedback': \"The question seeks detailed information on the UL2 training objective's configuration within the OpenMoE framework, mentioning 'the provided context' without actually including or describing this context within the query. This makes the question unclear for those who do not have access to the unspecified context. For the question to be clear and answerable, it needs to either include the relevant context directly within the question or be framed in a way that does not require external information. Detailing the specific aspects of the configuration of interest (e.g., loss functions, data augmentation techniques) could also help clarify the query.\", 'verdict': 0}}], input_keys=['question'], output_key='output', output_type='json', language='english')), question_answer_prompt=Prompt(name='answer_formulate', instruction=\"Answer the question using the information from the given context. Output verdict as '1' if answer is present '-1' if answer is not present in the context.\", output_format_instruction='', examples=[{'context': 'Climate change is significantly influenced by human activities, notably the emission of greenhouse gases from burning fossil fuels. The increased greenhouse gas concentration in the atmosphere traps more heat, leading to global warming and changes in weather patterns.', 'question': 'How do human activities contribute to climate change?', 'answer': {'answer': 'Human activities contribute to climate change primarily through the emission of greenhouse gases from burning fossil fuels. These emissions increase the concentration of greenhouse gases in the atmosphere, which traps more heat and leads to global warming and altered weather patterns.', 'verdict': '1'}}, {'context': 'The concept of artificial intelligence (AI) has evolved over time, but it fundamentally refers to machines designed to mimic human cognitive functions. AI can learn, reason, perceive, and, in some instances, react like humans, making it pivotal in fields ranging from healthcare to autonomous vehicles.', 'question': 'What are the key capabilities of artificial intelligence?', 'answer': {'answer': 'Artificial intelligence is designed to mimic human cognitive functions, with key capabilities including learning, reasoning, perception, and reacting to the environment in a manner similar to humans. These capabilities make AI pivotal in various fields, including healthcare and autonomous driving.', 'verdict': '1'}}, {'context': 'The novel \"Pride and Prejudice\" by Jane Austen revolves around the character Elizabeth Bennet and her family. The story is set in the 19th century in rural England and deals with issues of marriage, morality, and misconceptions.', 'question': \"What year was 'Pride and Prejudice' published?\", 'answer': {'answer': 'The answer to given question is not present in context', 'verdict': '-1'}}], input_keys=['context', 'question'], output_key='answer', output_type='json', language='english'), find_relevant_context_prompt=Prompt(name='find_relevant_context', instruction='Given a question and set of contexts, find the most relevant contexts to answer the question.', output_format_instruction='', examples=[{'question': 'What is the capital of France?', 'contexts': ['1. France is a country in Western Europe. It has several cities, including Paris, Lyon, and Marseille. Paris is not only known for its cultural landmarks like the Eiffel Tower and the Louvre Museum but also as the administrative center.', '2. The capital of France is Paris. It is also the most populous city in France, with a population of over 2 million people. Paris is known for its cultural landmarks like the Eiffel Tower and the Louvre Museum.', '3. Paris is the capital of France. It is also the most populous city in France, with a population of over 2 million people. Paris is known for its cultural landmarks like the Eiffel Tower and the Louvre Museum.'], 'output': {'relevant_contexts': [1, 2]}}, {'question': 'How does caffeine affect the body and what are its common sources?', 'contexts': ['1. Caffeine is a central nervous system stimulant. It can temporarily ward off drowsiness and restore alertness. It primarily affects the brain, where it alters the function of neurotransmitters.', '2. Regular physical activity is essential for maintaining good health. It can help control weight, combat health conditions, boost energy, and promote better sleep.', '3. Common sources of caffeine include coffee, tea, cola, and energy drinks. These beverages are consumed worldwide and are known for providing a quick boost of energy.'], 'output': {'relevant_contexts': [1, 2]}}], input_keys=['question', 'contexts'], output_key='output', output_type='json', language='english'), rewrite_invalid_question_prompt=Prompt(name='rewrite_question', instruction='Given a context, question and feedback, rewrite the question to improve its clarity and answerability based on the feedback provided.', output_format_instruction='', examples=[{'context': \"The Eiffel Tower was constructed using iron and was originally intended as a temporary exhibit for the 1889 World's Fair held in Paris. Despite its initial temporary purpose, the Eiffel Tower quickly became a symbol of Parisian ingenuity and an iconic landmark of the city, attracting millions of visitors each year. The tower's design, created by Gustave Eiffel, was initially met with criticism from some French artists and intellectuals, but it has since been celebrated as a masterpiece of structural engineering and architectural design.\", 'question': 'Who created the design for the Tower?', 'feedback': \"The question asks about the creator of the design for 'the Tower', but it does not specify which tower it refers to. There are many towers worldwide, and without specifying the exact tower, the question is unclear and unanswerable. To improve the question, it should include the name or a clear description of the specific tower in question.\", 'output': 'Who created the design for the Eiffel Tower?'}, {'context': \"'Exploring Zero-Shot Learning in Neural Networks' was published by Smith and Lee in 2021, focusing on the application of zero-shot learning techniques in artificial intelligence.\", 'question': 'What datasets were used for the zero-shot evaluations in this study?', 'feedback': \"The question asks about the datasets used for zero-shot evaluations in 'this study', without specifying or providing any details about the study in question. This makes the question unclear for those who do not have access to or knowledge of the specific study. To improve clarity and answerability, the question should specify the study it refers to, or provide enough context about the study for the question to be understood and answered independently.\", 'output': 'What datasets were used for the zero-shot evaluations Exploring Zero-Shot Learning in Neural Networks paper?'}], input_keys=['context', 'question', 'feedback'], output_key='output', output_type='str', language='english'), max_tries=5, is_async=True, compress_question_prompt=Prompt(name='compress_question', instruction='Rewrite the following question to make it more indirect and shorter while retaining the essence of the original question.\\n    The goal is to create a question that conveys the same meaning but in a less direct manner. The rewritten question should shorter so use abbreviation wherever possible.', output_format_instruction='', examples=[{'question': 'What is the distance between the Earth and the Moon?', 'output': 'How far is the Moon from Earth?'}, {'question': 'What ingredients are required to bake a chocolate cake?', 'output': \"What's needed for a chocolate cake?\"}], input_keys=['question'], output_key='output', output_type='str', language='english'), multi_context_question_prompt=Prompt(name='multi_context_question', instruction=\"\\n    The task is to rewrite and complicate the given question in a way that answering it requires information derived from both context1 and context2. \\n    Follow the rules given below while rewriting the question.\\n        1. The rewritten question should not be very long. Use abbreviation wherever possible.\\n        2. The rewritten question must be reasonable and must be understood and responded by humans.\\n        3. The rewritten question must be fully answerable from information present in context1 and context2. \\n        4. Read and understand both contexts and rewrite the question so that answering requires insight from both context1 and context2.\\n        5. phrases like 'based on the provided context','according to the context?',etc are not allowed to appear in the question.\", output_format_instruction='', examples=[{'question': 'What process turns plants green?', 'context1': 'Chlorophyll is the pigment that gives plants their green color and helps them photosynthesize.', 'context2': 'Photosynthesis in plants typically occurs in the leaves where chloroplasts are concentrated.', 'output': 'In which plant structures does the pigment responsible for their verdancy facilitate energy production?'}, {'question': 'How do you calculate the area of a rectangle?', 'context1': \"The area of a shape is calculated based on the shape's dimensions. For rectangles, this involves multiplying the length and width.\", 'context2': 'Rectangles have four sides with opposite sides being equal in length. They are a type of quadrilateral.', 'output': \"What multiplication involving equal opposites yields a quadrilateral's area?\"}], input_keys=['question', 'context1', 'context2'], output_key='output', output_type='str', language='english'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:ragas.testset.evolutions:seed question generated: Here's a question that can be fully answered from the given context:\n",
      "\n",
      "\"What is CuPy, and how does it differ from other libraries like Numba?\"\n",
      "\n",
      "This question can be answered by referencing the provided context, which mentions that CuPy is a \"NumPy-compatible matrix library accelerated by CUDA\" and that Davis Bennett mentioned it as an alternative to Numba.\n",
      "INFO:ragas.testset.evolutions:retrying evolution: 3 times\n",
      "INFO:ragas.testset.evolutions:seed question generated: Here's a question that can be fully answered from the given context:\n",
      "\n",
      "\"What is an alternative to Numba mentioned in this conversation?\"\n",
      "\n",
      "This question can be answered by referencing the message where Cameron Arshadi says \"nice, seems like a good alternative to numba\" and linking it to the inducer/pyopencl library.\n",
      "INFO:ragas.testset.evolutions:retrying evolution: 4 times\n",
      "INFO:ragas.testset.evolutions:seed question generated: Here's a question that can be fully answered from the given context:\n",
      "\n",
      "\"What is CuPy, and how does it differ from other libraries like Numba?\"\n",
      "\n",
      "This question can be answered by referencing the provided context, which mentions that CuPy is \"NumPy-compatible matrix library accelerated by CUDA\" and that Davis Bennett mentioned it as an alternative to Numba.\n",
      "INFO:ragas.testset.evolutions:retrying evolution: 5 times\n",
      "INFO:ragas.testset.evolutions:seed question generated: Here's a question that can be fully answered from the given context:\n",
      "\n",
      "\"What is an alternative approach to NumPy-compatible matrix library accelerated by CUDA, as mentioned in the scicomp virtual happy hour?\"\n",
      "\n",
      "This question uses the keyphrase \"GPU-accelerated array computing\" and can be answered based on the provided context.\n",
      "INFO:ragas.testset.evolutions:rewritten question: Here's the rewritten question:\n",
      "\n",
      "\"What alternative library, mentioned during the scicomp virtual happy hour, offers OpenCL integration for Python and serves as a lower-level vendor-agnostic approach?\"\n",
      "\n",
      "This question requires the reader to make multiple logical connections by linking the mention of \"GPU-accelerated array computing\" in the context to the specific libraries discussed (CuPy and pyopencl). The reader must infer that Davis Bennett mentioned CuPy, which is accelerated by CUDA, and then look for an alternative approach using OpenCL, which is provided by pyopencl.\n",
      "INFO:ragas.testset.evolutions:retrying evolution: 6 times\n",
      "WARNING:ragas.executor:max retries exceeded for ReasoningEvolution(generator_llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=15, max_wait=90, max_workers=16, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), docstore=InMemoryDocumentStore(splitter=<langchain_text_splitters.base.TokenTextSplitter object at 0x30be93bc0>, nodes=[Node(page_content=\"Davis Bennett said: to inaugurate this channel -- GPU-accelerated array computing came up in the scicomp virtual happy hour yesterday. Here's the library I was talking about (CuPy): https://cupy.chainer.org/\\nCuPy\\nCuPy is NumPy-compatible matrix library accelerated by CUDA\\nDavis Bennett said: a lower-level vendor-agnostic approach using OpenCL is here: https://github.com/inducer/pyopencl\\ninducer/pyopencl\\nOpenCL integration for Python, plus shiny features - inducer/pyopencl\\nCameron Arshadi said: nice, seems like a good alternative to numba\\nDavis Bennett said: yeah I'm not sure how a cuda kernel jitted with numba will compare in performance to the same operation on a cupy array\\nOthers reacted to the previous message with +1::skin-tone-3 a total of 1 times.\\n\", metadata={'source': './tempTestGen.txt'}, doc_id='ddaf50de-f60d-4ecd-bde7-cfe98cdf2955', wins=36)], node_embeddings_list=[[-0.01725480024039584, -0.004083251731097058, 0.02810026250043858, -0.030390340092342476, 0.0032640808533688052, 0.00967161765579621, 0.01906957733882603, -0.019602489448888906, -0.03214750557418349, -0.031801832149358035, 0.03347258393160573, 0.022583910165153286, 0.0008254722065003568, 0.0030894443600142938, -0.005786407020877686, 0.009167512285350529, 0.009045087134437236, -0.0018138783721125605, 0.01931442950329783, 0.010744640999689083, -0.04004035292625644, 0.011205537657692886, -0.014338191195810363, -0.005361518554564725, -0.03891691708954152, 0.017830920131577985, 0.01620337985573999, -0.02775458907561312, -0.023260851316689087, -0.0010046095491932341, 0.03373183806890222, 0.007806428530205277, 0.0007372537783138952, -0.009059490038584528, -0.033414968589726125, -0.028373918610559754, 0.003044435168138678, 0.00047529915469745406, 0.033616611110433445, 0.005447936445109785, 0.03969467950143098, -0.00288960278440202, -0.005429932582095017, -0.004698980307176214, 0.0012782665906370138, -0.005880026363496394, 0.023304060960453576, 0.008612996284728018, -0.02815787411702775, 0.010463782971832963, 0.02133084912243534, 0.03594989834610182, -0.022036596082265728, -0.03934900980189596, 0.008533779846256603, -0.0032010677984784216, -0.012278561001585761, 0.01591531991014892, -0.005797209431818808, -0.018032560789640082, 0.005077059102179823, 0.02847473987091341, 0.007370737652951193, 0.043612299231818086, -0.001780571481648957, -0.0069206438715498165, 0.014669459853843313, 0.029310113899392042, 0.025694959812711127, -0.0035935494976293224, 0.01276826346788415, 0.022411075315385772, -0.006686595049341744, -0.029843026009454918, 0.020279430600424708, -0.01852226325593847, -0.016433828184741893, -0.02006338610689271, -0.012696248015825076, 0.01155841113760808, 0.0005635175246762526, -0.019444056571946075, 0.020149803531776464, 0.00795765995507446, -0.002061429975166383, 0.013351585276801244, -0.006236500802279063, 0.01901196572223686, -0.016001737335032674, -0.020653907970899537, 0.007611987927232912, 0.012444195796263541, 0.016347410759858134, 0.007986465763369045, -0.007403144420113254, 0.05867783941537325, -0.0038924118541615164, 0.024081823372343037, -0.017470844733927838, 0.0003492728702936969, -0.007453554584628778, 0.01941525076365149, -0.029987055050927844, -0.026948020855429074, -0.019746518490361832, -0.017110769336277695, -0.006960252090785523, 0.020495475093956706, 0.02140286457449441, 0.03715974974505528, 0.002405301756404845, 0.032377955765830614, -0.03381825363114076, -0.02438428715340401, 0.008029675407133532, -0.028791605624799068, 0.02328965898762889, -0.02449951038658235, -0.015512035800056896, -0.023246449343864405, 0.016664276513743793, 0.025968617785477516, 0.032377955765830614, -0.008879452339759456, 0.025622944360652055, 0.02040905766907295, -0.01548322999176231, -0.018277412954111887, 0.03232034042395101, -0.010679827465364961, 0.025680557839886445, 0.0189111444618832, 0.009815647628591745, 0.015252781662760409, -0.015007930429611214, -0.012091322316348347, 0.007792025626057984, 0.0026285484005024477, -0.02409622720781294, -0.04145184684591722, 0.0031308530586837387, 0.014338191195810363, -0.03252198294465832, 0.017845322104402667, -0.03577706349633431, 0.05896590122360954, 0.006423739953177782, -0.013747667469158316, 0.00481060351280969, -0.007165494639037706, 0.01167363530210903, -0.002219863084939864, -0.027351305896843706, 0.019127190818060417, 0.013279569824742172, 0.008260122804812824, 0.013344383359066294, 0.017773306652343595, -0.021518087807672753, 0.005134671184430299, 0.010089304670035524, -0.009858856341033624, -0.008540981763991555, -0.0006490354083350967, 0.010355759793744354, 0.023865778878811035, 0.043497072273349306, -0.028676382391620726, -0.004576554690601618, -0.001241358974136587, 0.012926696344826977, 0.009138706477055943, -0.03517213593421236, 0.0017355620569426888, 0.006866632282505512, -0.02604063137489137, 0.030591980750404573, -0.0005018547129458457, -0.032954075657012756, -0.005469540801330724, 0.023952196303694794, -0.016016141170502575, 0.00950598286111843, 0.017672487254635154, 0.0037159751142039196, -0.022871971973389575, 0.010276543355272939, 0.003950024169242644, 0.009938072779505038, -0.008159302475781775, 0.02138846073902451, 0.014907109169257556, -0.01183206817905186, -0.03381825363114076, -0.5936342100554578, -0.018147785885463643, -0.02040905766907295, -0.026400706772541516, -0.011536806315725836, 0.019170398599179687, 0.011688038206256324, 0.015569647416646066, -0.00431370006009896, 0.021374058766199827, -0.013236361112300294, 0.009808445710856794, -0.001653644899320668, -0.019703310709242562, -0.003451320004267524, -0.018651890324586713, 0.012235352289143882, -0.029670189297042186, -0.019530473996829834, -0.004565752279660496, -0.025277272798471813, 0.023376076412512648, -0.01924241405123876, 0.02771138129449385, 0.024974809017410837, 0.020797938875017682, 0.02063950599807485, 0.01741323311733867, -0.0005959242918383135, 0.017125173171747596, -0.007720010173998912, 0.010139715300212354, 0.007698405817777972, -0.031024071600113792, 0.0563157482340555, -0.00583321669218704, -0.0035845477989525907, 0.027552948417551022, -0.007856838694720801, 0.03145616244982301, -0.041768712599802874, -0.01924241405123876, 0.01737002347357418, 0.013466809441302196, -0.03162899729959052, 0.01587211026638443, 0.022598314000623187, -0.00796486187280941, -0.00654976606295855, -0.01454703470293002, -0.009707625381825746, -0.0129915098791511, 0.0006985457405873938, 0.0006584873432855891, -0.0013151743235527667, 0.005498347075286614, 0.0184646516393493, -0.028618770775031555, 0.002704164112937039, -0.003755583333439627, -0.00016327156355758858, -0.0067946172961077436, -0.0043605097314083135, -0.035690644208805335, -0.02686160343054532, -0.0005563160726026062, -0.034538404426441044, -0.005710791075612443, -0.005555959157537089, 0.01708196352798311, 0.01371166067445139, -0.018450247803879397, -0.0012719653782802362, -0.014395802812399534, 0.017989353008520812, 0.024859585784232495, 0.03557542097562699, -0.010406170423921182, -0.0015501233854777077, 0.020668311806369438, 0.01088867097248462, -0.0022450684000282785, -0.02791302195255595, -0.008901057161641699, 0.022151821178089285, 0.014186959305279877, -0.02472995871558425, 0.005221089074975359, 0.01354602587977361, -0.021374058766199827, 0.006067265514395112, 0.02516204956529347, -0.02007778807971739, -0.0549618659309839, 0.00414806526542118, 0.02029383257324939, -0.012653039303383198, -0.0036079526346072676, -0.028993248145506384, -0.02111480462890334, -0.008036876393545873, -0.0046521706358668615, -0.008944265874083578, -0.0008817339291755288, 0.00024687651057766526, 0.01614576823915082, -0.0059052316785848085, 0.0051490740885775915, 0.03154257801206155, -0.029338919707686626, -0.03047675751722623, -0.02637190096424693, 0.0071114835156547065, -0.009448371244529259, 0.03508572037197382, -0.0433530450945216, 0.018781517393234956, -0.010154118204359646, -0.020135399696306563, -0.03367422272702261, -0.004889819951281104, -0.025968617785477516, 0.004184072991450716, -0.0059052316785848085, 0.002111840605343212, 0.027797798719377608, 0.032493178999008956, -0.010240536560566012, -0.03816796234859186, -0.005674783815244212, 0.010939081602661448, -0.010377364615626597, 0.020034578435952903, -0.005051853787091409, 0.027783394883907707, -0.005768403157862918, 0.00851217595569697, 0.019055175366001344, -0.007914451242632582, -0.022367865671621287, 0.0036547623059166212, -0.00139529100174105, 0.008324936339136946, 0.002994024537961849, -0.006394934144883196, 0.00583321669218704, -0.025306078606766397, 0.02173413416384997, -0.006517359295796489, 0.0008542781894179314, -0.029929443434338673, 0.01924241405123876, -0.007640793735527497, 0.020509878929426607, -0.006751408118004561, -0.005836817651054515, 0.009390758696617478, -0.02709205175954722, -0.019991370654833637, -0.04413080750641106, -0.012509009330587663, 0.015281587471054995, -0.020999581395724998, 0.015195170046171238, 0.002135245440997889, -0.0150367362379058, -0.015252781662760409, 0.03505691270103402, -0.0021532490711820046, -0.011587216945902666, -0.0008821840490339632, -0.02514764572982357, 0.024744362551054153, 0.02771138129449385, -0.011227141548252521, -0.005109465869341884, -0.005044652335017762, 0.00475659238942669, -0.017053157719688523, -0.0071186849677283524, -0.004788999156588751, 0.013740466482745975, -0.026602349293248832, -0.028604366939561653, 0.04410199983547126, 0.013257965934182537, 0.007597585023085619, 0.007511166666879254, -0.012112927138230591, 0.015368005827261359, 0.0004964535656829479, 0.020898760135371338, -0.03301168727360193, 0.02691921504713449, -0.020985177560255096, -0.0036259562647913833, 0.004090453183170705, 0.006448945268266196, 0.006639784912371086, 0.012545017056617199, 0.0259974235937721, 0.019645697230008172, 0.023937794330870107, -0.015281587471054995, 0.0033270941410898417, -0.03537377845491968, 0.02000577262765832, -0.020509878929426607, -0.004879017540339983, -0.0051166673214155306, 0.006553367021826025, 0.005264298253078542, -0.014475019250870948, -0.03079362327111189, 0.009102698751026407, 0.01575688703320609, -0.011313559904458887, -0.02547891531917913, -0.005584764965831675, -0.009405161600764772, -0.016736291965802865, 0.0031920658669710375, 0.025349288250530885, 0.017110769336277695, -0.021906969013617484, 0.006679393131606794, -0.020711519587488708, 0.024571525838641424, 0.026876005403370002, -0.014698265662137899, 0.0015870310019781345, 0.0042416846080398874, -0.005880026363496394, -0.0001803751286478248, 0.016721888130332964, 0.003256879401295159, 0.03805273911541352, -0.008915460065788992, 0.03520094360515216, 0.005044652335017762, -0.014640654045548727, 0.0186950999683512, 0.01675069393862755, -0.0002891853325486529, -0.0022486691260651015, -0.00041206095256635827, 0.017658083419165253, 0.014179758318867534, -0.011817665274904568, -0.013632443304657366, -0.008728220449228968, 0.012833077002208272, -0.01797494917305091, 0.013178749495711123, 0.007532771488761497, -0.008252921818400483, -0.0018507861050283134, 0.0036745664155344747, 0.03422153867255539, 0.027999441240084924, 0.009397960614352429, -0.004151666224288655, 0.009282736449851479, -0.0011630426589667154, 0.011248746370134765, -0.0068954385564614015, 0.03096645998352462, -0.029310113899392042, -0.007417547324260546, -0.01719718676116145, -0.01852226325593847, -0.036468406620694796, -0.015195170046171238, -0.023577718933219964, 0.028229889569086824, 0.0193576372844171, 0.0011801461658492885, 0.029209292639038383, 0.024542720030346837, -0.000833573898290872, -0.012804271193913686, -0.036266764099987484, 0.02161890906802641, 0.021705328355555383, -0.016232185664034577, -0.008605795298315677, -0.03534497450927031, 0.014964721717169336, -0.010082102752300573, 0.0008016171927795825, -0.004662972581146678, 0.009045087134437236, -0.01569927541661692, 0.01852226325593847, -0.020668311806369438, -0.00039023139089704433, 0.0330692988901911, 0.004320901512172607, -0.007640793735527497, -0.017830920131577985, 0.005761201705789272, -0.007082677241698816, -0.011572814041755372, -0.0006256305144727569, 0.040270799392613126, 0.002700563386900216, 0.010377364615626597, -0.0009632009087314524, 0.014006921606454803, -0.03298287960266213, 0.012069717494466102, -0.02670317055360249, -0.032925267986072954, -0.018234203310347398, 0.006927845323623462, -0.006297713843397014, 0.00967881864220855, 0.009261131627969234, 0.02025062479213012, 0.005127469732356652, -0.015108751689964872, 0.002241467673991455, -0.019559279805124417, 0.006646986364444733, 0.03658362985387314, 0.011111918315074179, -0.011255948287869716, 0.005883627322363869, -0.03975229111802015, 0.012509009330587663, -0.011140724123368764, -0.012458598700410833, 0.007158293186964059, 0.005293104061373128, -0.013805280017070097, 0.008087287023722703, 0.023304060960453576, -0.008238518914253189, 0.016505843636800965, 0.02582458688135937, -0.017888531748167156, -0.005350716143623603, 0.0026285484005024477, -0.021806149615909043, 0.003964427073389937, 0.030275114996518915, 0.019746518490361832, 0.007669600009483387, 0.00795765995507446, 0.02405301756404845, 0.034451985138912074, 0.0182486071458173, 0.02377935959128206, -0.010463782971832963, -0.019544877832299735, 0.007489562310658314, 1.2750315833471895e-05, -0.0026393505786129175, -0.012307367741202956, 0.014633452127813777, 0.03762064640305909, 0.0034261146891791097, 0.01830621876240647, 0.005386723869653139, 0.0038311992787048704, -0.0027239682225548927, -0.01050699168427484, 0.008872250422024506, -0.0021514488245789193, -0.01737002347357418, 0.021244431697551584, -0.0001358158383519069, -0.021748536136674653, -0.007878443516603046, 0.03612273692115977, 6.734529845674195e-05, -0.041423039174977416, -0.007039468529256938, -0.001829181515976722, 0.023520105453985574, -0.00459095759474891, -0.022367865671621287, 0.005379521951918188, -0.0015645264060403267, -0.010867067081924985, 0.007100681104713584, -0.010708634204982156, -0.004479334389115435, 0.014611848237254142, 0.0019065977078450511, -0.021892567040792798, 0.013121136947799343, -0.005602768828846443, 0.001481709125116763, 0.006531762665605086, -0.021863761232498214, -0.044908566193010084, 0.01657785722621482, 0.0057143920344799185, 0.008195309270488702, 0.02095637175196051, -0.000974003203257248, -0.014741475305902385, -0.010139715300212354, -0.017874127912697255, -0.030447951708931647, -0.03401989615184808, -0.03885930547295235, 0.03062078655869916, -0.028402724418854337, 0.004101255594111826, -0.027264886609314733, -0.0021604507560863033, 0.018176591693758227, 0.01692353065104028, -0.02444189876999318, -0.006650587323312208, -0.008000868667516337, 0.000731402569400226, 0.005944839897820515, -0.002804985140460045, -0.006268907569441124, -0.0014574040497452173, -0.027552948417551022, 0.01908398117429593, -0.022209432794678456, 0.016390618540977404, -0.014273377661486241, -0.030275114996518915, 0.00727351735146501, 0.012465800618145784, 0.017989353008520812, 0.013149942756093928, 0.006348124007912538, 0.013574831688068195, -0.012300165823468004, 0.0055271528835812, 0.0054155296779477245, 0.010146916286624695, 0.01000288631382916, 0.004943831074664104, 0.004994241704840933, -0.02074032725842851, 0.004198475895598009, 0.025234063154707324, -0.015007930429611214, 0.009261131627969234, 0.008080085105987752, 0.015454424183467725, 0.04456289649347506, -0.0029562165653292272, -0.04657931797525778, -0.017802114323283397, 0.0261990642518342, 0.022958389398273334, 0.004187673484656888, -0.013344383359066294, -0.006585773788988086, -0.04366991084840725, -0.026184662279009514, -0.011227141548252521, 0.007503965214805607, -0.02658794545777893, -0.00528230211609331, -0.014950318813022044, -0.004792599649794922, -0.0016941533582732439, 0.013668451030686903, -0.018479055474819202, -0.02880600946026897, 5.6908744505818965e-05, -0.001888593961245609, 0.0056135707741262605, 0.005746798801641979, 0.012314568727615298, -0.0036349581962987674, -0.021359654930729922, -0.028042649021204194, -0.0007034967679918572, -0.0048754170471338116, -0.0021172415779831203, 0.013308376564359367, 0.03966587555578161, 0.025781377237594882, 0.058245750428309255, 0.0020308236874380598, 0.018479055474819202, 0.004151666224288655, 0.00221086115343248, 0.009023482312554992, 0.020423459641897634, -0.001109931542469932, -0.0016095357143312687, -0.0010577206656900175, 0.02892123269344731, -0.010089304670035524, 0.004933029129384287, -0.0016293398239491223, 0.016131364403680917, 0.020265026764954806, 0.004194874936730534, -0.0016545451390375368, -0.014734273388167435, -0.03744781155329157, -0.026559139649484344, 0.00025250265956211726, -0.010420573328068476, 0.02130204331414075, -0.03643960267504543, -0.026026229402066687, 0.02448510841375767, 0.013070726317622515, 0.0298718318177495, -0.012357777440057175, 0.016721888130332964, 0.012026508782024225, 0.01588651410185433, 0.031715416587119495, 0.020927565943665925, -0.03891691708954152, -0.019991370654833637, -0.013834085825364682, 0.024139434988932205, 0.003224472634133098, 0.009210720997792406, 0.04243125177851399, 0.013639645222392317, 0.0013385792756227695, -0.029612577680453014, 0.03497049341350505, 0.00027635764417906, -0.007763219352102094, 0.02007778807971739, -0.02045226545019222, -0.018752711584940372, -0.04044363796767107, -0.0399251296930781, -0.013286771742477122, -0.01260262867320637, 0.02294398556280343, -0.006596576199929208, 0.013632443304657366, -0.013221958208153, 0.015252781662760409, 0.009585199299589843, 0.004194874936730534, 0.03537377845491968, -0.020149803531776464, 0.023548913124925377, 0.02581018490853469, -0.006909841460608694, 0.023030404850332406, -0.0034387173467233167, 0.026890409238839903, 0.024542720030346837, 0.026328691320482444, 0.029987055050927844, -0.010154118204359646, -6.132529459615984e-05, -0.020898760135371338, 0.003975229018669754, -0.02442749493452328, -0.039896322022138296, 0.022929583589978746, 0.008447362421372848, 0.008166503462194117, -0.016765097774097452, -0.013438002701685001, 0.005973646171776406, 0.005069857650106177, -0.010521394588422134, -0.010233334642831061, -0.00039135663233546734, -0.010478185875980255, -0.02033704221701388, 0.023534509289455476, 0.010550200396716718, 0.0442172230686496, 0.013157144673828879, -0.024859585784232495, -0.013956510976277975, -0.001522217584069339, -0.006592975241061732, 0.013906100346101145, -0.0008272725695187684, 0.02892123269344731, -0.02343368802910182, -0.019890549394479977, 0.026731976361897076, -0.0009731029635403791, -0.0031182504011395317, -0.022238238602973043, -0.023476897672866304, 0.03497049341350505, -0.021273237505846167, 0.00818090636634141, 0.013625242318245023, -0.003044435168138678, 0.036266764099987484, -0.012811472180326028, -0.01696673843215955, -0.007885644503015387, -0.0006472349871090221, -0.013898899359688804, 0.01276826346788415, -0.013459607523567245, -0.011493597603283959, 0.01741323311733867, 0.015584051252115969, 0.0071186849677283524, -0.01487830336096297, 0.013041920509327929, 0.04669454120843612, -0.0259830197583022, -0.002414303687912229, -0.017614873775400768, -0.020322638381543977, -0.020279430600424708, 0.022137417342619384, -0.008224116010105897, 0.007287920255612303, 0.02171973032838007, -0.02748093296549195, 0.05620052500087716, 0.013438002701685001, -0.0008385249256953354, -0.046435287071139635, 0.028978844310036483, -0.01626099147232916, -0.0036763668949682123, 0.03906094799365967, -0.025565332744062884, -0.02035144605248378, -0.01708196352798311, -0.010816656451748155, 0.02311682227521616, 0.01857987487252764, 0.002065030701203206, -0.0010919277958704899, 0.022036596082265728, 0.016174574047445406, -0.016347410759858134, -0.0036727661689313893, 0.015555244512498774, -0.026343095155952345, 0.0010064099122116458, 0.018493457447643885, -0.020668311806369438, 0.00440011795064402, -0.04090453090038444, -0.0002648802571771073, 0.00896587069596582, -0.0442460307395894, -0.013329980454919002, 0.003174062003956269, -0.013675652948421853, 0.0034387173467233167, 0.00779922707813163, -0.03041914590063706, -0.0031272523326469157, -0.02691921504713449, 0.0189255482973531, 0.008562586585873798, 0.008555384668138847, 0.01050699168427484, 0.022209432794678456, -0.010600611026893548, 0.012861882810502856, -0.00880023590128804, -0.019530473996829834, -0.007417547324260546, -0.01797494917305091, -0.028950038501741895, 0.003690769799115505, -0.006247303213220185, 0.015497632895909602, 0.017427635090163353, -0.0186806961328813, -0.030736011654522718, 0.011637627576079494, -0.0070358675703894626, -0.0012026508782024224, -0.01731241185698501, 0.03491288179691587, 0.024355481345109425, 0.009858856341033624, -0.0032460772231846895, -0.0014979125086977934, -0.00599885148686482, 0.027106453732371902, -0.016059350814267064, 0.018263009118641985, 0.012789868289766393, -0.008353742147431531, 0.012206546480849298, 0.007568778749129729, -0.01770129306292974, 0.002795983208952661, -0.0005297605143542146, 0.020999581395724998, 0.027034440142958048, 0.008865049435612163, 0.01686591903445111, 0.008490571133814726, 0.005408328225874078, -0.004961834937678872, -0.0006584873432855891, 0.0077344135438075085, 0.04067408443402776, -0.03822557396518103, -0.019055175366001344, 0.02035144605248378, 0.008360944065166482, 0.014950318813022044, -0.008368145982901433, -0.0021838555917409797, -0.020034578435952903, -0.007777622256249387, -0.013207555304005709, -0.01830621876240647, 0.00591603408952593, 0.009873259245180916, 0.0054659403081245535, 0.010622215848775792, 0.01963129525718349, 0.011320761822193838, 0.017715695035754424, -0.005239092937990127, -0.02481637614046801, 0.020999581395724998, -0.023073612631451672, -0.006863031789299341, 0.020279430600424708, 0.00569278767825898, -0.0010433176451273988, -0.014849497552668386, 0.01587211026638443, -0.01663547070544921, -0.033616611110433445, -0.010586208122746256, -0.03479765856373753, -0.000824572024991151, 0.003024630825690172, -0.006092470829483527, -0.018752711584940372, 0.012235352289143882, -0.012818674098060978, -0.00727351735146501, -0.0023260853179334308, -0.02074032725842851, 0.020265026764954806, -0.028935636528917213, -0.015728081224911504, 0.010931880616249107, -0.010046095957593646, -0.035892286729512654, -0.008778631079405798, 0.0055163509383013825, -0.008591392394168383, 0.012509009330587663, 0.2095925140146736, 0.011270351192017008, 0.010651021657070376, 0.03571945187974514, 0.0065713708848407935, -0.0059304369936732226, -0.008540981763991555, -0.003561142963297914, -0.013913302263836096, 0.004709782252456032, 0.001567226892360281, -0.0036817681004387734, -0.018176591693758227, -0.011731246918698202, -0.008548182750403897, -0.014525429881047778, -0.03557542097562699, -0.048250066032215044, -0.010910275794366863, 0.005735996390700857, 0.003445918798796963, -0.01088867097248462, -0.0030894443600142938, -0.026948020855429074, -0.0048754170471338116, -0.002146047619108358, 0.009880461162915867, -0.0028679981953504286, 0.04029960706355293, 0.004716984170190983, -0.02177734194496924, 0.02604063137489137, 0.011284754096164301, -0.019919355202774564, -0.008886653326171797, -0.010751842917424034, 0.00583321669218704, -0.006909841460608694, 0.0291948906662137, 0.02810026250043858, -0.018882338653588616, -0.0014853098511535862, -0.010269342368860597, -0.01421576511357446, -0.0017553661665605424, -0.009585199299589843, -0.018882338653588616, -0.026731976361897076, -0.011623224671932202, 0.018435845831054714, -0.015800096676970576, -0.0031110489490658853, 0.0291948906662137, 0.0182486071458173, -0.018839129009824127, -0.017470844733927838, 0.009469975135088893, 0.015267184566907701, 0.01588651410185433, 0.0007993667681103995, -0.010982291246425935, 0.011774456562462688, -0.0025169249620383203, 0.02543570567541464, -0.01807577043340457, 0.012818674098060978, -0.01260262867320637, 0.012112927138230591, 0.014921513004727459, -0.013553226866185951, -0.025637348196121956, 0.009405161600764772, 0.003723176566277566, 0.004486535841189082, -0.006780214391960452, -0.022569508192328603, 0.020149803531776464, 0.013329980454919002, 0.020221818983835536, 0.02990063762604409, 0.01028374527300789, -0.014467818264458606, -0.014619049223666485, 0.014006921606454803, -0.0339622845352589, -0.03281004475289461, 0.012897890536532392, 0.0024971208524204665, -0.002360292331698577, -0.027639365842434777, 0.004328102964246253, -0.020279430600424708, -0.016001737335032674, -0.014475019250870948, 0.009311542258146064, -0.002749173537643307, 0.012134531028790224, 0.01902636955770676, 0.003247877469787775, 0.03269482151971627, -0.02333286676874816, 0.03860005133565586, 0.020855550491606853, 0.009527587683000672, -0.0038420014568153397, -0.013567629770333245, -0.010687029383099914, 0.02504682446946991, 0.009585199299589843, -0.005095062965194591, -0.015166363306554043, -0.01420856412716212, 0.007255513488450242, -0.02405301756404845, -0.010449380067685669, 0.027005632472018246, -0.022569508192328603, -7.150866704065027e-05, 0.031340939216644666, 0.001648243810265433, -0.022151821178089285, 0.0008799335661571172, -0.021316447149610656, -0.013193152399858415, 0.00638773269280955, 0.0014484021182378333, -0.01700994807592404, 0.002749173537643307, -0.031081683216702963, -0.00669379650141539, 0.027725783267318536, -0.026011825566596786, 0.03355899949384427, -0.007388741515965961, -0.007205102858273413, 0.009686020559943501, 0.0010442177684289414, -0.0030192298530502637, -0.005883627322363869, 0.0035053311276505243, -0.02274234490474133, 0.0008385249256953354, 0.019717712682067248, -0.008447362421372848, 0.024931601236291567, -0.010831059355895449, 0.00688463614552028, 0.006459747679207318, 0.02366413635810372, -0.014345392182222704, -0.013373190098683489, 0.007230308173361828, 0.004144464306553705, -0.03413511938502641, 0.030044666667517015, -0.024557122003171523, -0.01437419799051729, -0.03197467072441598, 0.008829041709582626, 0.0027167667704812463, -0.0073347299269216565, -0.0129915098791511, 0.03309810283584047, 0.028503545679207994, -0.03442318119326271, -0.031081683216702963, -0.18516502466808596, 0.007352733789936425, 0.01133516472634113, -0.017153978980042183, 0.015958529553913407, 0.0186950999683512, 0.011407179247077593, 0.00884344461372992, -0.028935636528917213, -0.011263149274282057, 0.006016854884218283, 0.011824866261316909, 0.0031182504011395317, -0.02304480682315709, 0.019141592790885103, -0.008058481215428117, -0.031052877408408376, 0.01310673404365205, 0.027783394883907707, 0.027999441240084924, 0.04228722087439585, -0.02403861372857855, 0.022151821178089285, 0.012509009330587663, 0.014950318813022044, -0.013207555304005709, -0.008418555681755653, 0.0031272523326469157, 0.01641942434927199, -0.03450960048079168, -0.0016815508171443628, 0.008166503462194117, 0.03517213593421236, -0.003896012813028992, 0.016088156622561647, 0.021906969013617484, -0.0037123743881670966, -0.016664276513743793, 0.004212878799745302, 0.024873989619702396, 0.03194586305347618, 0.015281587471054995, -0.003899613539065815, 0.008735422366963919, -0.02719287301990088, 0.00033689527267870685, 0.006963852583991695, -0.03416392705596622, 0.018810323201529543, -0.01737002347357418, 0.025392496031650152, -0.034365569576673534, 0.023520105453985574, -0.004464931484968142, 0.010319752999037425, 0.012530614152469905, 0.004050844963934997, 0.025032422496645227, -0.005487544664345492, -0.015713677389441603, 0.011191134753545594, -0.018392636187290225, 0.003957225621316291, -0.0043173005533051305, 1.8552308349035325e-05, -0.021993388301146458, -0.014575840511224606, 0.000804317795514863, -0.03462482371397002, -0.00719069995412612, -0.007460756502363729, 0.02000577262765832, 0.011565612124020422, 0.00023472395833997668, 0.004987040252767287, 0.023750553782987478, -0.011536806315725836, 0.0014366997004104948, 0.008029675407133532, -0.021532491643142655, -0.007662398557409741, 0.025248466990177226, -0.005077059102179823, -0.006992658857947584, 0.006999860310021231, -0.005177879896872177, 0.01702435191139394, 0.034538404426441044, -0.010967888342278643, -0.02791302195255595, 0.016765097774097452, -0.02516204956529347, 0.009426766422647014, -0.010377364615626597, 0.009138706477055943, 0.02025062479213012, -0.011234343465987472, -0.0189111444618832, 0.02123002786208168, -0.02771138129449385, 0.020610700189780267, 0.0070358675703894626, -0.02444189876999318, -0.01237938226193942, 0.02958377187215843, 0.03986751807648893, -0.02271353723380153, 0.01183206817905186, 0.02033704221701388, -0.011097514479604277, 0.0042596884710546555, 0.003982430936404705, 0.01978972813412632, -9.519485671068011e-05, -0.014150951579250339, 0.028791605624799068, -0.016333006924388233, -0.010478185875980255, 0.01051419360200979, -0.04784678099080041, 0.054040072614976294, -0.0056567799522294435, -0.026501528032895173, 0.006182489678896063, -0.01796054720022623, -0.003217271182059452, -0.09396519858276396, -0.0255365269357683, 0.022238238602973043, 0.013963712894012926, -0.017038753884218622, 0.004086852689964534, -0.02481637614046801, 0.03200347467006535, -0.03880169385636318, 0.02328965898762889, -0.0090090794084077, -0.04934469419799016, 0.00885064653146487, 0.015612857060410554, -0.008195309270488702, -0.002551132208634119, -0.040184383830374586, 0.0009150408778467955, -0.060607841609627004, 0.012372181275527076, -0.014647855963283678, 0.01133516472634113, 0.021100400793433435, -0.0007750616927388539, -0.0010082102752300573, 0.015454424183467725, -0.029929443434338673, 0.023692942166398306, 0.013992518702307511, 0.0027185670170843316, 0.01762927761087067, -0.009887662149328208, 0.015900916074679017, -0.013438002701685001, -0.015771289006030774, -0.025291676633941714, -0.0002087310353627123, -0.03335735697313696, 0.01338759300283078, -0.025234063154707324, -0.00710428206358106, -0.004929428170516812, -0.006765811487813159, 0.010298148177155183, -0.027797798719377608, 0.024744362551054153, -0.03966587555578161, 0.0296413834887476, 0.021215625889256996, -0.02228144824673753, 0.00038505533266719526, -0.010096506587770476, 0.01664987267827389, 0.020221818983835536, 0.01338039108509583, -0.006207694993984478, 0.021820551588733725, 0.002444909975640552, -0.017240396404925938, -0.016390618540977404, -0.033328553027487585, 0.02506122830493981, -0.007763219352102094, 0.0214460742182589, 0.0300734724758116, -0.003156058373772153, 0.000523459185582111, -0.0008794834462986828, 0.005937638445746869, 0.01299871179688605, -0.01758606796710618, 0.009491579956971136, -0.021215625889256996, 0.029266904255627554, -0.0259974235937721, 0.011241545383722422, -0.005541555787728493, -0.012127330042377883, 0.03381825363114076, 0.012264158097438468, -0.027552948417551022, 0.003899613539065815, -0.008706616558669335, -0.0010343157136200147, -0.006416538501104136, 0.032464371328069154, 0.001843584536539341, -0.009412363518499722, 0.028733994008209897, -0.011911284617523275, 6.796417688229987e-05, 0.0006818922371479289, 0.010939081602661448, -0.017946143364756327, -0.021604507095201727, 0.020855550491606853, -0.0068954385564614015, -0.012818674098060978, -0.010651021657070376, 0.017384427309044083, -0.031801832149358035, -0.0062545046652938315, -0.07241830496679662, 0.03566184026315597, -0.0016941533582732439, -0.004331703457452423, -0.0042092778408778266, -0.03594989834610182, -0.0015060142004883086, -0.02274234490474133, 0.0016923529952548324, 0.01764367958369535, -0.021762939972144554, 0.003697971484019804, -0.0013790877345753456, -0.010334155903184719, -0.004014837703566766, -0.011796060453022323, 0.04456289649347506, -0.013438002701685001, 0.027408917513432877, 0.018651890324586713, -0.019976966819363732, 0.010377364615626597, 0.014921513004727459, 0.019098383147120614, -0.03623796015433811, -0.022094209561500114, -0.011291955082576643, 0.03540258612585948, -0.006899039049667573, -0.014482221168605898, 0.012984308892738758, -0.033040491219251296, 0.009282736449851479, 0.013495615249596781, 0.01758606796710618, 0.013063525331210172, -0.009534788669413015, -0.008080085105987752, 0.011435985986694788, 0.006207694993984478, -0.013848488729511974, -0.02134525295790524, 0.0018399838105025179, 0.0017778708789136766, -0.01233617354949754, -0.027653767815259463, 0.0076768014615570335, 0.004356908772540838, 0.02506122830493981, 0.03376064201455159, 0.0011117319054883435, 0.002936412455711374, 0.020092191915187293, -0.052254101324840686, 0.023981002111989377, 0.009700423464090795, 0.002020021276496938, -0.023966600139164695, 0.004194874936730534, -0.02000577262765832, 0.010751842917424034, 0.01376207037330561, 0.019602489448888906, 0.007806428530205277, 0.01011811047833011, -0.005455137897183431, -0.019717712682067248, -0.004706181759249861, 0.01957368364059432, -0.023952196303694794, 0.023851375043341134, -0.021762939972144554, 0.016549051417920235, 0.011630425658344544, -0.006765811487813159, -0.029022053953800968, 0.004832207869030629, -0.010262140451125647, -0.02304480682315709, -0.001146839275385685, 0.016621066869979308, -0.003633157949695682, -0.01696673843215955, -0.0032712823054424516, 0.022295850219562215, 0.0018102776460757373, -0.0027365708800990997, -0.02274234490474133, -0.006182489678896063, 0.014014123524189754, -3.685143882961706e-05, 0.002689760975959094, 0.019184802434649588, 0.0006283310590003742, 0.006672191679533147, 0.010622215848775792, 7.252137851446468e-05, 0.005397525814932956, -0.002333286770007077, 0.012134531028790224, 0.001798575228248399, 0.019213608242944175, -0.010831059355895449, -0.019055175366001344, -0.032550790615598124, 0.005869224418216576, -0.022699135260976847, -0.001132436254823066, -0.021518087807672753, 0.014748676292314728, 0.012948301166709222, 0.018032560789640082, -0.018795921228704857, 0.025291676633941714, -0.01476307919646202, 0.02239667147991587, -0.009311542258146064, 0.012926696344826977, -0.010679827465364961, 0.01338039108509583, 0.009822848615004086, 0.014640654045548727, 0.0005671183089207388, 0.023937794330870107, 0.03957945626825264, 0.02274234490474133, 0.011644829493814445, -0.0003825798189649636, 0.021906969013617484, 0.007936055133192215, -0.014964721717169336, -0.009995685327416818, 0.001744563872034747, -0.009916468888945403, -0.0009532988539225256, -0.020927565943665925, -0.020941967916490608, 0.02334727060421806, 0.00425248701898101, 0.0640645646820103, 0.017571665994281498, -0.016793903582392036, -0.003953624662448815, -0.0046737749920878, -0.0113927763429303, 0.011918486535258226, -0.0223390598633267, -0.018234203310347398, -0.018190995529228128, -0.030044666667517015, 0.007741614995881155, -0.021849357397028313, -0.03364541878137325, 0.001975012084621322, -0.010154118204359646, 0.007532771488761497, 0.019429652736476174, -0.02746652913002205, -0.017067559692513206, 0.015713677389441603, 0.0032856854424203968, -0.0028607967432767822, -0.0042596884710546555, -0.029929443434338673, 0.005937638445746869, 0.02035144605248378, 0.010636618752923084, -0.006740606172724744, -0.05778485377030545, 0.0053471151847561274, 0.009858856341033624, -0.021100400793433435, -0.026357498991422246, -0.00830333244857731, 0.006373329323000953, -0.008533779846256603, 0.01924241405123876, 0.004637767266058264, 0.022526298548564114, -0.0038384007307785168, 0.00489342091014858, -0.042834536819928624, -0.02742332134890278, 0.013401995906978074, -0.01760047180257608, -0.030303920804813502, -0.03315571445242964, -0.04928708258140099]], node_map={'ddaf50de-f60d-4ecd-bde7-cfe98cdf2955': Node(page_content=\"Davis Bennett said: to inaugurate this channel -- GPU-accelerated array computing came up in the scicomp virtual happy hour yesterday. Here's the library I was talking about (CuPy): https://cupy.chainer.org/\\nCuPy\\nCuPy is NumPy-compatible matrix library accelerated by CUDA\\nDavis Bennett said: a lower-level vendor-agnostic approach using OpenCL is here: https://github.com/inducer/pyopencl\\ninducer/pyopencl\\nOpenCL integration for Python, plus shiny features - inducer/pyopencl\\nCameron Arshadi said: nice, seems like a good alternative to numba\\nDavis Bennett said: yeah I'm not sure how a cuda kernel jitted with numba will compare in performance to the same operation on a cupy array\\nOthers reacted to the previous message with +1::skin-tone-3 a total of 1 times.\\n\", metadata={'source': './tempTestGen.txt'}, doc_id='ddaf50de-f60d-4ecd-bde7-cfe98cdf2955', wins=36)}, run_config=RunConfig(timeout=60, max_retries=15, max_wait=90, max_workers=16, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), node_filter=NodeFilter(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=15, max_wait=90, max_workers=16, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), threshold=1.5, context_scoring_prompt=Prompt(name='score_context', instruction='\\n    Given a context, perform the following task and output the answer in VALID JSON format: Assess the provided context and assign a numerical score of 1 (Low), 2 (Medium), or 3 (High) for each of the following criteria in your JSON response:\\n\\nclarity: Evaluate the precision and understandability of the information presented. High scores (3) are reserved for contexts that are both precise in their information and easy to understand. Low scores (1) are for contexts where the information is vague or hard to comprehend.\\ndepth: Determine the level of detailed examination and the inclusion of innovative insights within the context. A high score indicates a comprehensive and insightful analysis, while a low score suggests a superficial treatment of the topic.\\nstructure: Assess how well the content is organized and whether it flows logically. High scores are awarded to contexts that demonstrate coherent organization and logical progression, whereas low scores indicate a lack of structure or clarity in progression.\\nrelevance: Judge the pertinence of the content to the main topic, awarding high scores to contexts tightly focused on the subject without unnecessary digressions, and low scores to those that are cluttered with irrelevant information.\\nStructure your JSON output to reflect these criteria as keys with their corresponding scores as values\\n    ', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"clarity\": {\"title\": \"Clarity\", \"type\": \"integer\"}, \"depth\": {\"title\": \"Depth\", \"type\": \"integer\"}, \"structure\": {\"title\": \"Structure\", \"type\": \"integer\"}, \"relevance\": {\"title\": \"Relevance\", \"type\": \"integer\"}}, \"required\": [\"clarity\", \"depth\", \"structure\", \"relevance\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'The Pythagorean theorem is a fundamental principle in geometry. It states that in a right-angled triangle, the square of the length of the hypotenuse (the side opposite the right angle) is equal to the sum of the squares of the lengths of the other two sides. This can be written as a^2 + b^2 = c^2 where c represents the length of the hypotenuse, and a and b represent the lengths of the other two sides.', 'output': {'clarity': 3, 'depth': 1, 'structure': 3, 'relevance': 3}}, {'context': 'Albert Einstein (14 March 1879 - 18 April 1955) was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time.', 'output': {'clarity': 3, 'depth': 2, 'structure': 3, 'relevance': 3}}, {'context': \"I love chocolate. It's really tasty. Oh, and by the way, the earth orbits the sun, not the other way around. Also, my favorite color is blue.\", 'output': {'clarity': 2, 'depth': 1, 'structure': 1, 'relevance': 1}}], input_keys=['context'], output_key='output', output_type='json', language='english')), question_filter=QuestionFilter(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=15, max_wait=90, max_workers=16, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), filter_question_prompt=Prompt(name='filter_question', instruction='\\nAsses the given question for clarity and answerability given enough domain knowledge, consider the following criteria:\\n1.Independence: Can the question be understood and answered without needing additional context or access to external references not provided within the question itself? Questions should be self-contained, meaning they do not rely on specific documents, tables, or prior knowledge not shared within the question.\\n2.Clear Intent: Is it clear what type of answer or information the question seeks? The question should convey its purpose without ambiguity, allowing for a direct and relevant response.\\nBased on these criteria, assign a verdict of \"1\" if a question is specific, independent, and has a clear intent, making it understandable and answerable based on the details provided. Assign \"0\" if it fails to meet one or more of these criteria due to vagueness, reliance on external references, or ambiguity in intent.\\nProvide feedback and a verdict in JSON format, including suggestions for improvement if the question is deemed unclear. Highlight aspects of the question that contribute to its clarity or lack thereof, and offer advice on how it could be reframed or detailed for better understanding and answerability.\\n', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"feedback\": {\"title\": \"Feedback\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"type\": \"integer\"}}, \"required\": [\"feedback\", \"verdict\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'What is the discovery about space?', 'output': {'feedback': \"The question is too vague and broad, asking for a 'discovery about space' without specifying any particular aspect, time frame, or context of interest. This could refer to a wide range of topics, from the discovery of new celestial bodies to advancements in space travel technology. To improve clarity and answerability, the question could specify the type of discovery (e.g., astronomical, technological), the time frame (e.g., recent, historical), or the context (e.g., within a specific research study or space mission).\", 'verdict': 0}}, {'question': \"How does ALMA-13B-R perform compared to other translation models in the WMT'23 study, based on the results in context1 and context2?\", 'output': {'feedback': \"This question asks for a comparison of the ALMA-13B-R model's performance against other translation models within the WMT'23 study, specifically referring to results in 'context1' and 'context2'. While it clearly specifies the model of interest (ALMA-13B-R) and the study (WMT'23), it assumes access to and understanding of 'context1' and 'context2' without explaining what these contexts entail. This makes the question unclear for those not familiar with the WMT'23 study or these specific contexts. To improve clarity and answerability for a broader audience, the question could benefit from defining or describing 'context1' and 'context2' or explaining the criteria used for comparison in these contexts.\", 'verdict': 0}}, {'question': 'How do KIWI-XXL and XCOMET compare to the gold standard references in Table 1 in terms of evaluation scores, translation model performance, and success rate in surpassing the references?', 'output': {'feedback': \"The question requests a comparison between KIWI-XXL and XCOMET models and gold standard references in 'Table 1', focusing on evaluation scores, translation model performance, and success rates in surpassing the references. It specifies the models and criteria for comparison, making the intent clear. However, the question assumes access to 'Table 1' without providing its content or context, making it unclear for those without direct access to the source material. To be clearer and more answerable for a general audience, the question could include a brief description of the content or key findings of 'Table 1', or alternatively, frame the question in a way that does not rely on specific, unpublished documents.\", 'verdict': 0}}, {'question': 'What is the configuration of UL2 training objective in OpenMoE and why is it a better choice for pre-training?', 'output': {'feedback': 'The question asks for the configuration of the UL2 training objective within the OpenMoE framework and the rationale behind its suitability for pre-training. It is clear in specifying the topic of interest (UL2 training objective, OpenMoE) and seeks detailed information on both the configuration and the reasons for its effectiveness in pre-training. However, the question might be challenging for those unfamiliar with the specific terminology or the context of OpenMoE and UL2. For broader clarity and answerability, it would be helpful if the question included a brief explanation or context about OpenMoE and the UL2 training objective, or clarified the aspects of pre-training effectiveness it refers to (e.g., efficiency, accuracy, generalization).', 'verdict': 1}}, {'question': 'What is the detailed configuration of the UL2 training objective in OpenMoE, based on the provided context?', 'output': {'feedback': \"The question seeks detailed information on the UL2 training objective's configuration within the OpenMoE framework, mentioning 'the provided context' without actually including or describing this context within the query. This makes the question unclear for those who do not have access to the unspecified context. For the question to be clear and answerable, it needs to either include the relevant context directly within the question or be framed in a way that does not require external information. Detailing the specific aspects of the configuration of interest (e.g., loss functions, data augmentation techniques) could also help clarify the query.\", 'verdict': 0}}], input_keys=['question'], output_key='output', output_type='json', language='english')), question_answer_prompt=Prompt(name='answer_formulate', instruction=\"Answer the question using the information from the given context. Output verdict as '1' if answer is present '-1' if answer is not present in the context.\", output_format_instruction='', examples=[{'context': 'Climate change is significantly influenced by human activities, notably the emission of greenhouse gases from burning fossil fuels. The increased greenhouse gas concentration in the atmosphere traps more heat, leading to global warming and changes in weather patterns.', 'question': 'How do human activities contribute to climate change?', 'answer': {'answer': 'Human activities contribute to climate change primarily through the emission of greenhouse gases from burning fossil fuels. These emissions increase the concentration of greenhouse gases in the atmosphere, which traps more heat and leads to global warming and altered weather patterns.', 'verdict': '1'}}, {'context': 'The concept of artificial intelligence (AI) has evolved over time, but it fundamentally refers to machines designed to mimic human cognitive functions. AI can learn, reason, perceive, and, in some instances, react like humans, making it pivotal in fields ranging from healthcare to autonomous vehicles.', 'question': 'What are the key capabilities of artificial intelligence?', 'answer': {'answer': 'Artificial intelligence is designed to mimic human cognitive functions, with key capabilities including learning, reasoning, perception, and reacting to the environment in a manner similar to humans. These capabilities make AI pivotal in various fields, including healthcare and autonomous driving.', 'verdict': '1'}}, {'context': 'The novel \"Pride and Prejudice\" by Jane Austen revolves around the character Elizabeth Bennet and her family. The story is set in the 19th century in rural England and deals with issues of marriage, morality, and misconceptions.', 'question': \"What year was 'Pride and Prejudice' published?\", 'answer': {'answer': 'The answer to given question is not present in context', 'verdict': '-1'}}], input_keys=['context', 'question'], output_key='answer', output_type='json', language='english'), find_relevant_context_prompt=Prompt(name='find_relevant_context', instruction='Given a question and set of contexts, find the most relevant contexts to answer the question.', output_format_instruction='', examples=[{'question': 'What is the capital of France?', 'contexts': ['1. France is a country in Western Europe. It has several cities, including Paris, Lyon, and Marseille. Paris is not only known for its cultural landmarks like the Eiffel Tower and the Louvre Museum but also as the administrative center.', '2. The capital of France is Paris. It is also the most populous city in France, with a population of over 2 million people. Paris is known for its cultural landmarks like the Eiffel Tower and the Louvre Museum.', '3. Paris is the capital of France. It is also the most populous city in France, with a population of over 2 million people. Paris is known for its cultural landmarks like the Eiffel Tower and the Louvre Museum.'], 'output': {'relevant_contexts': [1, 2]}}, {'question': 'How does caffeine affect the body and what are its common sources?', 'contexts': ['1. Caffeine is a central nervous system stimulant. It can temporarily ward off drowsiness and restore alertness. It primarily affects the brain, where it alters the function of neurotransmitters.', '2. Regular physical activity is essential for maintaining good health. It can help control weight, combat health conditions, boost energy, and promote better sleep.', '3. Common sources of caffeine include coffee, tea, cola, and energy drinks. These beverages are consumed worldwide and are known for providing a quick boost of energy.'], 'output': {'relevant_contexts': [1, 2]}}], input_keys=['question', 'contexts'], output_key='output', output_type='json', language='english'), rewrite_invalid_question_prompt=Prompt(name='rewrite_question', instruction='Given a context, question and feedback, rewrite the question to improve its clarity and answerability based on the feedback provided.', output_format_instruction='', examples=[{'context': \"The Eiffel Tower was constructed using iron and was originally intended as a temporary exhibit for the 1889 World's Fair held in Paris. Despite its initial temporary purpose, the Eiffel Tower quickly became a symbol of Parisian ingenuity and an iconic landmark of the city, attracting millions of visitors each year. The tower's design, created by Gustave Eiffel, was initially met with criticism from some French artists and intellectuals, but it has since been celebrated as a masterpiece of structural engineering and architectural design.\", 'question': 'Who created the design for the Tower?', 'feedback': \"The question asks about the creator of the design for 'the Tower', but it does not specify which tower it refers to. There are many towers worldwide, and without specifying the exact tower, the question is unclear and unanswerable. To improve the question, it should include the name or a clear description of the specific tower in question.\", 'output': 'Who created the design for the Eiffel Tower?'}, {'context': \"'Exploring Zero-Shot Learning in Neural Networks' was published by Smith and Lee in 2021, focusing on the application of zero-shot learning techniques in artificial intelligence.\", 'question': 'What datasets were used for the zero-shot evaluations in this study?', 'feedback': \"The question asks about the datasets used for zero-shot evaluations in 'this study', without specifying or providing any details about the study in question. This makes the question unclear for those who do not have access to or knowledge of the specific study. To improve clarity and answerability, the question should specify the study it refers to, or provide enough context about the study for the question to be understood and answered independently.\", 'output': 'What datasets were used for the zero-shot evaluations Exploring Zero-Shot Learning in Neural Networks paper?'}], input_keys=['context', 'question', 'feedback'], output_key='output', output_type='str', language='english'), max_tries=5, is_async=True, compress_question_prompt=Prompt(name='compress_question', instruction='Rewrite the following question to make it more indirect and shorter while retaining the essence of the original question.\\n    The goal is to create a question that conveys the same meaning but in a less direct manner. The rewritten question should shorter so use abbreviation wherever possible.', output_format_instruction='', examples=[{'question': 'What is the distance between the Earth and the Moon?', 'output': 'How far is the Moon from Earth?'}, {'question': 'What ingredients are required to bake a chocolate cake?', 'output': \"What's needed for a chocolate cake?\"}], input_keys=['question'], output_key='output', output_type='str', language='english'), reasoning_question_prompt=Prompt(name='reasoning_question', instruction=\"Complicate the given question by rewriting question into a multi-hop reasoning question based on the provided context.\\n    Answering the question should require the reader to make multiple logical connections or inferences using the information available in given context.\\n    Rules to follow when rewriting question:\\n    1. Ensure that the rewritten question can be answered entirely from the information present in the contexts.\\n    2. Do not frame questions that contains more than 15 words. Use abbreviation wherever possible.\\n    3. Make sure the question is clear and unambiguous.\\n    4. phrases like 'based on the provided context','according to the context',etc are not allowed to appear in the question.\", output_format_instruction='', examples=[{'question': 'What is the capital of France?', 'context': 'France is a country in Western Europe. It has several cities, including Paris, Lyon, and Marseille. Paris is not only known for its cultural landmarks like the Eiffel Tower and the Louvre Museum but also as the administrative center.', 'output': 'Linking the Eiffel Tower and administrative center, which city stands as both?'}, {'question': 'What does the append() method do in Python?', 'context': 'In Python, lists are used to store multiple items in a single variable. Lists are one of 4 built-in data types used to store collections of data. The append() method adds a single item to the end of a list.', 'output': 'If a list represents a variable collection, what method extends it by one item?'}], input_keys=['question', 'context'], output_key='output', output_type='str', language='english'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|██████████| 4/4 [04:10<00:00, 62.71s/it]\n",
      "/var/folders/yj/fs6gw7z97z14mqrvd0dfvkyr0000gp/T/ipykernel_5201/3039136531.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['contexts'] = df['contexts'].apply(lambda x: [[y] for y in x] if isinstance(x, list) and all(isinstance(y, str) for y in x) else x)\n",
      "/var/folders/yj/fs6gw7z97z14mqrvd0dfvkyr0000gp/T/ipykernel_5201/3039136531.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['ground_truth'] = df['ground_truth'].apply(lambda x: [[y] for y in x] if isinstance(x, list) and all(isinstance(y, str) for y in x) else x)\n",
      "embedding nodes:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "embedding nodes:  50%|█████     | 1/2 [00:00<00:00,  6.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:ragas.testset.docstore:Document [ID: 8f49cbbb-a463-47c6-ac94-1cb45252d24c] has no filename, using `doc_id` instead\n",
      "INFO:ragas.testset.docstore:Document [ID: 8f49cbbb-a463-47c6-ac94-1cb45252d24c] has no filename, using `doc_id` instead\n",
      "INFO:ragas.testset.docstore:Document [ID: 5eb509fc-7beb-40d8-8275-518dce1dd15a] has no filename, using `doc_id` instead\n",
      "INFO:ragas.testset.docstore:Document [ID: 5eb509fc-7beb-40d8-8275-518dce1dd15a] has no filename, using `doc_id` instead\n",
      "WARNING:ragas.testset.docstore:Filename and doc_id are the same for all nodes.\n",
      "INFO:ragas.testset.docstore:Document [ID: 8f49cbbb-a463-47c6-ac94-1cb45252d24c] has no filename, using `doc_id` instead\n",
      "INFO:ragas.testset.docstore:Document [ID: 5eb509fc-7beb-40d8-8275-518dce1dd15a] has no filename, using `doc_id` instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:ragas.testset.evolutions:seed question generated: Here's a question that can be fully answered from the given context:\n",
      "\n",
      "\"What is Davis Bennett's comparison between using Numba and CuPy for accelerating array computing operations?\"\n",
      "\n",
      "This question can be answered by referencing Davis Bennett's statement about comparing the performance of a CUDA kernel jitted with Numba to the same operation on a CuPy array.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|██████████| 1/1 [00:13<00:00, 13.46s/it]\n",
      "/var/folders/yj/fs6gw7z97z14mqrvd0dfvkyr0000gp/T/ipykernel_5201/3039136531.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['contexts'] = df['contexts'].apply(lambda x: [[y] for y in x] if isinstance(x, list) and all(isinstance(y, str) for y in x) else x)\n",
      "/var/folders/yj/fs6gw7z97z14mqrvd0dfvkyr0000gp/T/ipykernel_5201/3039136531.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['ground_truth'] = df['ground_truth'].apply(lambda x: [[y] for y in x] if isinstance(x, list) and all(isinstance(y, str) for y in x) else x)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>contexts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The purpose of the Scientific Computing Server...</td>\n",
       "      <td>[[Scientific Computing Server - e03u07\\nTitle:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The purpose of the Scientific Computing Server...</td>\n",
       "      <td>[[Scientific Computing Server - e03u07\\nTitle:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>Davis Bennett compared the performance of a CU...</td>\n",
       "      <td>[[Davis Bennett said: to inaugurate this chann...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  Here is a question that can be fully answered ...   \n",
       "1  Here is a question that can be fully answered ...   \n",
       "2  Here's a question that can be fully answered f...   \n",
       "\n",
       "                                        ground_truth  \\\n",
       "0  The purpose of the Scientific Computing Server...   \n",
       "1  The purpose of the Scientific Computing Server...   \n",
       "2  Davis Bennett compared the performance of a CU...   \n",
       "\n",
       "                                            contexts  \n",
       "0  [[Scientific Computing Server - e03u07\\nTitle:...  \n",
       "1  [[Scientific Computing Server - e03u07\\nTitle:...  \n",
       "2  [[Davis Bennett said: to inaugurate this chann...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"RUN EVALS\"\"\"\n",
    "from datasets import Dataset\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from ragas.testset.generator import TestsetGenerator\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "import pandas as pd\n",
    "import pyarrow \n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Load .env file\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "# generator_llm = Ollama(model=\"llama3:70b\")\n",
    "# critic_llm = Ollama(model=\"llama3:70b\")\n",
    "\n",
    "# generator_llm = ChatOpenAI(model=\"gpt-3.5-turbo\", api_key=api_key)\n",
    "# critic_llm = ChatOpenAI(model=\"gpt-3.5-turbo\", api_key=api_key)\n",
    "# embeddings = OpenAIEmbeddings(api_key=api_key)\n",
    "\n",
    "\n",
    "# generator_llm = Ollama(model=\"phi\")\n",
    "# critic_llm = Ollama(model=\"phi\")\n",
    "\n",
    "\n",
    "generator_llm = Ollama(model=\"llama3\")\n",
    "critic_llm = Ollama(model=\"llama3\")\n",
    "embeddings = OllamaEmbeddings(\n",
    "    model=\"avr/sfr-embedding-mistral\"\n",
    ")\n",
    "\n",
    "\n",
    "\"\"\"curl http://e02u30.int.janelia.org:11434/api/generate -d '{\n",
    "  \"model\": \"llama3\",\n",
    "  \"prompt\":\"Why is the sky blue?\"\n",
    "}'\"\"\"\n",
    "# generator_llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "# critic_llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "\n",
    "generator = TestsetGenerator.from_langchain(\n",
    "    generator_llm,\n",
    "    critic_llm,\n",
    "    embeddings\n",
    ") \n",
    "\n",
    "# current_testset = generator.generate_with_langchain_docs(document, test_size=1, distributions={\"simple\": 0.5, \"reasoning\": 0.25, \"multi_context\": 0.25})\n",
    "\n",
    "\n",
    "\n",
    "# Initialize an empty list to collect all testsets\n",
    "\n",
    "# Iterate over each document\n",
    "\n",
    "def datasetFix(df):\n",
    "    columns_to_keep = ['question', 'ground_truth', 'contexts']\n",
    "    df = df[columns_to_keep]\n",
    "    \n",
    "    # Apply transformations\n",
    "    df['contexts'] = df['contexts'].apply(lambda x: [[y] for y in x] if isinstance(x, list) and all(isinstance(y, str) for y in x) else x)\n",
    "    df['ground_truth'] = df['ground_truth'].apply(lambda x: [[y] for y in x] if isinstance(x, list) and all(isinstance(y, str) for y in x) else x)\n",
    "\n",
    "    \n",
    "    return df\n",
    "\n",
    "all_data_df = pd.DataFrame()\n",
    "  \n",
    "for document in documents:\n",
    "    test_size_gen = int(len(str(document)) // 500)\n",
    "    current_testset = generator.generate_with_langchain_docs(document, test_size=test_size_gen, distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25})\n",
    "    current_testset = current_testset.to_pandas()\n",
    "\n",
    "    # current_testset.to_parquet('importMe.parquet', index=False)\n",
    "    current_df = datasetFix(current_testset)\n",
    "\n",
    "    # current_df = datasetFix(current_testset)\n",
    "    \n",
    "    all_data_df = pd.concat([all_data_df, current_df], ignore_index=True)    # If this is the first iteration, set the DataFrame, otherwise append to it\n",
    "\n",
    "display(all_data_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b05cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d241aad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Here is a question that can be fully answered from the given context:\\n\\n\"What is the purpose of the Scientific Computing Server, e03u07?\"\\n\\nThis question can be answered by reading the \"Purpose\" section of the context, which states that the server \"Runs the production services for the Janelia Workstation using Docker Swarm. This is the master server.', 'Here is a question that can be fully answered from the given context:\\n\\n\"What is the purpose of the Scientific Computing Server - e03u07?\"\\n\\nThis question can be answered by reading the \"Purpose\" section of the context, which states: \"Runs the production services for the Janelia Workstation using Docker Swarm. This is the master server.', 'Here\\'s a question that can be fully answered from the given context:\\n\\n\"What is Davis Bennett\\'s comparison between using Numba and CuPy for accelerating array computing operations?\"\\n\\nThis question can be answered by referencing Davis Bennett\\'s statement about comparing the performance of a CUDA kernel jitted with Numba to the same operation on a CuPy array.']\n",
      "Here is a question that can be fully answered from the given context:\n",
      "\n",
      "\"What is the purpose of the Scientific Computing Server, e03u07?\"\n",
      "\n",
      "This question can be answered by reading the \"Purpose\" section of the context, which states that the server \"Runs the production services for the Janelia Workstation using Docker Swarm. This is the master server.\n",
      "Here is a question that can be fully answered from the given context:\n",
      "\n",
      "\"What is the purpose of the Scientific Computing Server - e03u07?\"\n",
      "\n",
      "This question can be answered by reading the \"Purpose\" section of the context, which states: \"Runs the production services for the Janelia Workstation using Docker Swarm. This is the master server.\n",
      "Here's a question that can be fully answered from the given context:\n",
      "\n",
      "\"What is Davis Bennett's comparison between using Numba and CuPy for accelerating array computing operations?\"\n",
      "\n",
      "This question can be answered by referencing Davis Bennett's statement about comparing the performance of a CUDA kernel jitted with Numba to the same operation on a CuPy array.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "questions_list = all_data_df['question'].tolist()\n",
    "print (questions_list)\n",
    "\n",
    "seen = set()\n",
    "questions_list = [x for x in questions_list if not (x in seen or seen.add(x))]\n",
    "\n",
    "for item in questions_list:\n",
    "    print(item)\n",
    "\n",
    "    \n",
    "\n",
    "# testset.to_json(\"testset.json\")\n",
    "# Creates dataset of ground truths contexts and questions for the testset\n",
    "# Missing answers column \n",
    "# On one medium size document, it took about 1 minutes to generate 10 questions and cost 3 dollars on OpenAI\n",
    "# Seems expensive when using gpt-4, is its use justified or does 3.5 get the job done?\n",
    "# Evaluate gpt-4 vs gpt-3.5-turbo-16k for RAGAS evaluation test data generation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0a0523",
   "metadata": {},
   "source": [
    "fetch the LLM's response and append to a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "862687da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>contexts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>Setting the visibility of a node in this hiera...</td>\n",
       "      <td>[[        ...\\n    @overload\\n    def first(se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>When no parent is found for an image, a warnin...</td>\n",
       "      <td>[[     parent_zarr = None\\n        if image:\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>A newly created node may be considered higher ...</td>\n",
       "      <td>[[        ...\\n    @overload\\n    def first(se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>The newly created node may be considered highe...</td>\n",
       "      <td>[[        ...\\n    @overload\\n    def first(se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Based on the given context, a suitable questio...</td>\n",
       "      <td>The `matches` method in the `Labels` class che...</td>\n",
       "      <td>[[ node = Node(zarr, self, visibility=visibili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>The exception is swallowed</td>\n",
       "      <td>[[     parent_zarr = None\\n        if image:\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How would Srini visualize simulation results t...</td>\n",
       "      <td>Srini would visualize simulation results by pl...</td>\n",
       "      <td>[[Srini said: Huh. If the result is so sensiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How does a Node's structure impact its visibil...</td>\n",
       "      <td>The Node class has properties like `visible` a...</td>\n",
       "      <td>[[ node = Node(zarr, self, visibility=visibili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What makes nodes visible in a hierarchy, given...</td>\n",
       "      <td>Nodes are made visible in a hierarchy based on...</td>\n",
       "      <td>[[ node = Node(zarr, self, visibility=visibili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>The `load` method iterates over the specs in t...</td>\n",
       "      <td>[[        ...\\n    @overload\\n    def first(se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Based on the given context, a suitable questio...</td>\n",
       "      <td>An additional aspect of a multiscale image is ...</td>\n",
       "      <td>[[ node = Node(zarr, self, visibility=visibili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Here's a rewritten version of the question:\\n\\...</td>\n",
       "      <td>The discussion suggests that increasing simula...</td>\n",
       "      <td>[[Srini said: Huh. If the result is so sensiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Here is the question that can be fully answere...</td>\n",
       "      <td>Due to a known incompatibility with pytest and...</td>\n",
       "      <td>[[Mark Kittisopikul said: https://discuss.pyth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Here is the question that can be fully answere...</td>\n",
       "      <td>Pytest rewrites the AST nodes in the testing c...</td>\n",
       "      <td>[[Mark Kittisopikul said: https://discuss.pyth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>Srini's suggestion for visualizing and compari...</td>\n",
       "      <td>[[Srini said: Huh. If the result is so sensiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Based on the given context, I would form the q...</td>\n",
       "      <td>The values along the first axis are the coordi...</td>\n",
       "      <td>[[ip said: or y x z\\nGert-Jan Both said: What ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>What changes when flipping a multi-dim matrix?...</td>\n",
       "      <td>When flipping a multi-dim matrix, the values a...</td>\n",
       "      <td>[[ip said: or y x z\\nGert-Jan Both said: What ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>When you click on that +13 on the org chart in...</td>\n",
       "      <td>[[Mark Kittisopikul said: Huh, my Windows star...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Here's the question:\\n\\n\"What features does Ta...</td>\n",
       "      <td>Tabnine is an AI code assistant that makes you...</td>\n",
       "      <td>[[Konrad Rokicki said: CoPilot getting some co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Here is the question that can be fully answere...</td>\n",
       "      <td>The issue preventing the 'make' command from w...</td>\n",
       "      <td>[[/bin/ld: /opt/cray/pe/mpich/8.1.16/ofi/nvidi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>The --log-window-size is probably not needed, ...</td>\n",
       "      <td>[[Cristian Goina said: here’s how  I checked i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>Gert-Jan Both is planning to use Deb's dataloa...</td>\n",
       "      <td>[[Gert-Jan Both said: I managed to run the ful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>What is the purpose of the `--log-window-size`...</td>\n",
       "      <td>The --log-window-size option probably refers t...</td>\n",
       "      <td>[[Cristian Goina said: here’s how  I checked i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>What are the steps involved in compiling a C++...</td>\n",
       "      <td>The steps involved in compiling a C++ program ...</td>\n",
       "      <td>[[UPTI/lib64:/opt/nvidia/hpc_sdk/Linux_x86_64/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>When a new ZarrLocation is added to a node, it...</td>\n",
       "      <td>[[        ...\\n    @overload\\n    def first(se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Here's a rewritten question that requires mult...</td>\n",
       "      <td>Mark Kittisopikul explores George Washington B...</td>\n",
       "      <td>[[Mark Kittisopikul said: https://loudounnow.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Here's a rewritten version of the question:\\n\\...</td>\n",
       "      <td>Cristian Goina uses git svn for his build proc...</td>\n",
       "      <td>[[Cristian Goina said: here’s how  I checked i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Here's a rewritten version of the question tha...</td>\n",
       "      <td>If anything goes wrong, the exception is swall...</td>\n",
       "      <td>[[     parent_zarr = None\\n        if image:\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>What's involved in compiling C++ for GPU use?</td>\n",
       "      <td>The compilation process involves using languag...</td>\n",
       "      <td>[[UPTI/lib64:/opt/nvidia/hpc_sdk/Linux_x86_64/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>The undefined references in the compilation pr...</td>\n",
       "      <td>[[8.1.16/gtl/lib/libmpi_gtl_cuda.so: undefined...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>One possible reason for the discrepancy in the...</td>\n",
       "      <td>[[Srini said: Huh. If the result is so sensiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Here is the question that can be fully answere...</td>\n",
       "      <td>Due to a known incompatibility with pytest and...</td>\n",
       "      <td>[[Mark Kittisopikul said: https://discuss.pyth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>A crossover link on RT-7, as mentioned by Mark...</td>\n",
       "      <td>[[Mark Kittisopikul said: https://loudounnow.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>Gert-Jan Both faces challenges when checking t...</td>\n",
       "      <td>[[Gert-Jan Both said: Alright I have a basic r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>What changes with axis reversal in a multi-dim...</td>\n",
       "      <td>When you do .T on a multi-D matrix, it reverse...</td>\n",
       "      <td>[[ip said: or y x z\\nGert-Jan Both said: What ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>How does the George Washington Boulevard exten...</td>\n",
       "      <td>The George Washington Boulevard extension may ...</td>\n",
       "      <td>[[Mark Kittisopikul said: https://loudounnow.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>The purpose of regex101 is to build, test, and...</td>\n",
       "      <td>[[William Katz said: \\n&lt;image.png&gt;\\nOthers rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>What are the key differences between Blender a...</td>\n",
       "      <td>The key differences between Blender and Neurog...</td>\n",
       "      <td>[[Davis Bennett said: Philip Hubbard how hard ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Here's a question that can be fully answered b...</td>\n",
       "      <td>Some potential solutions for establishing a Ma...</td>\n",
       "      <td>[[Konrad Rokicki said: Curious if anyone knows...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>A crossover link is being built near Ashburn.</td>\n",
       "      <td>[[Mark Kittisopikul said: https://loudounnow.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>The advertised highest speed for real-time com...</td>\n",
       "      <td>[[Davis Bennett said: Mark Kittisopikul Raghav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Here's a possible rewritten version:\\n\\n\"What ...</td>\n",
       "      <td>The symbols missing from CUDA libraries are cu...</td>\n",
       "      <td>[[8.1.16/gtl/lib/libmpi_gtl_cuda.so: undefined...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>The main difference is that Mark Kittisopikul ...</td>\n",
       "      <td>[[isopikul said: Could you run\\necho $LD_LIBRA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The simple solution to this is to run the foll...</td>\n",
       "      <td>[[Ken Carlile said: Stephan Saalfeld has alrea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>The advertised highest speed for real-time com...</td>\n",
       "      <td>[[Davis Bennett said: Mark Kittisopikul Raghav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>What are the key differences between Blender a...</td>\n",
       "      <td>The key differences between Blender and Neurog...</td>\n",
       "      <td>[[Davis Bennett said: Philip Hubbard how hard ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Here's a question that can be fully answered b...</td>\n",
       "      <td>Ken Carlile's concern about dealing with large...</td>\n",
       "      <td>[[William Katz said: Illustrations for Zarr co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>AWS Lambda has made two changes to its billing...</td>\n",
       "      <td>[[Konrad Rokicki said: Other huge changes:\\nLa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The matrix operations performed in this code s...</td>\n",
       "      <td>[[.10534273, -0.5556871 ,\\n         0.8352932 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>AWS Lambda has changed its billing system to b...</td>\n",
       "      <td>[[Konrad Rokicki said: CoPilot getting some co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Based on the given context, a suitable questio...</td>\n",
       "      <td>The `matches` method in the `Labels` class che...</td>\n",
       "      <td>[[ node = Node(zarr, self, visibility=visibili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Here is the question that can be fully answere...</td>\n",
       "      <td>The reason for the expedited release of Python...</td>\n",
       "      <td>[[Mark Kittisopikul said: https://discuss.pyth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Based on the given context, here's a question ...</td>\n",
       "      <td>The purpose of the illustrations created by He...</td>\n",
       "      <td>[[William Katz said: Illustrations for Zarr co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>Some of the challenges and difficulties in usi...</td>\n",
       "      <td>[[Davis Bennett said: can anyone make sense of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>What happens if manual walltime overrules scri...</td>\n",
       "      <td>The manual walltime setting overrules script s...</td>\n",
       "      <td>[[harms said: `qsub -A alcf_training -l select...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Here is the question that can be fully answere...</td>\n",
       "      <td>The kernel crash in Cristian Goina's Jupyter n...</td>\n",
       "      <td>[[Cristian Goina said: I am running my jupyter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>someone to build Client and Worker objects in ...</td>\n",
       "      <td>[[Mark Kittisopikul said: I just reading throu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>What's going on behind the scenes in this code?</td>\n",
       "      <td>The code is performing a QZ decomposition (als...</td>\n",
       "      <td>[[.10534273, -0.5556871 ,\\n         0.8352932 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The HHMI branding on Windows start menu looks ...</td>\n",
       "      <td>[[Mark Kittisopikul said: Huh, my Windows star...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>What is the purpose of specifying template par...</td>\n",
       "      <td>According to Davis Bennett, the purpose of spe...</td>\n",
       "      <td>[[Davis Bennett said: can anyone make sense of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>What is the condition for the `-gpu` option to...</td>\n",
       "      <td>The condition for the `-gpu` option to have an...</td>\n",
       "      <td>[[UPTI/lib64:/opt/nvidia/hpc_sdk/Linux_x86_64/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>What is the issue with using `dask_image.imrea...</td>\n",
       "      <td>The issue with using dask_image.imread to read...</td>\n",
       "      <td>[[Mark Kittisopikul said: It looks like Tim fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>200MB/sec/core</td>\n",
       "      <td>[[Davis Bennett said: Mark Kittisopikul Raghav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Here's a rewritten version of the question tha...</td>\n",
       "      <td>Adam Taylor faced challenges with Reveal.js in...</td>\n",
       "      <td>[[Davis Bennett said: has anyone tried this fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Here's a rewritten question that requires mult...</td>\n",
       "      <td>The answer to given question is not present in...</td>\n",
       "      <td>[[.10534273, -0.5556871 ,\\n         0.8352932 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Here is a rewritten version of the question th...</td>\n",
       "      <td>Key factors to consider when deploying machine...</td>\n",
       "      <td>[[William Katz said:  Srini and I think it wou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>200MB/sec/core</td>\n",
       "      <td>[[Davis Bennett said: Mark Kittisopikul Raghav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The conventional way to safely interpret the s...</td>\n",
       "      <td>[[Mark Kittisopikul said: Is there a conventio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>Louis Scheffer should try to install a newer v...</td>\n",
       "      <td>[[Louis Scheffer said: My work machine uses Sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>What is the purpose of the illustrations creat...</td>\n",
       "      <td>The purpose of the illustrations created by He...</td>\n",
       "      <td>[[William Katz said: Illustrations for Zarr co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>The potential reasons why David Ackerman got d...</td>\n",
       "      <td>[[William Katz said:  Srini and I think it wou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Here's the question:\\n\\n\"What is the purpose o...</td>\n",
       "      <td>The purpose of AI-powered code completions is ...</td>\n",
       "      <td>[[Konrad Rokicki said: CoPilot getting some co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Here's a rewritten question that conveys the s...</td>\n",
       "      <td>The discussion revolves around identifying and...</td>\n",
       "      <td>[[Srini said: Huh. If the result is so sensiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>According to Mark Kittisopikul, the purpose of...</td>\n",
       "      <td>[[Mark Kittisopikul said: https://loudounnow.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>Rust's compile-time error message reveals that...</td>\n",
       "      <td>[[Mark Kittisopikul said: Sigh. I'm still tryi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The Seq language has several key features that...</td>\n",
       "      <td>[[Davis Bennett said: https://www.nature.com/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Here's a rewritten question that meets the rul...</td>\n",
       "      <td>Blosc2's sparse frame implementation allows fo...</td>\n",
       "      <td>[[Mark Kittisopikul said: Davis Bennett, you w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The conventional way to safely interpret the s...</td>\n",
       "      <td>[[Mark Kittisopikul said: Is there a conventio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Here's a question that can be fully answered b...</td>\n",
       "      <td>The purpose of the illustrations created by He...</td>\n",
       "      <td>[[William Katz said: Illustrations for Zarr co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>Booster shots will be on the way for people 8 ...</td>\n",
       "      <td>[[Mark Kittisopikul said: https://patch.com/vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>The issue with using dask_image.imread compare...</td>\n",
       "      <td>[[kwargs)\\n    512                            ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Here's a rewritten question that meets the rul...</td>\n",
       "      <td>The difference between `dask_image.imread` and...</td>\n",
       "      <td>[[kwargs)\\n    512                            ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Here's a rewritten version of the question:\\n\\...</td>\n",
       "      <td>Cristian Goina cloned an Ant-based project usi...</td>\n",
       "      <td>[[Cristian Goina said: here’s how  I checked i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Based on the given context, here's a question ...</td>\n",
       "      <td>The exact cause of the kernel crash is not exp...</td>\n",
       "      <td>[[.        ,  0.        ,  0.        ,  0.    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>The potential reasons for David Ackerman getti...</td>\n",
       "      <td>[[William Katz said:  Srini and I think it wou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Here is a rewritten version of the question th...</td>\n",
       "      <td>Matching LD_LIBRARY_PATH to Mark Kittisopikul'...</td>\n",
       "      <td>[[isopikul said: Could you run\\necho $LD_LIBRA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>Through correlation with light microscopy volu...</td>\n",
       "      <td>[[Ulrike Boehm said: Hello everyone, The Optic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The simple solution to this is to run the foll...</td>\n",
       "      <td>[[Ken Carlile said: Stephan Saalfeld has alrea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Here is the question that can be fully answere...</td>\n",
       "      <td>Julia's bounds checking has limitations when w...</td>\n",
       "      <td>[[William Katz said: Blog post: https://yuri.i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>How can you optimize job scheduling on a compu...</td>\n",
       "      <td>To optimize job scheduling on a compute cluste...</td>\n",
       "      <td>[[Davis Bennett said: cluster looking choked\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Here's a rewritten version of the question:\\n\\...</td>\n",
       "      <td>One can't assume that indexing starts at 1 for...</td>\n",
       "      <td>[[William Katz said: Blog post: https://yuri.i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Here's a question that can be fully answered b...</td>\n",
       "      <td>Louis Scheffer should update to v2.1-ish or in...</td>\n",
       "      <td>[[Louis Scheffer said: My work machine uses Sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Here's a question that can be fully answered b...</td>\n",
       "      <td>During the 'Next Gen File Formats' workshop at...</td>\n",
       "      <td>[[Ulrike Boehm said: For those of you interest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>Through correlation with light microscopy volu...</td>\n",
       "      <td>[[Ulrike Boehm said: Hello everyone, The Optic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The lsf_opts parameter defines a parameter cal...</td>\n",
       "      <td>[[Konrad Rokicki said: That’s just for the hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>Some potential issues with piping strings to a...</td>\n",
       "      <td>[[ need to eval the function definition. The c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>Some alternatives to conda for package managem...</td>\n",
       "      <td>[[ like??\\nMark Kittisopikul said: The conda-f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>Louis Scheffer should try to install the versi...</td>\n",
       "      <td>[[Louis Scheffer said: My work machine uses Sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Here is a rewritten version of the question th...</td>\n",
       "      <td>In the context of installing Python and packag...</td>\n",
       "      <td>[[Donald Olbris said: https://bitecode.substac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>Some ways to visually distinguish between gray...</td>\n",
       "      <td>[[Davis Bennett said: one thing I've wanted fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Here's the question:\\n\\n\"What is Amazon CodeWh...</td>\n",
       "      <td>Amazon CodeWhisperer- ML-Powered Coding Companion</td>\n",
       "      <td>[[Konrad Rokicki said: CoPilot getting some co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The expected result of the q @ s @ z.conj().T ...</td>\n",
       "      <td>[[e-01,... 0.36549678, 0.9152956 ,\\n       1.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Here is a rewritten question that conveys the ...</td>\n",
       "      <td>According to Philip Hubbard, Neuroglancer runs...</td>\n",
       "      <td>[[Davis Bennett said: Philip Hubbard how hard ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>The Napari tutorials recommend using Dask dela...</td>\n",
       "      <td>[[ not sure if the other major contributor eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Here's a rewritten version of the question tha...</td>\n",
       "      <td>The feasible coffee-and-donuts meeting dates a...</td>\n",
       "      <td>[[Virginia Scarlett said: Bob's has donuts on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The proposed schedule for conducting a code re...</td>\n",
       "      <td>[[Gert-Jan Both said: I just updated the funct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>What is the purpose of the `phase_factor` meth...</td>\n",
       "      <td>The phase_factor method calculates a bunch of ...</td>\n",
       "      <td>[[Gert-Jan Both said: I just updated the funct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>What is Gert-Jan Both's main focus in updating...</td>\n",
       "      <td>Gert-Jan Both's main focus in updating the fun...</td>\n",
       "      <td>[[Gert-Jan Both said: I just updated the funct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Here is the question that can be fully answere...</td>\n",
       "      <td>Possible reasons for kernel crashes in Jupyter...</td>\n",
       "      <td>[[Cristian Goina said: I am running my jupyter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The key components that would need to be rewri...</td>\n",
       "      <td>[[Mark Kittisopikul said: I just reading throu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>The old versions of python-atomicwrites on PyP...</td>\n",
       "      <td>[[Mark Kittisopikul said: There was this incid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The mechanism by which Python interacts with J...</td>\n",
       "      <td>[[Mark Kittisopikul said: Does anyone have any...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>According to the Loudoun County Health Departm...</td>\n",
       "      <td>[[Mark Kittisopikul said: https://patch.com/vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The simple solution to this is to run the foll...</td>\n",
       "      <td>[[Ken Carlile said: Stephan Saalfeld has alrea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The implications for Open Science if crucial i...</td>\n",
       "      <td>[[William Katz said: Interesting blog on Janel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>Anna Kreshuk's presentation at the Optical Int...</td>\n",
       "      <td>[[Ulrike Boehm said: Hello everyone, The Optic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The different ways to configure the executor i...</td>\n",
       "      <td>[[Konrad Rokicki said: That’s just for the hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>What dates are being considered for meetings w...</td>\n",
       "      <td>The dates being considered for meetings with V...</td>\n",
       "      <td>[[Virginia Scarlett said: Bob's has donuts on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Here's a rewritten version of the question:\\n\\...</td>\n",
       "      <td>The issues with search and following in the fe...</td>\n",
       "      <td>[[Konrad Rokicki said: Curious if anyone knows...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>When you edit your .bash_profile file and log ...</td>\n",
       "      <td>[[isopikul said: Could you run\\necho $LD_LIBRA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>Konrad Rokicki was able to query his AWS accou...</td>\n",
       "      <td>[[Konrad Rokicki said: This thing is so cool: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Here's a question that can be fully answered b...</td>\n",
       "      <td>Some potential solutions proposed by William K...</td>\n",
       "      <td>[[Konrad Rokicki said: Curious if anyone knows...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>Some ways to visually distinguish between gray...</td>\n",
       "      <td>[[Davis Bennett said: one thing I've wanted fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>What happens when aligning axes in a coord sys...</td>\n",
       "      <td>When aligning axes in a coord sys, difficultie...</td>\n",
       "      <td>[[Gert-Jan Both said: Alright I have a basic r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>What's a popular tool for creating slide decks...</td>\n",
       "      <td>Marp and Reveal.js are two popular tools for c...</td>\n",
       "      <td>[[Davis Bennett said: has anyone tried this fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>Some alternatives to PowerPoint mentioned in t...</td>\n",
       "      <td>[[Davis Bennett said: has anyone tried this fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>What is the purpose of adding regularization i...</td>\n",
       "      <td>The purpose of adding regularization in the co...</td>\n",
       "      <td>[[Xi said: I agree with Geneva!\\nIn the Hackat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>Examples of 'leaks' in the abstraction of remo...</td>\n",
       "      <td>[[Adam Taylor said: Well, there's the issue of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>What insight does 'format argument must be a s...</td>\n",
       "      <td>nan</td>\n",
       "      <td>[[Mark Kittisopikul said: Sigh. I'm still tryi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>What are some common pain points when using Re...</td>\n",
       "      <td>Some common pain points when using Reveal.js i...</td>\n",
       "      <td>[[Davis Bennett said: has anyone tried this fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>Some ways to visually distinguish between gray...</td>\n",
       "      <td>[[Davis Bennett said: one thing I've wanted fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Here is a rewritten version of the question th...</td>\n",
       "      <td>When running MinIO in server mode, your storag...</td>\n",
       "      <td>[[William Katz said: Some discussion of Minio ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>What fundamental aspect of the Fourier transfo...</td>\n",
       "      <td>Gert-Jan Both is struggling to understand how ...</td>\n",
       "      <td>[[Gert-Jan Both said: So more progress - I get...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>When the code encounters an ROI with 4 dimensi...</td>\n",
       "      <td>[[\\n                print(\"ROI is 2D, recruiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The possible reasons for differences in simula...</td>\n",
       "      <td>[[Srini said: We only have absorption at the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>Pyspark uses remote procedure calls through so...</td>\n",
       "      <td>[[ into Python via the Java Native Interface i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The data shape's last dimensions are assumed t...</td>\n",
       "      <td>[[N,4 it saves it as channels\\nDavis Bennett s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Here is the question that can be fully answere...</td>\n",
       "      <td>The issue preventing the make command from wor...</td>\n",
       "      <td>[[/bin/ld: /opt/cray/pe/mpich/8.1.16/ofi/nvidi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>Reveal.js, Marp, and Slides</td>\n",
       "      <td>[[Mark Kittisopikul said: Sometimes the simpli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Here's a rewritten version of the question:\\n\\...</td>\n",
       "      <td>The answer to given question is not present in...</td>\n",
       "      <td>[[.10534273, -0.5556871 ,\\n         0.8352932 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Here is a question that can be fully answered ...</td>\n",
       "      <td>The potential reasons for differences in simul...</td>\n",
       "      <td>[[Srini said: We only have absorption at the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>Mark Kittisopikul edited the maven packaging i...</td>\n",
       "      <td>[[Mark Kittisopikul said: The maven packaging ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Here is a rewritten version of the question th...</td>\n",
       "      <td>The key differences in how Caterva's and Neuro...</td>\n",
       "      <td>[[Mark Kittisopikul said: Davis Bennett, you w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Here's a question that can be fully answered f...</td>\n",
       "      <td>You were mostly trying to imitate how the wing...</td>\n",
       "      <td>[[Konrad Rokicki said: https://openai.com/blog...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0    Here's a question that can be fully answered f...   \n",
       "1    Here's a question that can be fully answered f...   \n",
       "2    Here's a question that can be fully answered f...   \n",
       "3    Here's a question that can be fully answered f...   \n",
       "4    Based on the given context, a suitable questio...   \n",
       "5    Here's a question that can be fully answered f...   \n",
       "6    How would Srini visualize simulation results t...   \n",
       "7    How does a Node's structure impact its visibil...   \n",
       "8    What makes nodes visible in a hierarchy, given...   \n",
       "9    Here's a question that can be fully answered f...   \n",
       "10   Based on the given context, a suitable questio...   \n",
       "11   Here's a rewritten version of the question:\\n\\...   \n",
       "12   Here is the question that can be fully answere...   \n",
       "13   Here is the question that can be fully answere...   \n",
       "14   Here's a question that can be fully answered f...   \n",
       "15   Based on the given context, I would form the q...   \n",
       "16   What changes when flipping a multi-dim matrix?...   \n",
       "17   Here is a question that can be fully answered ...   \n",
       "18   Here's the question:\\n\\n\"What features does Ta...   \n",
       "19   Here is the question that can be fully answere...   \n",
       "20   Here's a question that can be fully answered f...   \n",
       "21   Here's a question that can be fully answered f...   \n",
       "22   What is the purpose of the `--log-window-size`...   \n",
       "23   What are the steps involved in compiling a C++...   \n",
       "24   Here's a question that can be fully answered f...   \n",
       "25   Here's a rewritten question that requires mult...   \n",
       "26   Here's a rewritten version of the question:\\n\\...   \n",
       "27   Here's a rewritten version of the question tha...   \n",
       "28       What's involved in compiling C++ for GPU use?   \n",
       "29   Here's a question that can be fully answered f...   \n",
       "30   Here's a question that can be fully answered f...   \n",
       "31   Here is the question that can be fully answere...   \n",
       "32   Here's a question that can be fully answered f...   \n",
       "33   Here's a question that can be fully answered f...   \n",
       "34   What changes with axis reversal in a multi-dim...   \n",
       "35   How does the George Washington Boulevard exten...   \n",
       "36   Here's a question that can be fully answered f...   \n",
       "37   What are the key differences between Blender a...   \n",
       "38   Here's a question that can be fully answered b...   \n",
       "39   Here's a question that can be fully answered f...   \n",
       "40   Here's a question that can be fully answered f...   \n",
       "41   Here's a possible rewritten version:\\n\\n\"What ...   \n",
       "42   Here's a question that can be fully answered f...   \n",
       "43   Here is a question that can be fully answered ...   \n",
       "44   Here's a question that can be fully answered f...   \n",
       "45   What are the key differences between Blender a...   \n",
       "46   Here's a question that can be fully answered b...   \n",
       "47   Here is a question that can be fully answered ...   \n",
       "48   Here is a question that can be fully answered ...   \n",
       "49   Here is a question that can be fully answered ...   \n",
       "50   Based on the given context, a suitable questio...   \n",
       "51   Here is the question that can be fully answere...   \n",
       "52   Based on the given context, here's a question ...   \n",
       "53   Here is a question that can be fully answered ...   \n",
       "54   What happens if manual walltime overrules scri...   \n",
       "55   Here is the question that can be fully answere...   \n",
       "56   Here is a question that can be fully answered ...   \n",
       "57     What's going on behind the scenes in this code?   \n",
       "58   Here is a question that can be fully answered ...   \n",
       "59   What is the purpose of specifying template par...   \n",
       "60   What is the condition for the `-gpu` option to...   \n",
       "61   What is the issue with using `dask_image.imrea...   \n",
       "62   Here is a question that can be fully answered ...   \n",
       "63   Here's a rewritten version of the question tha...   \n",
       "64   Here's a rewritten question that requires mult...   \n",
       "65   Here is a rewritten version of the question th...   \n",
       "66   Here is a question that can be fully answered ...   \n",
       "67   Here is a question that can be fully answered ...   \n",
       "68   Here's a question that can be fully answered f...   \n",
       "69   What is the purpose of the illustrations creat...   \n",
       "70   Here's a question that can be fully answered f...   \n",
       "71   Here's the question:\\n\\n\"What is the purpose o...   \n",
       "72   Here's a rewritten question that conveys the s...   \n",
       "73   Here's a question that can be fully answered f...   \n",
       "74   Here is a question that can be fully answered ...   \n",
       "75   Here is a question that can be fully answered ...   \n",
       "76   Here's a rewritten question that meets the rul...   \n",
       "77   Here is a question that can be fully answered ...   \n",
       "78   Here's a question that can be fully answered b...   \n",
       "79   Here is a question that can be fully answered ...   \n",
       "80   Here's a question that can be fully answered f...   \n",
       "81   Here's a rewritten question that meets the rul...   \n",
       "82   Here's a rewritten version of the question:\\n\\...   \n",
       "83   Based on the given context, here's a question ...   \n",
       "84   Here's a question that can be fully answered f...   \n",
       "85   Here is a rewritten version of the question th...   \n",
       "86   Here's a question that can be fully answered f...   \n",
       "87   Here is a question that can be fully answered ...   \n",
       "88   Here is the question that can be fully answere...   \n",
       "89   How can you optimize job scheduling on a compu...   \n",
       "90   Here's a rewritten version of the question:\\n\\...   \n",
       "91   Here's a question that can be fully answered b...   \n",
       "92   Here's a question that can be fully answered b...   \n",
       "93   Here's a question that can be fully answered f...   \n",
       "94   Here is a question that can be fully answered ...   \n",
       "95   Here's a question that can be fully answered f...   \n",
       "96   Here's a question that can be fully answered f...   \n",
       "97   Here's a question that can be fully answered f...   \n",
       "98   Here is a rewritten version of the question th...   \n",
       "99   Here is a question that can be fully answered ...   \n",
       "100  Here's the question:\\n\\n\"What is Amazon CodeWh...   \n",
       "101  Here is a question that can be fully answered ...   \n",
       "102  Here is a rewritten question that conveys the ...   \n",
       "103  Here's a question that can be fully answered f...   \n",
       "104  Here's a rewritten version of the question tha...   \n",
       "105  Here is a question that can be fully answered ...   \n",
       "106  What is the purpose of the `phase_factor` meth...   \n",
       "107  What is Gert-Jan Both's main focus in updating...   \n",
       "108  Here is the question that can be fully answere...   \n",
       "109  Here is a question that can be fully answered ...   \n",
       "110  Here's a question that can be fully answered f...   \n",
       "111  Here is a question that can be fully answered ...   \n",
       "112  Here is a question that can be fully answered ...   \n",
       "113  Here is a question that can be fully answered ...   \n",
       "114  Here is a question that can be fully answered ...   \n",
       "115  Here's a question that can be fully answered f...   \n",
       "116  Here is a question that can be fully answered ...   \n",
       "117  What dates are being considered for meetings w...   \n",
       "118  Here's a rewritten version of the question:\\n\\...   \n",
       "119  Here is a question that can be fully answered ...   \n",
       "120  Here's a question that can be fully answered f...   \n",
       "121  Here's a question that can be fully answered b...   \n",
       "122  Here is a question that can be fully answered ...   \n",
       "123  What happens when aligning axes in a coord sys...   \n",
       "124  What's a popular tool for creating slide decks...   \n",
       "125  Here is a question that can be fully answered ...   \n",
       "126  What is the purpose of adding regularization i...   \n",
       "127  Here is a question that can be fully answered ...   \n",
       "128  What insight does 'format argument must be a s...   \n",
       "129  What are some common pain points when using Re...   \n",
       "130  Here is a question that can be fully answered ...   \n",
       "131  Here is a rewritten version of the question th...   \n",
       "132  What fundamental aspect of the Fourier transfo...   \n",
       "133  Here is a question that can be fully answered ...   \n",
       "134  Here is a question that can be fully answered ...   \n",
       "135  Here is a question that can be fully answered ...   \n",
       "136  Here is a question that can be fully answered ...   \n",
       "137  Here is the question that can be fully answere...   \n",
       "138  Here is a question that can be fully answered ...   \n",
       "139  Here's a rewritten version of the question:\\n\\...   \n",
       "140  Here is a question that can be fully answered ...   \n",
       "141  Here's a question that can be fully answered f...   \n",
       "142  Here is a rewritten version of the question th...   \n",
       "143  Here's a question that can be fully answered f...   \n",
       "\n",
       "                                          ground_truth  \\\n",
       "0    Setting the visibility of a node in this hiera...   \n",
       "1    When no parent is found for an image, a warnin...   \n",
       "2    A newly created node may be considered higher ...   \n",
       "3    The newly created node may be considered highe...   \n",
       "4    The `matches` method in the `Labels` class che...   \n",
       "5                           The exception is swallowed   \n",
       "6    Srini would visualize simulation results by pl...   \n",
       "7    The Node class has properties like `visible` a...   \n",
       "8    Nodes are made visible in a hierarchy based on...   \n",
       "9    The `load` method iterates over the specs in t...   \n",
       "10   An additional aspect of a multiscale image is ...   \n",
       "11   The discussion suggests that increasing simula...   \n",
       "12   Due to a known incompatibility with pytest and...   \n",
       "13   Pytest rewrites the AST nodes in the testing c...   \n",
       "14   Srini's suggestion for visualizing and compari...   \n",
       "15   The values along the first axis are the coordi...   \n",
       "16   When flipping a multi-dim matrix, the values a...   \n",
       "17   When you click on that +13 on the org chart in...   \n",
       "18   Tabnine is an AI code assistant that makes you...   \n",
       "19   The issue preventing the 'make' command from w...   \n",
       "20   The --log-window-size is probably not needed, ...   \n",
       "21   Gert-Jan Both is planning to use Deb's dataloa...   \n",
       "22   The --log-window-size option probably refers t...   \n",
       "23   The steps involved in compiling a C++ program ...   \n",
       "24   When a new ZarrLocation is added to a node, it...   \n",
       "25   Mark Kittisopikul explores George Washington B...   \n",
       "26   Cristian Goina uses git svn for his build proc...   \n",
       "27   If anything goes wrong, the exception is swall...   \n",
       "28   The compilation process involves using languag...   \n",
       "29   The undefined references in the compilation pr...   \n",
       "30   One possible reason for the discrepancy in the...   \n",
       "31   Due to a known incompatibility with pytest and...   \n",
       "32   A crossover link on RT-7, as mentioned by Mark...   \n",
       "33   Gert-Jan Both faces challenges when checking t...   \n",
       "34   When you do .T on a multi-D matrix, it reverse...   \n",
       "35   The George Washington Boulevard extension may ...   \n",
       "36   The purpose of regex101 is to build, test, and...   \n",
       "37   The key differences between Blender and Neurog...   \n",
       "38   Some potential solutions for establishing a Ma...   \n",
       "39       A crossover link is being built near Ashburn.   \n",
       "40   The advertised highest speed for real-time com...   \n",
       "41   The symbols missing from CUDA libraries are cu...   \n",
       "42   The main difference is that Mark Kittisopikul ...   \n",
       "43   The simple solution to this is to run the foll...   \n",
       "44   The advertised highest speed for real-time com...   \n",
       "45   The key differences between Blender and Neurog...   \n",
       "46   Ken Carlile's concern about dealing with large...   \n",
       "47   AWS Lambda has made two changes to its billing...   \n",
       "48   The matrix operations performed in this code s...   \n",
       "49   AWS Lambda has changed its billing system to b...   \n",
       "50   The `matches` method in the `Labels` class che...   \n",
       "51   The reason for the expedited release of Python...   \n",
       "52   The purpose of the illustrations created by He...   \n",
       "53   Some of the challenges and difficulties in usi...   \n",
       "54   The manual walltime setting overrules script s...   \n",
       "55   The kernel crash in Cristian Goina's Jupyter n...   \n",
       "56   someone to build Client and Worker objects in ...   \n",
       "57   The code is performing a QZ decomposition (als...   \n",
       "58   The HHMI branding on Windows start menu looks ...   \n",
       "59   According to Davis Bennett, the purpose of spe...   \n",
       "60   The condition for the `-gpu` option to have an...   \n",
       "61   The issue with using dask_image.imread to read...   \n",
       "62                                      200MB/sec/core   \n",
       "63   Adam Taylor faced challenges with Reveal.js in...   \n",
       "64   The answer to given question is not present in...   \n",
       "65   Key factors to consider when deploying machine...   \n",
       "66                                      200MB/sec/core   \n",
       "67   The conventional way to safely interpret the s...   \n",
       "68   Louis Scheffer should try to install a newer v...   \n",
       "69   The purpose of the illustrations created by He...   \n",
       "70   The potential reasons why David Ackerman got d...   \n",
       "71   The purpose of AI-powered code completions is ...   \n",
       "72   The discussion revolves around identifying and...   \n",
       "73   According to Mark Kittisopikul, the purpose of...   \n",
       "74   Rust's compile-time error message reveals that...   \n",
       "75   The Seq language has several key features that...   \n",
       "76   Blosc2's sparse frame implementation allows fo...   \n",
       "77   The conventional way to safely interpret the s...   \n",
       "78   The purpose of the illustrations created by He...   \n",
       "79   Booster shots will be on the way for people 8 ...   \n",
       "80   The issue with using dask_image.imread compare...   \n",
       "81   The difference between `dask_image.imread` and...   \n",
       "82   Cristian Goina cloned an Ant-based project usi...   \n",
       "83   The exact cause of the kernel crash is not exp...   \n",
       "84   The potential reasons for David Ackerman getti...   \n",
       "85   Matching LD_LIBRARY_PATH to Mark Kittisopikul'...   \n",
       "86   Through correlation with light microscopy volu...   \n",
       "87   The simple solution to this is to run the foll...   \n",
       "88   Julia's bounds checking has limitations when w...   \n",
       "89   To optimize job scheduling on a compute cluste...   \n",
       "90   One can't assume that indexing starts at 1 for...   \n",
       "91   Louis Scheffer should update to v2.1-ish or in...   \n",
       "92   During the 'Next Gen File Formats' workshop at...   \n",
       "93   Through correlation with light microscopy volu...   \n",
       "94   The lsf_opts parameter defines a parameter cal...   \n",
       "95   Some potential issues with piping strings to a...   \n",
       "96   Some alternatives to conda for package managem...   \n",
       "97   Louis Scheffer should try to install the versi...   \n",
       "98   In the context of installing Python and packag...   \n",
       "99   Some ways to visually distinguish between gray...   \n",
       "100  Amazon CodeWhisperer- ML-Powered Coding Companion   \n",
       "101  The expected result of the q @ s @ z.conj().T ...   \n",
       "102  According to Philip Hubbard, Neuroglancer runs...   \n",
       "103  The Napari tutorials recommend using Dask dela...   \n",
       "104  The feasible coffee-and-donuts meeting dates a...   \n",
       "105  The proposed schedule for conducting a code re...   \n",
       "106  The phase_factor method calculates a bunch of ...   \n",
       "107  Gert-Jan Both's main focus in updating the fun...   \n",
       "108  Possible reasons for kernel crashes in Jupyter...   \n",
       "109  The key components that would need to be rewri...   \n",
       "110  The old versions of python-atomicwrites on PyP...   \n",
       "111  The mechanism by which Python interacts with J...   \n",
       "112  According to the Loudoun County Health Departm...   \n",
       "113  The simple solution to this is to run the foll...   \n",
       "114  The implications for Open Science if crucial i...   \n",
       "115  Anna Kreshuk's presentation at the Optical Int...   \n",
       "116  The different ways to configure the executor i...   \n",
       "117  The dates being considered for meetings with V...   \n",
       "118  The issues with search and following in the fe...   \n",
       "119  When you edit your .bash_profile file and log ...   \n",
       "120  Konrad Rokicki was able to query his AWS accou...   \n",
       "121  Some potential solutions proposed by William K...   \n",
       "122  Some ways to visually distinguish between gray...   \n",
       "123  When aligning axes in a coord sys, difficultie...   \n",
       "124  Marp and Reveal.js are two popular tools for c...   \n",
       "125  Some alternatives to PowerPoint mentioned in t...   \n",
       "126  The purpose of adding regularization in the co...   \n",
       "127  Examples of 'leaks' in the abstraction of remo...   \n",
       "128                                                nan   \n",
       "129  Some common pain points when using Reveal.js i...   \n",
       "130  Some ways to visually distinguish between gray...   \n",
       "131  When running MinIO in server mode, your storag...   \n",
       "132  Gert-Jan Both is struggling to understand how ...   \n",
       "133  When the code encounters an ROI with 4 dimensi...   \n",
       "134  The possible reasons for differences in simula...   \n",
       "135  Pyspark uses remote procedure calls through so...   \n",
       "136  The data shape's last dimensions are assumed t...   \n",
       "137  The issue preventing the make command from wor...   \n",
       "138                        Reveal.js, Marp, and Slides   \n",
       "139  The answer to given question is not present in...   \n",
       "140  The potential reasons for differences in simul...   \n",
       "141  Mark Kittisopikul edited the maven packaging i...   \n",
       "142  The key differences in how Caterva's and Neuro...   \n",
       "143  You were mostly trying to imitate how the wing...   \n",
       "\n",
       "                                              contexts  \n",
       "0    [[        ...\\n    @overload\\n    def first(se...  \n",
       "1    [[     parent_zarr = None\\n        if image:\\n...  \n",
       "2    [[        ...\\n    @overload\\n    def first(se...  \n",
       "3    [[        ...\\n    @overload\\n    def first(se...  \n",
       "4    [[ node = Node(zarr, self, visibility=visibili...  \n",
       "5    [[     parent_zarr = None\\n        if image:\\n...  \n",
       "6    [[Srini said: Huh. If the result is so sensiti...  \n",
       "7    [[ node = Node(zarr, self, visibility=visibili...  \n",
       "8    [[ node = Node(zarr, self, visibility=visibili...  \n",
       "9    [[        ...\\n    @overload\\n    def first(se...  \n",
       "10   [[ node = Node(zarr, self, visibility=visibili...  \n",
       "11   [[Srini said: Huh. If the result is so sensiti...  \n",
       "12   [[Mark Kittisopikul said: https://discuss.pyth...  \n",
       "13   [[Mark Kittisopikul said: https://discuss.pyth...  \n",
       "14   [[Srini said: Huh. If the result is so sensiti...  \n",
       "15   [[ip said: or y x z\\nGert-Jan Both said: What ...  \n",
       "16   [[ip said: or y x z\\nGert-Jan Both said: What ...  \n",
       "17   [[Mark Kittisopikul said: Huh, my Windows star...  \n",
       "18   [[Konrad Rokicki said: CoPilot getting some co...  \n",
       "19   [[/bin/ld: /opt/cray/pe/mpich/8.1.16/ofi/nvidi...  \n",
       "20   [[Cristian Goina said: here’s how  I checked i...  \n",
       "21   [[Gert-Jan Both said: I managed to run the ful...  \n",
       "22   [[Cristian Goina said: here’s how  I checked i...  \n",
       "23   [[UPTI/lib64:/opt/nvidia/hpc_sdk/Linux_x86_64/...  \n",
       "24   [[        ...\\n    @overload\\n    def first(se...  \n",
       "25   [[Mark Kittisopikul said: https://loudounnow.c...  \n",
       "26   [[Cristian Goina said: here’s how  I checked i...  \n",
       "27   [[     parent_zarr = None\\n        if image:\\n...  \n",
       "28   [[UPTI/lib64:/opt/nvidia/hpc_sdk/Linux_x86_64/...  \n",
       "29   [[8.1.16/gtl/lib/libmpi_gtl_cuda.so: undefined...  \n",
       "30   [[Srini said: Huh. If the result is so sensiti...  \n",
       "31   [[Mark Kittisopikul said: https://discuss.pyth...  \n",
       "32   [[Mark Kittisopikul said: https://loudounnow.c...  \n",
       "33   [[Gert-Jan Both said: Alright I have a basic r...  \n",
       "34   [[ip said: or y x z\\nGert-Jan Both said: What ...  \n",
       "35   [[Mark Kittisopikul said: https://loudounnow.c...  \n",
       "36   [[William Katz said: \\n<image.png>\\nOthers rea...  \n",
       "37   [[Davis Bennett said: Philip Hubbard how hard ...  \n",
       "38   [[Konrad Rokicki said: Curious if anyone knows...  \n",
       "39   [[Mark Kittisopikul said: https://loudounnow.c...  \n",
       "40   [[Davis Bennett said: Mark Kittisopikul Raghav...  \n",
       "41   [[8.1.16/gtl/lib/libmpi_gtl_cuda.so: undefined...  \n",
       "42   [[isopikul said: Could you run\\necho $LD_LIBRA...  \n",
       "43   [[Ken Carlile said: Stephan Saalfeld has alrea...  \n",
       "44   [[Davis Bennett said: Mark Kittisopikul Raghav...  \n",
       "45   [[Davis Bennett said: Philip Hubbard how hard ...  \n",
       "46   [[William Katz said: Illustrations for Zarr co...  \n",
       "47   [[Konrad Rokicki said: Other huge changes:\\nLa...  \n",
       "48   [[.10534273, -0.5556871 ,\\n         0.8352932 ...  \n",
       "49   [[Konrad Rokicki said: CoPilot getting some co...  \n",
       "50   [[ node = Node(zarr, self, visibility=visibili...  \n",
       "51   [[Mark Kittisopikul said: https://discuss.pyth...  \n",
       "52   [[William Katz said: Illustrations for Zarr co...  \n",
       "53   [[Davis Bennett said: can anyone make sense of...  \n",
       "54   [[harms said: `qsub -A alcf_training -l select...  \n",
       "55   [[Cristian Goina said: I am running my jupyter...  \n",
       "56   [[Mark Kittisopikul said: I just reading throu...  \n",
       "57   [[.10534273, -0.5556871 ,\\n         0.8352932 ...  \n",
       "58   [[Mark Kittisopikul said: Huh, my Windows star...  \n",
       "59   [[Davis Bennett said: can anyone make sense of...  \n",
       "60   [[UPTI/lib64:/opt/nvidia/hpc_sdk/Linux_x86_64/...  \n",
       "61   [[Mark Kittisopikul said: It looks like Tim fo...  \n",
       "62   [[Davis Bennett said: Mark Kittisopikul Raghav...  \n",
       "63   [[Davis Bennett said: has anyone tried this fo...  \n",
       "64   [[.10534273, -0.5556871 ,\\n         0.8352932 ...  \n",
       "65   [[William Katz said:  Srini and I think it wou...  \n",
       "66   [[Davis Bennett said: Mark Kittisopikul Raghav...  \n",
       "67   [[Mark Kittisopikul said: Is there a conventio...  \n",
       "68   [[Louis Scheffer said: My work machine uses Sc...  \n",
       "69   [[William Katz said: Illustrations for Zarr co...  \n",
       "70   [[William Katz said:  Srini and I think it wou...  \n",
       "71   [[Konrad Rokicki said: CoPilot getting some co...  \n",
       "72   [[Srini said: Huh. If the result is so sensiti...  \n",
       "73   [[Mark Kittisopikul said: https://loudounnow.c...  \n",
       "74   [[Mark Kittisopikul said: Sigh. I'm still tryi...  \n",
       "75   [[Davis Bennett said: https://www.nature.com/a...  \n",
       "76   [[Mark Kittisopikul said: Davis Bennett, you w...  \n",
       "77   [[Mark Kittisopikul said: Is there a conventio...  \n",
       "78   [[William Katz said: Illustrations for Zarr co...  \n",
       "79   [[Mark Kittisopikul said: https://patch.com/vi...  \n",
       "80   [[kwargs)\\n    512                            ...  \n",
       "81   [[kwargs)\\n    512                            ...  \n",
       "82   [[Cristian Goina said: here’s how  I checked i...  \n",
       "83   [[.        ,  0.        ,  0.        ,  0.    ...  \n",
       "84   [[William Katz said:  Srini and I think it wou...  \n",
       "85   [[isopikul said: Could you run\\necho $LD_LIBRA...  \n",
       "86   [[Ulrike Boehm said: Hello everyone, The Optic...  \n",
       "87   [[Ken Carlile said: Stephan Saalfeld has alrea...  \n",
       "88   [[William Katz said: Blog post: https://yuri.i...  \n",
       "89   [[Davis Bennett said: cluster looking choked\\n...  \n",
       "90   [[William Katz said: Blog post: https://yuri.i...  \n",
       "91   [[Louis Scheffer said: My work machine uses Sc...  \n",
       "92   [[Ulrike Boehm said: For those of you interest...  \n",
       "93   [[Ulrike Boehm said: Hello everyone, The Optic...  \n",
       "94   [[Konrad Rokicki said: That’s just for the hea...  \n",
       "95   [[ need to eval the function definition. The c...  \n",
       "96   [[ like??\\nMark Kittisopikul said: The conda-f...  \n",
       "97   [[Louis Scheffer said: My work machine uses Sc...  \n",
       "98   [[Donald Olbris said: https://bitecode.substac...  \n",
       "99   [[Davis Bennett said: one thing I've wanted fo...  \n",
       "100  [[Konrad Rokicki said: CoPilot getting some co...  \n",
       "101  [[e-01,... 0.36549678, 0.9152956 ,\\n       1.0...  \n",
       "102  [[Davis Bennett said: Philip Hubbard how hard ...  \n",
       "103  [[ not sure if the other major contributor eve...  \n",
       "104  [[Virginia Scarlett said: Bob's has donuts on ...  \n",
       "105  [[Gert-Jan Both said: I just updated the funct...  \n",
       "106  [[Gert-Jan Both said: I just updated the funct...  \n",
       "107  [[Gert-Jan Both said: I just updated the funct...  \n",
       "108  [[Cristian Goina said: I am running my jupyter...  \n",
       "109  [[Mark Kittisopikul said: I just reading throu...  \n",
       "110  [[Mark Kittisopikul said: There was this incid...  \n",
       "111  [[Mark Kittisopikul said: Does anyone have any...  \n",
       "112  [[Mark Kittisopikul said: https://patch.com/vi...  \n",
       "113  [[Ken Carlile said: Stephan Saalfeld has alrea...  \n",
       "114  [[William Katz said: Interesting blog on Janel...  \n",
       "115  [[Ulrike Boehm said: Hello everyone, The Optic...  \n",
       "116  [[Konrad Rokicki said: That’s just for the hea...  \n",
       "117  [[Virginia Scarlett said: Bob's has donuts on ...  \n",
       "118  [[Konrad Rokicki said: Curious if anyone knows...  \n",
       "119  [[isopikul said: Could you run\\necho $LD_LIBRA...  \n",
       "120  [[Konrad Rokicki said: This thing is so cool: ...  \n",
       "121  [[Konrad Rokicki said: Curious if anyone knows...  \n",
       "122  [[Davis Bennett said: one thing I've wanted fo...  \n",
       "123  [[Gert-Jan Both said: Alright I have a basic r...  \n",
       "124  [[Davis Bennett said: has anyone tried this fo...  \n",
       "125  [[Davis Bennett said: has anyone tried this fo...  \n",
       "126  [[Xi said: I agree with Geneva!\\nIn the Hackat...  \n",
       "127  [[Adam Taylor said: Well, there's the issue of...  \n",
       "128  [[Mark Kittisopikul said: Sigh. I'm still tryi...  \n",
       "129  [[Davis Bennett said: has anyone tried this fo...  \n",
       "130  [[Davis Bennett said: one thing I've wanted fo...  \n",
       "131  [[William Katz said: Some discussion of Minio ...  \n",
       "132  [[Gert-Jan Both said: So more progress - I get...  \n",
       "133  [[\\n                print(\"ROI is 2D, recruiti...  \n",
       "134  [[Srini said: We only have absorption at the s...  \n",
       "135  [[ into Python via the Java Native Interface i...  \n",
       "136  [[N,4 it saves it as channels\\nDavis Bennett s...  \n",
       "137  [[/bin/ld: /opt/cray/pe/mpich/8.1.16/ofi/nvidi...  \n",
       "138  [[Mark Kittisopikul said: Sometimes the simpli...  \n",
       "139  [[.10534273, -0.5556871 ,\\n         0.8352932 ...  \n",
       "140  [[Srini said: We only have absorption at the s...  \n",
       "141  [[Mark Kittisopikul said: The maven packaging ...  \n",
       "142  [[Mark Kittisopikul said: Davis Bennett, you w...  \n",
       "143  [[Konrad Rokicki said: https://openai.com/blog...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "display(pd.read_parquet(\"ragasTestSet_2.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c03839e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:asyncio:Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-10922' coro=<as_completed.<locals>.sema_coro() running at /Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/executor.py:37> wait_for=<Future pending cb=[Task.task_wakeup()]> cb=[as_completed.<locals>._on_completion() at /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:618]>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/selector_events.py:879: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=93 read=idle write=<idle, bufsize=0>>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:726: ResourceWarning: unclosed event loop <_UnixSelectorEventLoop running=False closed=False debug=False>\n",
      "  _warn(f\"unclosed event loop {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "Exception ignored in: <coroutine object Executor.wrap_callable_with_index.<locals>.wrapped_callable_async at 0x315b04f40>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/executor.py\", line 111, in wrapped_callable_async\n",
      "    return counter, await callable(*args, **kwargs)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/testset/evolutions.py\", line 142, in evolve\n",
      "    ) = await self._aevolve(current_tries, current_nodes)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/testset/evolutions.py\", line 466, in _aevolve\n",
      "    simple_question, current_nodes, _ = await self.se._aevolve(\n",
      "                                        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/testset/evolutions.py\", line 304, in _aevolve\n",
      "    results = await self.generator_llm.generate(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 47, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/tenacity/__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 50, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/llms/base.py\", line 178, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/langchain_core/language_models/llms.py\", line 643, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/langchain_core/language_models/llms.py\", line 1018, in agenerate\n",
      "    output = await self._agenerate_helper(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: coroutine ignored GeneratorExit\n",
      "Exception ignored in: <coroutine object Executor.wrap_callable_with_index.<locals>.wrapped_callable_async at 0x315b055d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/executor.py\", line 111, in wrapped_callable_async\n",
      "    return counter, await callable(*args, **kwargs)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/testset/evolutions.py\", line 142, in evolve\n",
      "    ) = await self._aevolve(current_tries, current_nodes)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/testset/evolutions.py\", line 304, in _aevolve\n",
      "    results = await self.generator_llm.generate(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 47, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/tenacity/__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 50, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/llms/base.py\", line 178, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/langchain_core/language_models/llms.py\", line 643, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/langchain_core/language_models/llms.py\", line 1018, in agenerate\n",
      "    output = await self._agenerate_helper(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: coroutine ignored GeneratorExit\n",
      "Exception ignored in: <coroutine object Executor.wrap_callable_with_index.<locals>.wrapped_callable_async at 0x315b056c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/executor.py\", line 111, in wrapped_callable_async\n",
      "    return counter, await callable(*args, **kwargs)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/testset/evolutions.py\", line 142, in evolve\n",
      "    ) = await self._aevolve(current_tries, current_nodes)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/testset/evolutions.py\", line 304, in _aevolve\n",
      "    results = await self.generator_llm.generate(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 47, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/tenacity/__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 50, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/llms/base.py\", line 178, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/langchain_core/language_models/llms.py\", line 643, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/langchain_core/language_models/llms.py\", line 1018, in agenerate\n",
      "    output = await self._agenerate_helper(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: coroutine ignored GeneratorExit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:asyncio:Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-10920' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/executor.py:35> wait_for=<Future pending cb=[Task.task_wakeup()]> cb=[as_completed.<locals>._on_completion() at /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:618]>\n",
      "ERROR:asyncio:Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-10921' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/ragas/executor.py:35> wait_for=<Future pending cb=[Task.task_wakeup()]> cb=[as_completed.<locals>._on_completion() at /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:618]>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/selector_events.py:879: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=91>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/selector_events.py:879: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=98>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/selector_events.py:879: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=99>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/selector_events.py:879: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=101>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "Exception ignored in: <function ClientResponse.__del__ at 0x176ab3f60>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/aiohttp/client_reqrep.py\", line 891, in __del__\n",
      "    self._connection.release()\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/aiohttp/connector.py\", line 173, in release\n",
      "    self._connector._release(\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/aiohttp/connector.py\", line 667, in _release\n",
      "    protocol.close()\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/aiohttp/client_proto.py\", line 71, in close\n",
      "    transport.close()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/selector_events.py\", line 1210, in close\n",
      "    super().close()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/selector_events.py\", line 875, in close\n",
      "    self._loop.call_soon(self._call_connection_lost, None)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 795, in call_soon\n",
      "    self._check_closed()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 541, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Exception ignored in: <function ClientResponse.__del__ at 0x176ab3f60>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/aiohttp/client_reqrep.py\", line 891, in __del__\n",
      "    self._connection.release()\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/aiohttp/connector.py\", line 173, in release\n",
      "    self._connector._release(\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/aiohttp/connector.py\", line 667, in _release\n",
      "    protocol.close()\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/aiohttp/client_proto.py\", line 71, in close\n",
      "    transport.close()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/selector_events.py\", line 1210, in close\n",
      "    super().close()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/selector_events.py\", line 875, in close\n",
      "    self._loop.call_soon(self._call_connection_lost, None)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 795, in call_soon\n",
      "    self._check_closed()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 541, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Exception ignored in: <function ClientResponse.__del__ at 0x176ab3f60>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/aiohttp/client_reqrep.py\", line 891, in __del__\n",
      "    self._connection.release()\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/aiohttp/connector.py\", line 173, in release\n",
      "    self._connector._release(\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/aiohttp/connector.py\", line 667, in _release\n",
      "    protocol.close()\n",
      "  File \"/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/aiohttp/client_proto.py\", line 71, in close\n",
      "    transport.close()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/selector_events.py\", line 1210, in close\n",
      "    super().close()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/selector_events.py\", line 875, in close\n",
      "    self._loop.call_soon(self._call_connection_lost, None)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 795, in call_soon\n",
      "    self._check_closed()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 541, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x311d9fce0>\n",
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x30c3c0050>\n",
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x311d95ca0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/aiohttp/client.py:364: ResourceWarning: Unclosed client session <aiohttp.client.ClientSession object at 0x311d9fce0>\n",
      "  _warnings.warn(\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/aiohttp/connector.py:119: ResourceWarning: Unclosed connection Connection<ConnectionKey(host='localhost', port=11434, is_ssl=False, ssl=True, proxy=None, proxy_auth=None, proxy_headers_hash=None)>\n",
      "  _warnings.warn(f\"Unclosed connection {self!r}\", ResourceWarning, **kwargs)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/aiohttp/client.py:364: ResourceWarning: Unclosed client session <aiohttp.client.ClientSession object at 0x30c3c0050>\n",
      "  _warnings.warn(\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Users/bakhalea/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/aiohttp/client.py:364: ResourceWarning: Unclosed client session <aiohttp.client.ClientSession object at 0x311d95ca0>\n",
      "  _warnings.warn(\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/selector_events.py:879: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=104 read=idle write=<idle, bufsize=0>>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/selector_events.py:879: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=106>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/selector_events.py:879: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=111 read=idle write=<idle, bufsize=0>>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/selector_events.py:879: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=113 read=idle write=<idle, bufsize=0>>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/selector_events.py:879: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=117>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/selector_events.py:879: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=116>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/urllib3/connection.py:196\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/urllib3/util/connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/urllib3/util/connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 73\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 61] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/urllib3/connectionpool.py:495\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 495\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce_content_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/urllib3/connection.py:398\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mputheader(header, value)\n\u001b[0;32m--> 398\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;66;03m# If we're given a body we start sending that in chunks.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:1331\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1331\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:1091\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1091\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1094\u001b[0m \n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:1035\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m-> 1035\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/urllib3/connection.py:236\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 236\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n\u001b[1;32m    238\u001b[0m         \u001b[38;5;66;03m# If we're tunneling it means we're connected to our proxy.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/urllib3/connection.py:211\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[1;32m    212\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    213\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;66;03m# Audit hooks are only available in Python 3.8+\u001b[39;00m\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x3211317f0>: Failed to establish a new connection: [Errno 61] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/urllib3/connectionpool.py:843\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    841\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[0;32m--> 843\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    846\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/urllib3/util/retry.py:519\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    518\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[0;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    521\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='localhost', port=8777): Max retries exceeded with url: /v1/.well-known/ready (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x3211317f0>: Failed to establish a new connection: [Errno 61] Connection refused'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/weaviate/connect/connection.py:644\u001b[0m, in \u001b[0;36mConnection.wait_for_weaviate\u001b[0;34m(self, startup_period)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 644\u001b[0m     \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mready_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_request_header\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mINIT_CHECK_TIMEOUT\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m    647\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m:rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/requests/adapters.py:700\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m--> 700\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPConnectionPool(host='localhost', port=8777): Max retries exceeded with url: /v1/.well-known/ready (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x3211317f0>: Failed to establish a new connection: [Errno 61] Connection refused'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgenerate_answer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SemanticSearchService\n\u001b[1;32m     11\u001b[0m weaviate_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://localhost:8777\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 12\u001b[0m service \u001b[38;5;241m=\u001b[39m \u001b[43mSemanticSearchService\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweaviate_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m (questions_list)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# List to store answers (optional)\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/eval/generate_answer.py:33\u001b[0m, in \u001b[0;36mSemanticSearchService.__init__\u001b[0;34m(self, weaviate_url)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, weaviate_url):\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweaviate_url \u001b[38;5;241m=\u001b[39m weaviate_url\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweaviate_client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_weaviate_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_query_engine()\n",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/eval/generate_answer.py:37\u001b[0m, in \u001b[0;36mSemanticSearchService.get_weaviate_client\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_weaviate_client\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 37\u001b[0m     client \u001b[38;5;241m=\u001b[39m \u001b[43mweaviate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweaviate_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m client\u001b[38;5;241m.\u001b[39mis_live():\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeaviate is not live at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweaviate_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/weaviate/client.py:150\u001b[0m, in \u001b[0;36mClient.__init__\u001b[0;34m(self, url, auth_client_secret, timeout_config, proxies, trust_env, additional_headers, startup_period, embedded_options, additional_config)\u001b[0m\n\u001b[1;32m    147\u001b[0m config \u001b[38;5;241m=\u001b[39m Config() \u001b[38;5;28;01mif\u001b[39;00m additional_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m additional_config\n\u001b[1;32m    148\u001b[0m url, embedded_db \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__parse_url_and_embedded_db(url, embedded_options)\n\u001b[0;32m--> 150\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection \u001b[38;5;241m=\u001b[39m \u001b[43mConnection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth_client_secret\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth_client_secret\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_get_valid_timeout_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_config\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43madditional_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madditional_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartup_period\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartup_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedded_db\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedded_db\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrcp_port\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrpc_port_experimental\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconnection_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassification \u001b[38;5;241m=\u001b[39m Classification(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschema \u001b[38;5;241m=\u001b[39m Schema(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection)\n",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/weaviate/connect/connection.py:166\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[0;34m(self, url, auth_client_secret, timeout_config, proxies, trust_env, additional_headers, startup_period, connection_config, embedded_db, grcp_port)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m startup_period \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     _check_positive_num(startup_period, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstartup_period\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mint\u001b[39m, include_zero\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 166\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_weaviate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstartup_period\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_sessions(auth_client_secret)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_adapter_to_session(connection_config)\n",
      "File \u001b[0;32m~/Documents/gpt-semantic-search/env/lib/python3.12/site-packages/weaviate/connect/connection.py:649\u001b[0m, in \u001b[0;36mConnection.wait_for_weaviate\u001b[0;34m(self, startup_period)\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (RequestsHTTPError, RequestsConnectionError, ReadTimeout):\n\u001b[0;32m--> 649\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    652\u001b[0m     requests\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    653\u001b[0m         ready_url, headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_request_header(), timeout\u001b[38;5;241m=\u001b[39mINIT_CHECK_TIMEOUT\n\u001b[1;32m    654\u001b[0m     )\u001b[38;5;241m.\u001b[39mraise_for_status()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Assuming SemanticSearchParser is your class and it has a method named 'generate_response' that takes a question and returns an answer\n",
    "\n",
    "# Initialize your SemanticSearchParser class\n",
    "# Adjust this step if your class initialization requires different parameters\n",
    "\n",
    "\n",
    "# Now you can import the class\n",
    "\n",
    "from generate_answer import SemanticSearchService\n",
    "\n",
    "weaviate_url = \"http://localhost:8777\"\n",
    "service = SemanticSearchService(weaviate_url)\n",
    "print (questions_list)\n",
    "\n",
    "# List to store answers (optional)\n",
    "answers_list = []\n",
    "\n",
    "\n",
    "# Loop through each question in the questions_list\n",
    "for question in questions_list:\n",
    "    # Use the question as input to get the answer\n",
    "    answer = service.generate_response(question)\n",
    "    \n",
    "    # Print the answer\n",
    "    \n",
    "    # Optionally, append the answer to answers_list for further processing\n",
    "    answers_list.append(answer)\n",
    "\n",
    "print (answers_list)\n",
    "# temp_ans_list = [\"The Janelia Scientific Computing team operates and maintains a world-class computational infrastructure that includes a high-performance compute cluster with over 5000 cores and 300 GPUs. This infrastructure is used to analyze and mine the large amounts of data produced by Janelia's scientists. The team also supports a state-of-the-art storage and compute infrastructure across two data centers, which currently supports over 15 petabytes of scientific data. This data is split across various storage tiers and is connected with an optical fiber ring. The team also maintains a 4500 sq ft data center with significant power and cooling capacity. \\n\\nIn addition to hardware, the team also has deep software skills in a broad range of programming languages, extendable applications, frameworks, cloud & cluster technologies, and databases. These skills are used to help with research and engineering tasks, from quick questions to full software life cycle support. The team's software skills, combined with their domain knowledge in areas such as image processing, machine learning, data handling, microscopy, instrument control, 3D graphics & visualization, and bioinformatics & transcriptomics, allow them to efficiently work with both experimentalists and computer scientists. \\n\\nThe team also develops and maintains a variety of tools and projects, such as NeuronBridge, HortaCloud, VVD Viewer, EASI-FISH pipeline, Render, RS-FISH, and BigStitcher, which are used for various aspects of data analysis and simulation in biological research.\", \"The Janelia Scientific Computing team provides a wide range of support for advanced imaging techniques and image analysis. They offer consultation on experiment design as well as image visualization and processing. They also provide comprehensive image and data analysis support for multiple software packages through hands-on assistance and/or custom-written macros/plugins/scripts for ImageJ/FIJI, MATLAB, Imaris, etc. \\n\\nIn addition, they maintain several computer workstations dedicated to viewing and processing large image datasets acquired with the facility's instruments. These workstations are equipped with a suite of imaging software, including a full version of Imaris, and have robust hardware specifications to handle large datasets. \\n\\nThe team also has deep domain knowledge in image processing, machine learning, data handling, and 3D graphics & visualization, which allows them to efficiently work with experimentalists and computer scientists in various research areas.\", \"The Janelia Scientific Computing team provides world-class computational infrastructure to support the institute's scientific endeavors. They operate and maintain all of Janelia’s storage and associated backup infrastructure, high performance compute cluster, and all Linux systems. They also manage Janelia’s data center and backup and disaster recovery resources. The team supports a Linux compute cluster with over 5000 cores and 300 GPUs, and is responsible for maintaining many other Linux servers and workstations. They also handle a significant amount of data, with almost 100TB of new Janelia’s data being safely backed up every month.\\n\\nIn addition to infrastructure, the Scientific Computing Software team works closely with Janelia's labs and project teams, providing everything from answering quick questions to full software life cycle support. They have a broad range of software skills, including programming languages, extendable applications, frameworks, cloud & cluster technologies, and databases. They also have deep domain knowledge in areas like image processing, machine learning, data handling, microscopy, instrument control, 3D graphics & visualization, and bioinformatics & transcriptomics. \\n\\nThe team also identifies opportunities for code reuse, reducing development overhead and support costs across Janelia. They are strong proponents of open science and have created the Open Science Software Initiative. Most of their software is open source and available via GitHub. They also run a Scientific Computing Associates program to embed associates in SciComp and the lab or team they work with. \\n\\nThe team is led by Stephan Preibisch and consists of three teams: Software Engineering headed by Konrad Rokicki, Computational Methods and Solutions, both headed by Stephan Preibisch. They have developed several tools and projects like NeuronBridge, HortaCloud, VVD Viewer, EASI-FISH pipeline, Render, RS-FISH, and BigStitcher. \\n\\nIn summary, the Janelia Scientific Computing team supports the institute's mission and drives innovation in modern biological research by providing robust computational infrastructure, software support, and developing innovative tools and solutions.\", 'The Janelia Scientific Computing team supports advanced imaging techniques in neuroscience and cell biology through a variety of ways. They have deep domain knowledge in image processing, machine learning, data handling, electron and light microscopy, instrument control, 3D graphics & visualization, bioinformatics & transcriptomics. They also develop and maintain a range of software tools and applications that aid in these areas. Some of these tools include NeuronBridge for finding neuron matches across modalities, HortaCloud for cloud-based collaborative annotation, VVD Viewer for volumetric rendering of 3D/4D microscopy data, and BigStitcher for efficient alignment of multi-tile and multi-angle image datasets. They also work closely with labs and project teams, providing full software life cycle support.', \"The Janelia Scientific Computing team supports modern biological research in several ways. They maintain a world-class computational infrastructure, including storage and backup infrastructure, a high-performance compute cluster, and all Linux systems. They also manage Janelia's data center and backup and disaster recovery resources. The team supports data storage infrastructure for storing and accessing scientific data, with over 15 petabytes of scientific data split across various storage tiers. They also support a Linux compute cluster with over 5000 cores and 300 GPUs, and maintain many other Linux servers and workstations. \\n\\nIn addition to infrastructure support, the Scientific Computing Software team works closely with Janelia's labs, project teams, and shared resources to help with research and engineering tasks. They provide everything from answering quick questions to full software life cycle support. The team's software skills span a broad range of programming languages, extendable applications, frameworks, cloud & cluster technologies, and databases. They also have deep domain knowledge in image processing, machine learning, data handling, electron and light microscopy, instrument control, 3D graphics & visualization, bioinformatics & transcriptomics. \\n\\nThe team also develops and maintains a variety of tools and projects, such as NeuronBridge, HortaCloud, VVD Viewer, EASI-FISH pipeline, Render, RS-FISH, and BigStitcher. They are strong proponents of open science and most of their software is open source and available via GitHub. They also run the Scientific Computing Associates program, which offers challenging assignments for those interested in computational science.\", \"The Janelia Scientific Computing team provides comprehensive support for advanced imaging techniques in neuroscience, cell biology, and bioinformatics through a variety of collaborations and custom software tools. They work closely with Janelia's labs, project teams, and shared resources to assist with research and engineering tasks. This can range from answering quick questions to providing full software life cycle support.\\n\\nThe team's software skills cover a broad range of programming languages, extendable applications, frameworks, cloud & cluster technologies, and databases. They have deep domain knowledge in image processing, machine learning, data handling, electron and light microscopy, instrument control, 3D graphics & visualization, bioinformatics & transcriptomics. Many team members have backgrounds in biology, enabling them to work efficiently with experimentalists and computer scientists.\\n\\nThe team is also involved in various projects and tools such as NeuronBridge, HortaCloud, VVD Viewer, EASI-FISH pipeline, Render, RS-FISH, and BigStitcher, which are designed to support advanced imaging techniques and data analysis in neuroscience, cell biology, and bioinformatics.\\n\\nFurthermore, the team is a strong proponent of open science and has teamed up with the Computation & Theory research area to create the Open Science Software Initiative. Most of their software is open source and available via GitHub, promoting collaboration and knowledge sharing. They also run the Scientific Computing Associates program, which embeds associates in SciComp and the lab or team they work with.\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9699a438",
   "metadata": {},
   "source": [
    "Add values from the list of JaneliaGPT responses to the dataframe[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93eaea4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['answer'] = None\n",
    "# Assuming df is your DataFrame and answers_list is a list with values to populate the 'Answer' column\n",
    "if len(df) == len(answers_list):\n",
    "    df['answer'] = answers_list\n",
    "else:\n",
    "    print(\"The length of answers_list does not match the number of rows in the DataFrame.\")\n",
    "\n",
    "df.dropna(axis=1, how='all', inplace=True)\n",
    "display(df)\n",
    "# df.to_json('WithAnswersDatasetFromTestTxt.json', index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6095ca61",
   "metadata": {},
   "source": [
    "Preprocess the dataframe to conver to a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55166bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attempt to fix the issue with the answers_list not bsjdkflasdjjfklasdkl fasdjkfh jkas\n",
    "df_fix = df\n",
    "# List of columns to keep\n",
    "columns_to_keep = ['question', 'ground_truth', 'answer', 'contexts']\n",
    "\n",
    "# Reassign df to a DataFrame containing only the columns to keep\n",
    "\n",
    "df_fix= df_fix[columns_to_keep]\n",
    "\n",
    "\n",
    "\n",
    "# Assuming df is already defined and contains the necessary columns\n",
    "\n",
    "# Convert 'question' and 'answer' to lists of strings if they are not already\n",
    "# df_fix['question'] = df_fix['question'].apply(lambda x: [x] if isinstance(x, str) else x)\n",
    "# df_fix['answer'] = df_fix['answer'].apply(lambda x: [x] if isinstance(x, str) else x)\n",
    "\n",
    "# Ensure 'contexts' and 'ground_truth' are lists of lists of strings\n",
    "# This step assumes 'contexts' and 'ground_truth' are already in the correct format\n",
    "# If not, you would need to apply a similar conversion as above, ensuring each element is a list\n",
    "\n",
    "# Example conversion if 'contexts' and 'ground_truth' were not already lists of lists\n",
    "df_fix['contexts'] = df_fix['contexts'].apply(lambda x: [[y] for y in x] if isinstance(x, list) and all(isinstance(y, str) for y in x) else x)\n",
    "df_fix['ground_truth'] = df_fix['ground_truth'].apply(lambda x: [[y] for y in x] if isinstance(x, list) and all(isinstance(y, str) for y in x) else x)\n",
    "display(df_fix)\n",
    "# Now df should be in the correct format for training\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "amnesty_qa = load_dataset(\"explodinggradients/amnesty_qa\", \"english_v2\")\n",
    "\n",
    "from datasets import Dataset\n",
    "dataset_fix = Dataset.from_pandas(df_fix)\n",
    "dataset_fix = dataset_fix.remove_columns(['__index_level_0__'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636e5b0c",
   "metadata": {},
   "source": [
    "Convert dataframe to Dataset and compare to a vaild Dataset for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec82fd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Features\n",
    "\n",
    "# Assuming dataset_fix and amnesty_qa[\"eval\"] are your datasets\n",
    "features_dataset_fix = dataset_fix.features\n",
    "# features_amnesty_eval = amnesty_qa[\"eval\"].features\n",
    "def format_columns(example):\n",
    "    # Format 'question', 'answer', and 'ground_truths' columns to single values\n",
    "    for column in ['ground_truth', 'answer', 'question']:\n",
    "        if column in example and example[column]:\n",
    "            example[column] = example[column]\n",
    "    \n",
    "    # Correctly format 'contexts' column to a list of list of strings\n",
    "    if 'contexts' in example:\n",
    "        # Ensure 'contexts' is a list of strings (not a list of lists)\n",
    "        if isinstance(example['contexts'], list):\n",
    "            # If the items are lists (or other non-string types), flatten and convert to strings\n",
    "            example['contexts'] = [str(item) for sublist in example['contexts'] for item in (sublist if isinstance(sublist, list) else [sublist])]\n",
    "        else:\n",
    "            # If 'contexts' is not a list, convert it into a list of a single string\n",
    "            example['contexts'] = [str(example['contexts'])]\n",
    "\n",
    "    \n",
    "    return example\n",
    "\n",
    "\n",
    "# Apply the transformation to both datasets\n",
    "dataset_fix = dataset_fix.map(format_columns)\n",
    "# Direct comparison of data types\n",
    "\"\"\"if set(features_dataset_fix.keys()) == set(features_amnesty_eval.keys()):\n",
    "    all_types_match = True\n",
    "    for key in features_dataset_fix.keys():\n",
    "        type_dataset_fix = type(features_dataset_fix[key]).__name__\n",
    "        type_amnesty_eval = type(features_amnesty_eval[key]).__name__\n",
    "        if type_dataset_fix != type_amnesty_eval:\n",
    "            print(f\"Data type for feature '{key}' differs between datasets. dataset_fix: {type_dataset_fix}, amnesty_qa['eval']: {type_amnesty_eval}\")\n",
    "            all_types_match = False\n",
    "    if all_types_match:\n",
    "        print(\"The data types of all features in both datasets match.\")\n",
    "else:\n",
    "    print(\"The Features of the datasets differ in their keys.\")\"\"\"\n",
    "\"\"\"\n",
    "print (dataset_fix[\"question\"])\n",
    "print (dataset_fix[\"answer\"])\n",
    "print (dataset_fix[\"ground_truth\"])\n",
    "print (dataset_fix[\"contexts\"])\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6505f4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from deepeval.metrics import (\n",
    "    ContextualPrecisionMetric,\n",
    "    ContextualRecallMetric,\n",
    "    ContextualRelevancyMetric\n",
    ")\n",
    "\n",
    "contextual_precision = ContextualPrecisionMetric()\n",
    "contextual_recall = ContextualRecallMetric()\n",
    "contextual_relevancy = ContextualRelevancyMetric()\n",
    "\n",
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval import evaluate\n",
    "modified_items = []\n",
    "\n",
    "# Step 2: Iterate over each item in dataset_fix\n",
    "for item in dataset_fix:\n",
    "    # Step 3: Create a new LLMTestCase instance with modified fields\n",
    "    modified_item = LLMTestCase(\n",
    "        input=item[\"question\"],\n",
    "        actual_output=item[\"answer\"],\n",
    "        expected_output=item[\"ground_truth\"],\n",
    "        retrieval_context=item[\"contexts\"]\n",
    "    )\n",
    "    # Step 4: Append the modified item to the list\n",
    "    modified_items.append(modified_item)\n",
    "# Assuming dataset_fix supports item assignment\n",
    "\n",
    "\n",
    "\n",
    "evaluate(\n",
    "    test_cases=[modified_items],\n",
    "    metrics=[contextual_precision, contextual_recall, contextual_relevancy]\n",
    ")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2cc907",
   "metadata": {},
   "source": [
    "Run evaluation to gather the below metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7be48f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "\n",
    "\n",
    "from ragas import evaluate\n",
    "\n",
    "eval_llm = Ollama(model=\"llama3\")\n",
    "# Will reutrn a dataframe with the metrics\n",
    "# Returns error for now because answers column is missing\n",
    "# Error is misleading, fix dataset first and make it match the docs example dataset\n",
    "\n",
    "result = evaluate(\n",
    "    dataset_fix,\n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_recall,\n",
    "    ],\n",
    "    llm=eval_llm,\n",
    ")\n",
    "\n",
    "result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22595923",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)\n",
    "result.to_pandas()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36276909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import json\n",
    "import os\n",
    "\n",
    "class MetricsManager:\n",
    "    def __init__(self, file_path='metrics.json'):\n",
    "        self.file_path = file_path\n",
    "        self.metrics = self.load_metrics()\n",
    "\n",
    "    def load_metrics(self):\n",
    "        if os.path.exists(self.file_path):\n",
    "            with open(self.file_path, 'r') as file:\n",
    "                return json.load(file)\n",
    "        else:\n",
    "            return {}\n",
    "\n",
    "    def save_metrics(self):\n",
    "        with open(self.file_path, 'w') as file:\n",
    "            json.dump(self.metrics, file, indent=4)\n",
    "\n",
    "    def update_metrics(self, trial_name, context_precision, faithfulness, answer_relevancy, context_recall):\n",
    "        averages = {\n",
    "            'context_precision': context_precision,\n",
    "            'faithfulness': faithfulness,\n",
    "            'answer_relevancy': answer_relevancy,\n",
    "            'context_recall': context_recall\n",
    "        }\n",
    "        self.metrics[trial_name] = averages\n",
    "        self.save_metrics()\n",
    "\n",
    "    def render_table(self):\n",
    "        if not self.metrics:\n",
    "            print(\"No metrics available for plotting.\")\n",
    "            return\n",
    "\n",
    "        trials, metrics, averages = [], [], []\n",
    "        for trial_name, metrics_averages in self.metrics.items():\n",
    "            for metric, average in metrics_averages.items():\n",
    "                trials.append(trial_name)\n",
    "                metrics.append(metric)\n",
    "                averages.append(round(average, 4))\n",
    "\n",
    "        Eval_Categories = pd.DataFrame({\n",
    "            'Trial': trials,\n",
    "            'Metric': metrics,\n",
    "            'Average': averages\n",
    "        })\n",
    "\n",
    "        if Eval_Categories.empty:\n",
    "            print(\"No metrics data to plot.\")\n",
    "            return\n",
    "\n",
    "        fig = px.bar(\n",
    "            Eval_Categories,\n",
    "            x='Trial',\n",
    "            y='Average',\n",
    "            color='Metric',\n",
    "            barmode='group',\n",
    "            text='Average',\n",
    "            category_orders={\"Metric\": [\"context_precision\", \"faithfulness\", \"answer_relevancy\", \"context_recall\"]},\n",
    "            labels={\n",
    "                \"Average\": \"Average Score\",\n",
    "                \"Metric\": \"Metric\",\n",
    "                \"Trial\": \"Trial Name\"\n",
    "            }\n",
    "        )\n",
    "\n",
    "        fig.update_layout(\n",
    "            width=1000,\n",
    "            height=600,\n",
    "            title=\"<b>Average Scores of Evaluation Metrics by Trial</b>\",\n",
    "            xaxis_title=\"Trial Name\",\n",
    "            yaxis_title=\"Average Score\",\n",
    "            font=dict(size=15)\n",
    "        )\n",
    "\n",
    "        fig.show()\n",
    "\n",
    "MetricsManager()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
